{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules & prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data.shape: (1259300, 10, 10)\n",
      "original target.shape: (1259300,)\n",
      "\n",
      "electron.shape: (3150, 10, 10), (3150,)\n",
      "muon.shape: (700, 10, 10), (700,)\n",
      "pion.shape: (981050, 10, 10), (981050,)\n",
      "kaon.shape: (160300, 10, 10), (160300,)\n",
      "proton.shape: (114100, 10, 10), (114100,)\n"
     ]
    }
   ],
   "source": [
    "# Import sklearn/tensorflow modules.\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import other modules.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from os import walk\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "# Data source: https://www.kaggle.com/stephenmugisha/particle-collisions\n",
    "\n",
    "_, _, files = next(walk('data'))\n",
    "\n",
    "target_names = {\n",
    "    '0': 'electron',    # Negatively charged particle that is a lepton  (doesn't take part in strong force).\n",
    "    '1': 'muon',    # Electron with 200 times more mass and makes up lots of cosmic radiation.\n",
    "    '2': 'pion',    # Meson (connects with strong force) that can be positive, negative, or neutral\n",
    "    '3': 'kaon',    # Pion with more mass.\n",
    "    '4': 'proton'    # Positively charged particle with 2 up quarks and 1 down quark.\n",
    "}\n",
    "\n",
    "# Check how the data is formatted/stored.\n",
    "file_test = open(f'data/{files[0]}', 'rb')\n",
    "file = pickle.load(file_test)\n",
    "\n",
    "print(file[0].shape)    # Group of 3000 images.\n",
    "print(file[0][0].shape)    # Check first image.\n",
    "print(file[1].shape)    # Group of 3000 targets.\n",
    "print(file[1][0])    # Classified as 'pion.'\n",
    "\n",
    "# Collect all the data.\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for file in files:\n",
    "    file = open(f'data/{files[0]}', 'rb')\n",
    "    file =  pickle.load(file)\n",
    "\n",
    "    for sample, sample_target in zip(file[0], file[1]):\n",
    "        data.append(sample)\n",
    "        target.append(sample_target)\n",
    "\n",
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "\n",
    "sleep(7)\n",
    "clear_output()\n",
    "\n",
    "print(f'original data.shape: {data.shape}')\n",
    "print(f'original target.shape: {target.shape}\\n')\n",
    "\n",
    "# Edit target values to 0, 1, 2...\n",
    "new_target = []\n",
    "\n",
    "for tar in target:\n",
    "    if tar == 11:\n",
    "        new_target.append(0)\n",
    "    elif tar == 13:\n",
    "        new_target.append(1)\n",
    "    elif tar == 211:\n",
    "        new_target.append(2)\n",
    "    elif tar == 321:\n",
    "        new_target.append(3)\n",
    "    else:\n",
    "        new_target.append(4)\n",
    "    \n",
    "target = np.array(new_target)\n",
    "\n",
    "for i in range(5):\n",
    "    particle_indexes = np.where(target == i)[0]\n",
    "\n",
    "    data_modified = data[particle_indexes]\n",
    "    target_modified = target[particle_indexes]\n",
    "    \n",
    "    print(f'{target_names[str(i)]}.shape: {data_modified.shape}, {target_modified.shape}')\n",
    "\n",
    "# NOTE: through the above code, we find there are inconsistencies in the data (less samples for one particle but lots of samples in another)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping data (to make even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even data.shape: (3500, 10, 10)\n",
      "even target.shape: (3500,)\n",
      "even data.shape (sklearn version): (3500, 100)\n"
     ]
    }
   ],
   "source": [
    "muon_indexes = np.where(target == 1)[0]    # since this has least # of samples... use this as limiter\n",
    "\n",
    "def set_data_samples(number_of_samples):    # limit to <= 700 samples for each particle. (to keep data even)\n",
    "    \n",
    "    data_new, target_new = ((data[muon_indexes])[:number_of_samples], (target[muon_indexes])[:number_of_samples])\n",
    "    \n",
    "    for i in [0, 2, 3, 4]:\n",
    "        particle_indexes = np.where(target == i)[0]\n",
    "        data_modified = (data[particle_indexes])[:number_of_samples]    \n",
    "        target_modified = (target[particle_indexes])[:number_of_samples]\n",
    "    \n",
    "        data_new = np.append(data_new, data_modified, axis=0)\n",
    "        target_new = np.append(target_new, target_modified)\n",
    "\n",
    "    return (np.array(data_new), np.array(target_new))\n",
    "\n",
    "\n",
    "data_50_samples, target_50_samples = set_data_samples(50)\n",
    "data_100_samples, target_100_samples = set_data_samples(100)\n",
    "data_150_samples, target_150_samples = set_data_samples(150)\n",
    "data_200_samples, target_200_samples = set_data_samples(200)\n",
    "data_250_samples, target_250_samples = set_data_samples(250)\n",
    "data_300_samples, target_300_samples = set_data_samples(300)\n",
    "data_350_samples, target_350_samples = set_data_samples(350)\n",
    "data_400_samples, target_400_samples = set_data_samples(400)\n",
    "data_450_samples, target_450_samples = set_data_samples(450)\n",
    "data_500_samples, target_500_samples = set_data_samples(500)\n",
    "data_550_samples, target_550_samples = set_data_samples(550)\n",
    "data_600_samples, target_600_samples = set_data_samples(600)\n",
    "data_650_samples, target_650_samples = set_data_samples(650)\n",
    "data_700_samples, target_700_samples = set_data_samples(700)\n",
    "\n",
    "\n",
    "# data_140_samples, target_140_samples = set_data_samples(140)    # NOTE: These will be used for later tests.\n",
    "# data_280_samples, target_280_samples = set_data_samples(280)\n",
    "# data_420_samples, target_420_samples = set_data_samples(420)\n",
    "# data_560_samples, target_560_samples = set_data_samples(560)\n",
    "# data_700_samples, target_700_samples = set_data_samples(700)\n",
    "\n",
    "data = data_700_samples    # Regular number of samples that should be used.\n",
    "target = target_700_samples\n",
    "\n",
    "data_sklearn = data.reshape((3500, -1))\n",
    "\n",
    "print(f'even data.shape: {data.shape}')\n",
    "print(f'even target.shape: {target.shape}')\n",
    "\n",
    "print(f'even data.shape (sklearn version): {data_sklearn.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2625, 10, 10, 1)\n",
      "y_train.shape: (2625, 5)\n",
      "X_test.shape: (875, 10, 10, 1)\n",
      "y_test.shape: (875, 5)\n",
      "\n",
      "sklearn versions\n",
      "X_train.shape: (2625, 100)\n",
      "y_train.shape: (2625,)\n",
      "X_test.shape: (875, 100)\n",
      "y_test.shape: (875,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for NaN values.\n",
    "print(np.isnan(np.sum(data)))    # -> False\n",
    "\n",
    "# Check range of values.\n",
    "print(np.max(data), np.min(data))    # -> 8, 0\n",
    "\n",
    "sleep(4)\n",
    "clear_output()\n",
    "\n",
    "# Get indexes for each different target possibility.\n",
    "indexes = [\n",
    "    np.where(target == 0)[0][0],\n",
    "    np.where(target == 1)[0][0],\n",
    "    np.where(target == 2)[0][0],\n",
    "    np.where(target == 3)[0][0],\n",
    "    np.where(target == 4)[0][0],\n",
    "]\n",
    "\n",
    "samples = [data[index] for index in indexes]\n",
    "samples_target = [target_names[str(target[index])] for index in indexes]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9, 6), subplot_kw={\n",
    "    'yticks': (),\n",
    "    'xticks': ()\n",
    "})\n",
    "\n",
    "axs = [ax for ax in axs.flatten()]\n",
    "\n",
    "for sample, sample_target, ax in zip(samples, samples_target, axs):\n",
    "    ax.imshow(sample, cmap='binary')\n",
    "    ax.set_title(str(sample_target))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, stratify=target)\n",
    "\n",
    "# Change the train and test datasets.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape + change data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Scale and reshape data back to og form.\n",
    "X_train = (scaler.fit_transform(X_train)).reshape((X_train.shape[0], 10, 10, 1))\n",
    "X_test = (scaler.transform(X_test)).reshape((X_test.shape[0], 10, 10, 1))\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train_sklearn, X_test_sklearn, y_train_sklearn, y_test_sklearn = train_test_split(data_sklearn, target, stratify=target)\n",
    "\n",
    "y_train_sklearn, y_test_sklearn = ([], [])\n",
    "\n",
    "for label in list(y_train):\n",
    "    y_train_sklearn.append(list(label).index(1))    # changing sample from [0, 1, 0, 0, 0] to [2, .....]\n",
    "\n",
    "for label in list(y_test):\n",
    "    y_test_sklearn.append(list(label).index(1))\n",
    "\n",
    "y_train_sklearn = np.array(y_train_sklearn)\n",
    "y_test_sklearn = np.array(y_test_sklearn)\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "\n",
    "print('\\nsklearn versions')\n",
    "print(f'X_train.shape: {X_train_sklearn.shape}')\n",
    "print(f'y_train.shape: {y_train_sklearn.shape}')\n",
    "print(f'X_test.shape: {X_test_sklearn.shape}')\n",
    "print(f'y_test.shape: {y_test_sklearn.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "42/42 [==============================] - 1s 2ms/step - loss: 2.1976 - accuracy: 0.1570\n",
      "Epoch 2/3\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 2.0495 - accuracy: 0.1832\n",
      "Epoch 3/3\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9935 - accuracy: 0.3093\n",
      "Train accuracy: 32.3%\n",
      "Test accuracy: 31.2%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(5, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "tf_model = Model()\n",
    "\n",
    "tf_model.build(input_shape=(1, 10, 10, 1))\n",
    "tf_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = tf_model.fit(X_train, y_train, epochs=3, batch_size=64).history\n",
    "\n",
    "sleep(4)\n",
    "# clear_output()\n",
    "\n",
    "print(f'Train accuracy: {tf_model.evaluate(X_train, y_train, verbose=False)[1]*100:.1f}%')\n",
    "print(f'Test accuracy: {tf_model.evaluate(X_test, y_test, verbose=False)[1]*100:.1f}%')\n",
    "\n",
    "fig, (ax_1, ax_2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax_1.plot(range(3), history['loss'])\n",
    "ax_2.plot(range(3), history['accuracy'])\n",
    "\n",
    "ax_1.set_title('Loss')\n",
    "ax_2.set_title('Accuracy');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `sklearn` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 26.13%\n",
      "Test Accuracy: 18.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_sklearn, y_train_sklearn)\n",
    "\n",
    "print(f'Train Accuracy: {logreg.score(X_train_sklearn, y_train_sklearn)*100:.2f}%')\n",
    "print(f'Test Accuracy: {logreg.score(X_test_sklearn, y_test_sklearn)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron accuracy: 79.4%\n",
      "muon accuracy: 100.0%\n",
      "pion accuracy: 9.1%\n",
      "kaon accuracy: 29.1%\n",
      "proton accuracy: 23.4%\n"
     ]
    }
   ],
   "source": [
    "def individual_particle_test(model):\n",
    "    for i in range(5):\n",
    "        int_y_test = np.array([np.argmax(y, axis=None, out=None) for y in y_test])    # convert back to integer for comparison.\n",
    "        particle_indexes = np.where(int_y_test == i)    # gives indexes for all electron, muon, etc testcases...\n",
    "\n",
    "        X_test_modified = X_test[particle_indexes]\n",
    "        y_test_modified = y_test[particle_indexes]\n",
    "\n",
    "        print(f'{target_names[str(i)]} accuracy: {model.evaluate(X_test_modified, y_test_modified, verbose=False)[1]*100:.1f}%')\n",
    "\n",
    "individual_particle_test(tf_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Results\n",
    "<img src='images/test_1_(19).png'>\n",
    "<img src='images/test 2 (19).png'></br>\n",
    "difference between one test and another (inconsistencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "* The algorithm shows some promise for some particles, but little for others.\n",
    "    * muon could have 100% accuracy because of its mass... has less quantum effect compared to others.\n",
    "    * electron could be low because of quantum effects\n",
    "    * proton is actually pretty consistent.\n",
    "    * out of mesons, kaon and proton lowest while pion higher (because of higher mass than other mesons)\n",
    "    * next steps, find reason for fluctuations in percentages and relationships between particles considering their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph relationship between sample size and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (2088013771.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [14]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def samples_test(verbose=True, test):\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# TODO: figure out how to do this with both image classifier and regular classifier.\n",
    "\n",
    "info_x_samples = [\n",
    "    (data_50_samples, target_50_samples), \n",
    "    (data_100_samples, target_100_samples),\n",
    "    (data_150_samples, target_150_samples), \n",
    "    (data_200_samples, target_200_samples), \n",
    "    (data_250_samples, target_250_samples), \n",
    "    (data_300_samples, target_300_samples), \n",
    "    (data_350_samples, target_350_samples), \n",
    "    (data_400_samples, target_400_samples), \n",
    "    (data_450_samples, target_450_samples),\n",
    "    (data_500_samples, target_500_samples), \n",
    "    (data_550_samples, target_550_samples), \n",
    "    (data_600_samples, target_600_samples), \n",
    "    (data_650_samples, target_650_samples), \n",
    "    (data_700_samples, target_700_samples)\n",
    "]\n",
    "sample_numbers = (list(range(50, 701, 50)))\n",
    "results = []\n",
    "\n",
    "def samples_test(verbose=True):\n",
    "    \n",
    "    results.append([])\n",
    "\n",
    "    for sample_number, i in zip(sample_numbers, range(14)):\n",
    "        data_x_samples = info_x_samples[i][0]\n",
    "        target_x_samples = info_x_samples[i][1]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data_x_samples = data_x_samples.reshape(data_x_samples.shape[0], -1)\n",
    "        data_x_samples = (scaler.fit_transform(data_x_samples)).reshape((data_x_samples.shape[0], 10, 10, 1))\n",
    "        \n",
    "        target_x_samples = to_categorical(target_x_samples)\n",
    "    \n",
    "        temp_tf_model = Model()\n",
    "    \n",
    "        temp_tf_model.build(input_shape=(1, 10, 10, 1))\n",
    "        temp_tf_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        temp_tf_model.fit(data_x_samples, target_x_samples, epochs=3, batch_size=64, verbose=False)\n",
    "    \n",
    "        initial_accuracy = temp_tf_model.evaluate(X_train, y_train, verbose=False)[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nTrain accuracy: {initial_accuracy*100:.1f}% ({sample_number} samples)')\n",
    "        \n",
    "        if verbose:\n",
    "            for re_iter in info_x_samples:\n",
    "                data_new = re_iter[0]\n",
    "                target_new = re_iter[1]\n",
    "        \n",
    "                scaler = StandardScaler()\n",
    "        \n",
    "                data_new = data_new.reshape(data_new.shape[0], -1)\n",
    "                data_new = (scaler.fit_transform(data_new)).reshape((data_new.shape[0], 10, 10, 1))\n",
    "        \n",
    "                target_new = to_categorical(target_new)\n",
    "        \n",
    "                print(f'\\t{(data_new.shape[0])/5} samples test: {tf_model.evaluate(data_new, target_new, verbose=False)[1]*100:.1f}%')\n",
    "        \n",
    "        results[-1].append(initial_accuracy)\n",
    "    \n",
    "\n",
    "samples_test()\n",
    "for i in range(49):\n",
    "    samples_test(verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare results from tests for R data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "df = pd.DataFrame(results, columns=[f'{num} samples' for num in range(50, 701, 50)])\n",
    "df.to_csv('R Data Analysis/data/samples_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Test Runs (when trained on 700 samples):\n",
    "<img src='images/accuracy_sample_test1.png'>\n",
    "<img src='images/accuracy_sample_test2.png'>\n",
    "<img src='images/accuracy_sample_test3.png'>\n",
    "<img src='images/accuracy_sample_test4.png'>\n",
    "<img src='images/accuracy_sample_test5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy: 25.3% (50 samples)\n",
      "\t50.0 samples test: 25.6%\n",
      "\t100.0 samples test: 25.6%\n",
      "\t150.0 samples test: 25.9%\n",
      "\t200.0 samples test: 25.6%\n",
      "\t250.0 samples test: 25.1%\n",
      "\t300.0 samples test: 25.3%\n",
      "\t350.0 samples test: 25.1%\n",
      "\t400.0 samples test: 25.5%\n",
      "\t450.0 samples test: 25.5%\n",
      "\t500.0 samples test: 25.3%\n",
      "\t550.0 samples test: 25.3%\n",
      "\t600.0 samples test: 23.2%\n",
      "\t650.0 samples test: 23.1%\n",
      "\t700.0 samples test: 23.0%\n",
      "\n",
      "Train accuracy: 18.9% (100 samples)\n",
      "\t50.0 samples test: 19.2%\n",
      "\t100.0 samples test: 19.4%\n",
      "\t150.0 samples test: 19.6%\n",
      "\t200.0 samples test: 19.2%\n",
      "\t250.0 samples test: 19.0%\n",
      "\t300.0 samples test: 18.8%\n",
      "\t350.0 samples test: 18.9%\n",
      "\t400.0 samples test: 19.0%\n",
      "\t450.0 samples test: 18.8%\n",
      "\t500.0 samples test: 18.5%\n",
      "\t550.0 samples test: 18.8%\n",
      "\t600.0 samples test: 18.8%\n",
      "\t650.0 samples test: 18.7%\n",
      "\t700.0 samples test: 18.8%\n",
      "\n",
      "Train accuracy: 20.8% (150 samples)\n",
      "\t50.0 samples test: 24.8%\n",
      "\t100.0 samples test: 34.2%\n",
      "\t150.0 samples test: 23.2%\n",
      "\t200.0 samples test: 22.8%\n",
      "\t250.0 samples test: 22.0%\n",
      "\t300.0 samples test: 21.9%\n",
      "\t350.0 samples test: 21.5%\n",
      "\t400.0 samples test: 21.5%\n",
      "\t450.0 samples test: 21.2%\n",
      "\t500.0 samples test: 21.2%\n",
      "\t550.0 samples test: 21.3%\n",
      "\t600.0 samples test: 21.1%\n",
      "\t650.0 samples test: 20.9%\n",
      "\t700.0 samples test: 21.0%\n",
      "\n",
      "Train accuracy: 25.0% (200 samples)\n",
      "\t50.0 samples test: 21.2%\n",
      "\t100.0 samples test: 23.4%\n",
      "\t150.0 samples test: 24.9%\n",
      "\t200.0 samples test: 25.0%\n",
      "\t250.0 samples test: 24.9%\n",
      "\t300.0 samples test: 24.2%\n",
      "\t350.0 samples test: 24.5%\n",
      "\t400.0 samples test: 24.3%\n",
      "\t450.0 samples test: 24.9%\n",
      "\t500.0 samples test: 24.9%\n",
      "\t550.0 samples test: 24.8%\n",
      "\t600.0 samples test: 24.7%\n",
      "\t650.0 samples test: 24.7%\n",
      "\t700.0 samples test: 24.9%\n",
      "\n",
      "Train accuracy: 41.2% (250 samples)\n",
      "\t50.0 samples test: 37.6%\n",
      "\t100.0 samples test: 38.8%\n",
      "\t150.0 samples test: 40.5%\n",
      "\t200.0 samples test: 40.6%\n",
      "\t250.0 samples test: 40.7%\n",
      "\t300.0 samples test: 40.4%\n",
      "\t350.0 samples test: 40.4%\n",
      "\t400.0 samples test: 40.5%\n",
      "\t450.0 samples test: 40.2%\n",
      "\t500.0 samples test: 40.7%\n",
      "\t550.0 samples test: 40.5%\n",
      "\t600.0 samples test: 40.6%\n",
      "\t650.0 samples test: 40.4%\n",
      "\t700.0 samples test: 40.6%\n",
      "\n",
      "Train accuracy: 30.5% (300 samples)\n",
      "\t50.0 samples test: 30.8%\n",
      "\t100.0 samples test: 31.6%\n",
      "\t150.0 samples test: 31.5%\n",
      "\t200.0 samples test: 31.4%\n",
      "\t250.0 samples test: 30.8%\n",
      "\t300.0 samples test: 30.7%\n",
      "\t350.0 samples test: 30.4%\n",
      "\t400.0 samples test: 30.2%\n",
      "\t450.0 samples test: 30.6%\n",
      "\t500.0 samples test: 30.5%\n",
      "\t550.0 samples test: 30.5%\n",
      "\t600.0 samples test: 30.7%\n",
      "\t650.0 samples test: 30.7%\n",
      "\t700.0 samples test: 30.5%\n",
      "\n",
      "Train accuracy: 18.9% (350 samples)\n",
      "\t50.0 samples test: 28.0%\n",
      "\t100.0 samples test: 30.0%\n",
      "\t150.0 samples test: 19.9%\n",
      "\t200.0 samples test: 19.4%\n",
      "\t250.0 samples test: 29.4%\n",
      "\t300.0 samples test: 29.5%\n",
      "\t350.0 samples test: 29.4%\n",
      "\t400.0 samples test: 18.9%\n",
      "\t450.0 samples test: 19.1%\n",
      "\t500.0 samples test: 18.9%\n",
      "\t550.0 samples test: 18.8%\n",
      "\t600.0 samples test: 18.9%\n",
      "\t650.0 samples test: 18.7%\n",
      "\t700.0 samples test: 18.8%\n",
      "\n",
      "Train accuracy: 28.9% (400 samples)\n",
      "\t50.0 samples test: 20.4%\n",
      "\t100.0 samples test: 22.8%\n",
      "\t150.0 samples test: 25.7%\n",
      "\t200.0 samples test: 26.9%\n",
      "\t250.0 samples test: 27.7%\n",
      "\t300.0 samples test: 28.1%\n",
      "\t350.0 samples test: 27.6%\n",
      "\t400.0 samples test: 28.1%\n",
      "\t450.0 samples test: 28.3%\n",
      "\t500.0 samples test: 28.4%\n",
      "\t550.0 samples test: 28.4%\n",
      "\t600.0 samples test: 28.6%\n",
      "\t650.0 samples test: 28.5%\n",
      "\t700.0 samples test: 28.3%\n",
      "\n",
      "Train accuracy: 41.0% (450 samples)\n",
      "\t50.0 samples test: 26.8%\n",
      "\t100.0 samples test: 30.2%\n",
      "\t150.0 samples test: 41.6%\n",
      "\t200.0 samples test: 41.8%\n",
      "\t250.0 samples test: 41.8%\n",
      "\t300.0 samples test: 42.0%\n",
      "\t350.0 samples test: 41.5%\n",
      "\t400.0 samples test: 40.9%\n",
      "\t450.0 samples test: 40.9%\n",
      "\t500.0 samples test: 40.8%\n",
      "\t550.0 samples test: 41.2%\n",
      "\t600.0 samples test: 41.2%\n",
      "\t650.0 samples test: 41.3%\n",
      "\t700.0 samples test: 41.3%\n",
      "\n",
      "Train accuracy: 37.5% (500 samples)\n",
      "\t50.0 samples test: 35.6%\n",
      "\t100.0 samples test: 34.6%\n",
      "\t150.0 samples test: 37.3%\n",
      "\t200.0 samples test: 37.4%\n",
      "\t250.0 samples test: 38.3%\n",
      "\t300.0 samples test: 38.6%\n",
      "\t350.0 samples test: 38.8%\n",
      "\t400.0 samples test: 38.2%\n",
      "\t450.0 samples test: 38.5%\n",
      "\t500.0 samples test: 38.2%\n",
      "\t550.0 samples test: 38.0%\n",
      "\t600.0 samples test: 38.1%\n",
      "\t650.0 samples test: 38.2%\n",
      "\t700.0 samples test: 38.3%\n",
      "\n",
      "Train accuracy: 22.5% (550 samples)\n",
      "\t50.0 samples test: 23.2%\n",
      "\t100.0 samples test: 23.0%\n",
      "\t150.0 samples test: 23.3%\n",
      "\t200.0 samples test: 23.4%\n",
      "\t250.0 samples test: 22.6%\n",
      "\t300.0 samples test: 22.9%\n",
      "\t350.0 samples test: 22.3%\n",
      "\t400.0 samples test: 22.0%\n",
      "\t450.0 samples test: 22.1%\n",
      "\t500.0 samples test: 22.3%\n",
      "\t550.0 samples test: 22.2%\n",
      "\t600.0 samples test: 22.8%\n",
      "\t650.0 samples test: 22.6%\n",
      "\t700.0 samples test: 22.6%\n",
      "\n",
      "Train accuracy: 32.8% (600 samples)\n",
      "\t50.0 samples test: 34.0%\n",
      "\t100.0 samples test: 33.8%\n",
      "\t150.0 samples test: 33.1%\n",
      "\t200.0 samples test: 32.8%\n",
      "\t250.0 samples test: 32.2%\n",
      "\t300.0 samples test: 32.6%\n",
      "\t350.0 samples test: 32.6%\n",
      "\t400.0 samples test: 33.3%\n",
      "\t450.0 samples test: 33.3%\n",
      "\t500.0 samples test: 33.0%\n",
      "\t550.0 samples test: 33.2%\n",
      "\t600.0 samples test: 33.2%\n",
      "\t650.0 samples test: 33.0%\n",
      "\t700.0 samples test: 32.7%\n",
      "\n",
      "Train accuracy: 35.2% (650 samples)\n",
      "\t50.0 samples test: 34.8%\n",
      "\t100.0 samples test: 34.8%\n",
      "\t150.0 samples test: 34.1%\n",
      "\t200.0 samples test: 32.7%\n",
      "\t250.0 samples test: 35.7%\n",
      "\t300.0 samples test: 35.1%\n",
      "\t350.0 samples test: 34.9%\n",
      "\t400.0 samples test: 35.1%\n",
      "\t450.0 samples test: 35.2%\n",
      "\t500.0 samples test: 35.1%\n",
      "\t550.0 samples test: 35.1%\n",
      "\t600.0 samples test: 34.9%\n",
      "\t650.0 samples test: 34.8%\n",
      "\t700.0 samples test: 34.9%\n",
      "\n",
      "Train accuracy: 26.9% (700 samples)\n",
      "\t50.0 samples test: 25.6%\n",
      "\t100.0 samples test: 26.0%\n",
      "\t150.0 samples test: 26.1%\n",
      "\t200.0 samples test: 26.5%\n",
      "\t250.0 samples test: 26.8%\n",
      "\t300.0 samples test: 27.2%\n",
      "\t350.0 samples test: 26.9%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 27.0%\n",
      "\t500.0 samples test: 26.6%\n",
      "\t550.0 samples test: 26.6%\n",
      "\t600.0 samples test: 26.5%\n",
      "\t650.0 samples test: 26.7%\n",
      "\t700.0 samples test: 26.9%\n"
     ]
    }
   ],
   "source": [
    "info_x_samples = [\n",
    "    (data_50_samples, target_50_samples), \n",
    "    (data_100_samples, target_100_samples),\n",
    "    (data_150_samples, target_150_samples), \n",
    "    (data_200_samples, target_200_samples), \n",
    "    (data_250_samples, target_250_samples), \n",
    "    (data_300_samples, target_300_samples), \n",
    "    (data_350_samples, target_350_samples), \n",
    "    (data_400_samples, target_400_samples), \n",
    "    (data_450_samples, target_450_samples),\n",
    "    (data_500_samples, target_500_samples), \n",
    "    (data_550_samples, target_550_samples), \n",
    "    (data_600_samples, target_600_samples), \n",
    "    (data_650_samples, target_650_samples), \n",
    "    (data_700_samples, target_700_samples)\n",
    "]\n",
    "sample_numbers = (list(range(50, 701, 50)))\n",
    "results = []\n",
    "\n",
    "def samples_test(verbose=True):\n",
    "    \n",
    "    results.append([])\n",
    "\n",
    "    for sample_number, i in zip(sample_numbers, range(14)):\n",
    "        data_x_samples = info_x_samples[i][0]\n",
    "        target_x_samples = info_x_samples[i][1]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data_x_samples = data_x_samples.reshape(data_x_samples.shape[0], -1)\n",
    "        data_x_samples = (scaler.fit_transform(data_x_samples)).reshape((data_x_samples.shape[0], 10, 10, 1))\n",
    "        \n",
    "        target_x_samples = to_categorical(target_x_samples)\n",
    "    \n",
    "        model = Model()\n",
    "    \n",
    "        model.build(input_shape=(1, 10, 10, 1))\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(data_x_samples, target_x_samples, epochs=3, batch_size=64, verbose=False)\n",
    "    \n",
    "        initial_accuracy = model.evaluate(X_train, y_train, verbose=False)[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nTrain accuracy: {initial_accuracy*100:.1f}% ({sample_number} samples)')\n",
    "        \n",
    "        if verbose:\n",
    "            for re_iter in info_x_samples:\n",
    "                data_new = re_iter[0]\n",
    "                target_new = re_iter[1]\n",
    "        \n",
    "                scaler = StandardScaler()\n",
    "        \n",
    "                data_new = data_new.reshape(data_new.shape[0], -1)\n",
    "                data_new = (scaler.fit_transform(data_new)).reshape((data_new.shape[0], 10, 10, 1))\n",
    "        \n",
    "                target_new = to_categorical(target_new)\n",
    "        \n",
    "                print(f'\\t{(data_new.shape[0])/5} samples test: {model.evaluate(data_new, target_new, verbose=False)[1]*100:.1f}%')\n",
    "        \n",
    "        results[-1].append(initial_accuracy)\n",
    "\n",
    "\n",
    "samples_test()\n",
    "for i in range(49):\n",
    "    samples_test(verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Test with Constant Test Samples (175 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "\t50.0 samples train: 16.0% test: 16.6%\n",
      "\t100.0 samples train: 19.2% test: 17.3%\n",
      "\t150.0 samples train: 22.2% test: 16.9%\n",
      "\t200.0 samples train: 20.5% test: 18.5%\n",
      "\t250.0 samples train: 22.9% test: 29.7%\n",
      "\t300.0 samples train: 19.4% test: 22.9%\n",
      "\t350.0 samples train: 31.5% test: 22.3%\n",
      "\t400.0 samples train: 9.4% test: 16.5%\n",
      "\t450.0 samples train: 21.9% test: 19.9%\n",
      "\t500.0 samples train: 24.4% test: 21.5%\n",
      "\t550.0 samples train: 29.6% test: 21.3%\n",
      "\t600.0 samples train: 28.4% test: 20.6%\n",
      "\t650.0 samples train: 28.8% test: 20.0%\n",
      "\t700.0 samples train: 22.8% test: 20.6%\n",
      "\n",
      "\n",
      "Run 2\n",
      "\t50.0 samples train: 22.5% test: 19.9%\n",
      "\t100.0 samples train: 21.6% test: 38.1%\n",
      "\t150.0 samples train: 21.0% test: 9.1%\n",
      "\t200.0 samples train: 20.4% test: 20.2%\n",
      "\t250.0 samples train: 20.1% test: 22.1%\n",
      "\t300.0 samples train: 18.0% test: 19.7%\n",
      "\t350.0 samples train: 29.0% test: 21.8%\n",
      "\t400.0 samples train: 31.3% test: 20.8%\n",
      "\t450.0 samples train: 28.5% test: 20.3%\n",
      "\t500.0 samples train: 17.3% test: 20.3%\n",
      "\t550.0 samples train: 23.2% test: 20.3%\n",
      "\t600.0 samples train: 20.0% test: 18.7%\n",
      "\t650.0 samples train: 37.6% test: 20.0%\n",
      "\t700.0 samples train: 25.4% test: 19.0%\n",
      "\n",
      "\n",
      "Run 3\n",
      "\t50.0 samples train: 17.6% test: 20.2%\n",
      "\t100.0 samples train: 35.5% test: 25.5%\n",
      "\t150.0 samples train: 20.3% test: 23.5%\n",
      "\t200.0 samples train: 28.9% test: 31.4%\n",
      "\t250.0 samples train: 34.7% test: 23.2%\n",
      "\t300.0 samples train: 19.6% test: 19.7%\n",
      "\t350.0 samples train: 31.9% test: 17.7%\n",
      "\t400.0 samples train: 27.4% test: 22.4%\n",
      "\t450.0 samples train: 23.1% test: 20.3%\n",
      "\t500.0 samples train: 26.7% test: 18.4%\n",
      "\t550.0 samples train: 32.5% test: 19.9%\n",
      "\t600.0 samples train: 23.6% test: 20.6%\n",
      "\t650.0 samples train: 17.7% test: 20.6%\n",
      "\t700.0 samples train: 31.4% test: 20.9%\n",
      "\n",
      "\n",
      "Run 4\n",
      "\t50.0 samples train: 21.9% test: 20.2%\n",
      "\t100.0 samples train: 15.5% test: 28.2%\n",
      "\t150.0 samples train: 27.9% test: 14.1%\n",
      "\t200.0 samples train: 18.8% test: 19.5%\n",
      "\t250.0 samples train: 25.4% test: 18.9%\n",
      "\t300.0 samples train: 25.3% test: 20.3%\n",
      "\t350.0 samples train: 19.7% test: 20.1%\n",
      "\t400.0 samples train: 30.1% test: 19.7%\n",
      "\t450.0 samples train: 24.7% test: 19.5%\n",
      "\t500.0 samples train: 23.8% test: 22.9%\n",
      "\t550.0 samples train: 35.2% test: 22.4%\n",
      "\t600.0 samples train: 18.1% test: 19.3%\n",
      "\t650.0 samples train: 24.7% test: 19.1%\n",
      "\t700.0 samples train: 33.0% test: 21.7%\n",
      "\n",
      "\n",
      "Run 5\n",
      "\t50.0 samples train: 20.3% test: 21.3%\n",
      "\t100.0 samples train: 22.7% test: 25.6%\n",
      "\t150.0 samples train: 24.9% test: 20.0%\n",
      "\t200.0 samples train: 31.9% test: 31.7%\n",
      "\t250.0 samples train: 24.0% test: 24.9%\n",
      "\t300.0 samples train: 18.7% test: 20.7%\n",
      "\t350.0 samples train: 22.9% test: 19.2%\n",
      "\t400.0 samples train: 22.8% test: 20.0%\n",
      "\t450.0 samples train: 30.8% test: 19.8%\n",
      "\t500.0 samples train: 26.8% test: 20.7%\n",
      "\t550.0 samples train: 20.8% test: 19.4%\n",
      "\t600.0 samples train: 18.6% test: 21.4%\n",
      "\t650.0 samples train: 35.7% test: 19.5%\n",
      "\t700.0 samples train: 30.3% test: 19.4%\n",
      "\n",
      "\n",
      "Run 6\n",
      "\t50.0 samples train: 17.1% test: 20.1%\n",
      "\t100.0 samples train: 32.3% test: 12.6%\n",
      "\t150.0 samples train: 15.8% test: 20.3%\n",
      "\t200.0 samples train: 33.5% test: 17.6%\n",
      "\t250.0 samples train: 28.5% test: 17.7%\n",
      "\t300.0 samples train: 24.0% test: 20.3%\n",
      "\t350.0 samples train: 31.7% test: 18.9%\n",
      "\t400.0 samples train: 33.5% test: 20.0%\n",
      "\t450.0 samples train: 32.4% test: 19.9%\n",
      "\t500.0 samples train: 24.9% test: 20.3%\n",
      "\t550.0 samples train: 22.6% test: 19.8%\n",
      "\t600.0 samples train: 25.1% test: 20.3%\n",
      "\t650.0 samples train: 17.0% test: 19.9%\n",
      "\t700.0 samples train: 19.6% test: 19.7%\n",
      "\n",
      "\n",
      "Run 7\n",
      "\t50.0 samples train: 15.0% test: 14.7%\n",
      "\t100.0 samples train: 28.8% test: 30.7%\n",
      "\t150.0 samples train: 21.4% test: 18.4%\n",
      "\t200.0 samples train: 20.1% test: 15.8%\n",
      "\t250.0 samples train: 16.1% test: 17.7%\n",
      "\t300.0 samples train: 16.0% test: 19.4%\n",
      "\t350.0 samples train: 24.6% test: 20.9%\n",
      "\t400.0 samples train: 22.1% test: 19.3%\n",
      "\t450.0 samples train: 25.4% test: 21.0%\n",
      "\t500.0 samples train: 29.0% test: 18.7%\n",
      "\t550.0 samples train: 31.0% test: 20.2%\n",
      "\t600.0 samples train: 39.7% test: 19.5%\n",
      "\t650.0 samples train: 33.8% test: 19.5%\n",
      "\t700.0 samples train: 38.5% test: 19.4%\n",
      "\n",
      "\n",
      "Run 8\n",
      "\t50.0 samples train: 17.6% test: 17.6%\n",
      "\t100.0 samples train: 17.1% test: 17.6%\n",
      "\t150.0 samples train: 25.1% test: 24.1%\n",
      "\t200.0 samples train: 21.6% test: 23.4%\n",
      "\t250.0 samples train: 18.7% test: 20.9%\n",
      "\t300.0 samples train: 26.3% test: 21.7%\n",
      "\t350.0 samples train: 20.3% test: 22.6%\n",
      "\t400.0 samples train: 19.3% test: 20.8%\n",
      "\t450.0 samples train: 20.7% test: 20.2%\n",
      "\t500.0 samples train: 19.4% test: 21.7%\n",
      "\t550.0 samples train: 38.1% test: 21.4%\n",
      "\t600.0 samples train: 26.8% test: 21.4%\n",
      "\t650.0 samples train: 25.2% test: 20.0%\n",
      "\t700.0 samples train: 37.2% test: 21.4%\n",
      "\n",
      "\n",
      "Run 9\n",
      "\t50.0 samples train: 26.7% test: 22.6%\n",
      "\t100.0 samples train: 22.4% test: 22.2%\n",
      "\t150.0 samples train: 24.6% test: 16.0%\n",
      "\t200.0 samples train: 22.0% test: 15.3%\n",
      "\t250.0 samples train: 26.9% test: 19.4%\n",
      "\t300.0 samples train: 28.0% test: 22.5%\n",
      "\t350.0 samples train: 25.1% test: 20.8%\n",
      "\t400.0 samples train: 23.9% test: 18.2%\n",
      "\t450.0 samples train: 36.2% test: 19.4%\n",
      "\t500.0 samples train: 27.0% test: 19.9%\n",
      "\t550.0 samples train: 25.0% test: 20.0%\n",
      "\t600.0 samples train: 24.3% test: 21.3%\n",
      "\t650.0 samples train: 41.3% test: 19.3%\n",
      "\t700.0 samples train: 22.1% test: 19.5%\n",
      "\n",
      "\n",
      "Run 10\n",
      "\t50.0 samples train: 22.5% test: 22.5%\n",
      "\t100.0 samples train: 27.7% test: 19.3%\n",
      "\t150.0 samples train: 17.3% test: 20.1%\n",
      "\t200.0 samples train: 23.6% test: 21.3%\n",
      "\t250.0 samples train: 21.7% test: 23.8%\n",
      "\t300.0 samples train: 16.6% test: 21.1%\n",
      "\t350.0 samples train: 16.5% test: 19.5%\n",
      "\t400.0 samples train: 22.9% test: 20.5%\n",
      "\t450.0 samples train: 19.0% test: 19.5%\n",
      "\t500.0 samples train: 24.6% test: 22.1%\n",
      "\t550.0 samples train: 25.2% test: 20.1%\n",
      "\t600.0 samples train: 25.8% test: 19.2%\n",
      "\t650.0 samples train: 27.8% test: 20.1%\n",
      "\t700.0 samples train: 21.5% test: 18.6%\n",
      "\n",
      "\n",
      "Run 11\n",
      "\t50.0 samples train: 18.7% test: 21.0%\n",
      "\t100.0 samples train: 17.3% test: 18.5%\n",
      "\t150.0 samples train: 21.2% test: 22.3%\n",
      "\t200.0 samples train: 28.5% test: 29.7%\n",
      "\t250.0 samples train: 18.6% test: 20.2%\n",
      "\t300.0 samples train: 33.1% test: 14.2%\n",
      "\t350.0 samples train: 29.5% test: 19.9%\n",
      "\t400.0 samples train: 30.5% test: 20.9%\n",
      "\t450.0 samples train: 21.7% test: 23.9%\n",
      "\t500.0 samples train: 29.8% test: 20.6%\n",
      "\t550.0 samples train: 28.4% test: 21.7%\n",
      "\t600.0 samples train: 39.3% test: 19.9%\n",
      "\t650.0 samples train: 32.4% test: 19.5%\n",
      "\t700.0 samples train: 29.9% test: 19.5%\n",
      "\n",
      "\n",
      "Run 12\n",
      "\t50.0 samples train: 25.1% test: 27.7%\n",
      "\t100.0 samples train: 26.9% test: 25.8%\n",
      "\t150.0 samples train: 21.4% test: 20.6%\n",
      "\t200.0 samples train: 32.3% test: 25.5%\n",
      "\t250.0 samples train: 25.9% test: 16.3%\n",
      "\t300.0 samples train: 25.0% test: 20.7%\n",
      "\t350.0 samples train: 23.9% test: 18.5%\n",
      "\t400.0 samples train: 19.9% test: 22.3%\n",
      "\t450.0 samples train: 27.1% test: 19.3%\n",
      "\t500.0 samples train: 29.2% test: 21.3%\n",
      "\t550.0 samples train: 21.9% test: 19.8%\n",
      "\t600.0 samples train: 38.6% test: 19.4%\n",
      "\t650.0 samples train: 44.4% test: 20.2%\n",
      "\t700.0 samples train: 46.6% test: 20.8%\n",
      "\n",
      "\n",
      "Run 13\n",
      "\t50.0 samples train: 19.8% test: 21.0%\n",
      "\t100.0 samples train: 30.9% test: 25.8%\n",
      "\t150.0 samples train: 21.2% test: 20.7%\n",
      "\t200.0 samples train: 26.8% test: 20.6%\n",
      "\t250.0 samples train: 25.7% test: 24.7%\n",
      "\t300.0 samples train: 34.3% test: 23.3%\n",
      "\t350.0 samples train: 15.7% test: 22.2%\n",
      "\t400.0 samples train: 36.0% test: 21.1%\n",
      "\t450.0 samples train: 32.1% test: 22.7%\n",
      "\t500.0 samples train: 21.2% test: 19.8%\n",
      "\t550.0 samples train: 28.0% test: 19.4%\n",
      "\t600.0 samples train: 31.5% test: 20.0%\n",
      "\t650.0 samples train: 28.1% test: 20.7%\n",
      "\t700.0 samples train: 20.0% test: 20.1%\n",
      "\n",
      "\n",
      "Run 14\n",
      "\t50.0 samples train: 24.6% test: 21.7%\n",
      "\t100.0 samples train: 22.7% test: 17.9%\n",
      "\t150.0 samples train: 21.4% test: 39.8%\n",
      "\t200.0 samples train: 22.3% test: 24.7%\n",
      "\t250.0 samples train: 16.1% test: 23.1%\n",
      "\t300.0 samples train: 37.7% test: 22.5%\n",
      "\t350.0 samples train: 18.1% test: 18.4%\n",
      "\t400.0 samples train: 23.6% test: 20.6%\n",
      "\t450.0 samples train: 24.5% test: 18.7%\n",
      "\t500.0 samples train: 28.9% test: 21.1%\n",
      "\t550.0 samples train: 38.7% test: 19.0%\n",
      "\t600.0 samples train: 30.4% test: 19.1%\n",
      "\t650.0 samples train: 32.6% test: 20.2%\n",
      "\t700.0 samples train: 32.1% test: 19.5%\n",
      "\n",
      "\n",
      "Run 15\n",
      "\t50.0 samples train: 18.2% test: 20.1%\n",
      "\t100.0 samples train: 18.4% test: 16.1%\n",
      "\t150.0 samples train: 18.7% test: 27.5%\n",
      "\t200.0 samples train: 27.2% test: 12.3%\n",
      "\t250.0 samples train: 22.6% test: 20.2%\n",
      "\t300.0 samples train: 37.2% test: 19.3%\n",
      "\t350.0 samples train: 26.8% test: 18.5%\n",
      "\t400.0 samples train: 20.4% test: 19.3%\n",
      "\t450.0 samples train: 31.3% test: 21.7%\n",
      "\t500.0 samples train: 19.4% test: 21.7%\n",
      "\t550.0 samples train: 38.1% test: 20.1%\n",
      "\t600.0 samples train: 20.9% test: 20.0%\n",
      "\t650.0 samples train: 35.8% test: 21.4%\n",
      "\t700.0 samples train: 22.7% test: 20.1%\n",
      "\n",
      "\n",
      "Run 16\n",
      "\t50.0 samples train: 17.6% test: 21.0%\n",
      "\t100.0 samples train: 19.5% test: 32.8%\n",
      "\t150.0 samples train: 18.3% test: 19.5%\n",
      "\t200.0 samples train: 22.1% test: 21.4%\n",
      "\t250.0 samples train: 35.1% test: 23.8%\n",
      "\t300.0 samples train: 20.7% test: 19.0%\n",
      "\t350.0 samples train: 23.1% test: 17.7%\n",
      "\t400.0 samples train: 31.5% test: 19.4%\n",
      "\t450.0 samples train: 30.3% test: 19.0%\n",
      "\t500.0 samples train: 30.4% test: 19.1%\n",
      "\t550.0 samples train: 19.5% test: 19.9%\n",
      "\t600.0 samples train: 40.7% test: 20.7%\n",
      "\t650.0 samples train: 25.3% test: 20.8%\n",
      "\t700.0 samples train: 23.8% test: 19.7%\n",
      "\n",
      "\n",
      "Run 17\n",
      "\t50.0 samples train: 21.9% test: 19.8%\n",
      "\t100.0 samples train: 17.6% test: 19.0%\n",
      "\t150.0 samples train: 28.8% test: 20.3%\n",
      "\t200.0 samples train: 18.3% test: 18.9%\n",
      "\t250.0 samples train: 22.6% test: 21.5%\n",
      "\t300.0 samples train: 24.4% test: 17.9%\n",
      "\t350.0 samples train: 27.4% test: 20.9%\n",
      "\t400.0 samples train: 30.4% test: 20.2%\n",
      "\t450.0 samples train: 26.7% test: 19.8%\n",
      "\t500.0 samples train: 31.6% test: 20.9%\n",
      "\t550.0 samples train: 24.3% test: 19.0%\n",
      "\t600.0 samples train: 24.4% test: 20.0%\n",
      "\t650.0 samples train: 32.2% test: 19.7%\n",
      "\t700.0 samples train: 30.3% test: 19.1%\n",
      "\n",
      "\n",
      "Run 18\n",
      "\t50.0 samples train: 15.0% test: 16.7%\n",
      "\t100.0 samples train: 13.9% test: 12.7%\n",
      "\t150.0 samples train: 25.1% test: 25.0%\n",
      "\t200.0 samples train: 20.8% test: 22.3%\n",
      "\t250.0 samples train: 29.8% test: 26.6%\n",
      "\t300.0 samples train: 31.1% test: 21.9%\n",
      "\t350.0 samples train: 35.1% test: 19.2%\n",
      "\t400.0 samples train: 23.1% test: 23.1%\n",
      "\t450.0 samples train: 30.7% test: 19.2%\n",
      "\t500.0 samples train: 31.1% test: 18.9%\n",
      "\t550.0 samples train: 32.3% test: 19.7%\n",
      "\t600.0 samples train: 28.2% test: 20.0%\n",
      "\t650.0 samples train: 36.1% test: 20.9%\n",
      "\t700.0 samples train: 19.2% test: 19.0%\n",
      "\n",
      "\n",
      "Run 19\n",
      "\t50.0 samples train: 26.7% test: 25.3%\n",
      "\t100.0 samples train: 22.7% test: 18.6%\n",
      "\t150.0 samples train: 25.6% test: 17.7%\n",
      "\t200.0 samples train: 18.8% test: 18.9%\n",
      "\t250.0 samples train: 21.2% test: 18.5%\n",
      "\t300.0 samples train: 26.2% test: 24.9%\n",
      "\t350.0 samples train: 26.1% test: 20.0%\n",
      "\t400.0 samples train: 26.2% test: 19.9%\n",
      "\t450.0 samples train: 34.8% test: 19.7%\n",
      "\t500.0 samples train: 25.7% test: 19.9%\n",
      "\t550.0 samples train: 29.5% test: 19.3%\n",
      "\t600.0 samples train: 19.2% test: 20.0%\n",
      "\t650.0 samples train: 30.3% test: 19.8%\n",
      "\t700.0 samples train: 23.1% test: 21.6%\n",
      "\n",
      "\n",
      "Run 20\n",
      "\t50.0 samples train: 19.8% test: 17.5%\n",
      "\t100.0 samples train: 27.2% test: 21.7%\n",
      "\t150.0 samples train: 21.7% test: 20.1%\n",
      "\t200.0 samples train: 16.0% test: 17.4%\n",
      "\t250.0 samples train: 23.3% test: 21.6%\n",
      "\t300.0 samples train: 16.4% test: 21.9%\n",
      "\t350.0 samples train: 20.0% test: 19.2%\n",
      "\t400.0 samples train: 25.3% test: 21.4%\n",
      "\t450.0 samples train: 24.7% test: 19.3%\n",
      "\t500.0 samples train: 27.4% test: 19.9%\n",
      "\t550.0 samples train: 34.0% test: 19.0%\n",
      "\t600.0 samples train: 22.5% test: 21.1%\n",
      "\t650.0 samples train: 36.8% test: 20.5%\n",
      "\t700.0 samples train: 32.3% test: 20.7%\n",
      "\n",
      "\n",
      "Run 21\n",
      "\t50.0 samples train: 17.6% test: 17.8%\n",
      "\t100.0 samples train: 18.4% test: 19.9%\n",
      "\t150.0 samples train: 18.0% test: 15.9%\n",
      "\t200.0 samples train: 25.5% test: 22.2%\n",
      "\t250.0 samples train: 34.3% test: 24.9%\n",
      "\t300.0 samples train: 21.2% test: 20.9%\n",
      "\t350.0 samples train: 18.9% test: 18.9%\n",
      "\t400.0 samples train: 38.6% test: 21.4%\n",
      "\t450.0 samples train: 20.6% test: 21.8%\n",
      "\t500.0 samples train: 30.2% test: 21.4%\n",
      "\t550.0 samples train: 29.0% test: 19.9%\n",
      "\t600.0 samples train: 38.3% test: 20.7%\n",
      "\t650.0 samples train: 34.0% test: 19.1%\n",
      "\t700.0 samples train: 35.1% test: 20.6%\n",
      "\n",
      "\n",
      "Run 22\n",
      "\t50.0 samples train: 18.7% test: 21.4%\n",
      "\t100.0 samples train: 21.6% test: 19.8%\n",
      "\t150.0 samples train: 15.3% test: 12.0%\n",
      "\t200.0 samples train: 19.6% test: 19.7%\n",
      "\t250.0 samples train: 19.6% test: 20.5%\n",
      "\t300.0 samples train: 22.2% test: 19.1%\n",
      "\t350.0 samples train: 21.2% test: 19.3%\n",
      "\t400.0 samples train: 27.7% test: 17.6%\n",
      "\t450.0 samples train: 39.1% test: 21.7%\n",
      "\t500.0 samples train: 20.6% test: 18.9%\n",
      "\t550.0 samples train: 35.1% test: 19.3%\n",
      "\t600.0 samples train: 36.8% test: 19.1%\n",
      "\t650.0 samples train: 30.9% test: 20.7%\n",
      "\t700.0 samples train: 32.4% test: 19.1%\n",
      "\n",
      "\n",
      "Run 23\n",
      "\t50.0 samples train: 25.7% test: 23.8%\n",
      "\t100.0 samples train: 32.3% test: 19.2%\n",
      "\t150.0 samples train: 21.4% test: 13.7%\n",
      "\t200.0 samples train: 28.8% test: 19.2%\n",
      "\t250.0 samples train: 17.5% test: 26.1%\n",
      "\t300.0 samples train: 31.8% test: 20.7%\n",
      "\t350.0 samples train: 33.3% test: 18.2%\n",
      "\t400.0 samples train: 27.3% test: 19.1%\n",
      "\t450.0 samples train: 19.7% test: 20.7%\n",
      "\t500.0 samples train: 35.0% test: 19.8%\n",
      "\t550.0 samples train: 22.5% test: 19.7%\n",
      "\t600.0 samples train: 36.8% test: 19.9%\n",
      "\t650.0 samples train: 39.5% test: 20.8%\n",
      "\t700.0 samples train: 23.5% test: 20.2%\n",
      "\n",
      "\n",
      "Run 24\n",
      "\t50.0 samples train: 19.8% test: 20.2%\n",
      "\t100.0 samples train: 17.3% test: 21.6%\n",
      "\t150.0 samples train: 17.4% test: 16.3%\n",
      "\t200.0 samples train: 14.5% test: 21.0%\n",
      "\t250.0 samples train: 30.1% test: 20.7%\n",
      "\t300.0 samples train: 27.2% test: 20.5%\n",
      "\t350.0 samples train: 32.7% test: 23.8%\n",
      "\t400.0 samples train: 30.7% test: 20.0%\n",
      "\t450.0 samples train: 30.6% test: 22.3%\n",
      "\t500.0 samples train: 22.7% test: 21.9%\n",
      "\t550.0 samples train: 33.9% test: 21.0%\n",
      "\t600.0 samples train: 21.4% test: 19.4%\n",
      "\t650.0 samples train: 34.7% test: 21.0%\n",
      "\t700.0 samples train: 31.4% test: 21.6%\n",
      "\n",
      "\n",
      "Run 25\n",
      "\t50.0 samples train: 26.7% test: 25.7%\n",
      "\t100.0 samples train: 19.7% test: 25.1%\n",
      "\t150.0 samples train: 24.0% test: 23.5%\n",
      "\t200.0 samples train: 17.7% test: 17.0%\n",
      "\t250.0 samples train: 20.3% test: 22.4%\n",
      "\t300.0 samples train: 29.5% test: 19.4%\n",
      "\t350.0 samples train: 27.4% test: 19.0%\n",
      "\t400.0 samples train: 34.6% test: 17.4%\n",
      "\t450.0 samples train: 33.0% test: 23.1%\n",
      "\t500.0 samples train: 24.8% test: 18.9%\n",
      "\t550.0 samples train: 16.3% test: 21.7%\n",
      "\t600.0 samples train: 32.4% test: 21.0%\n",
      "\t650.0 samples train: 22.1% test: 18.6%\n",
      "\t700.0 samples train: 26.3% test: 20.6%\n",
      "\n",
      "\n",
      "Run 26\n",
      "\t50.0 samples train: 26.2% test: 22.2%\n",
      "\t100.0 samples train: 20.8% test: 24.0%\n",
      "\t150.0 samples train: 23.5% test: 17.4%\n",
      "\t200.0 samples train: 33.7% test: 24.3%\n",
      "\t250.0 samples train: 33.9% test: 21.8%\n",
      "\t300.0 samples train: 18.0% test: 19.2%\n",
      "\t350.0 samples train: 16.5% test: 23.8%\n",
      "\t400.0 samples train: 31.5% test: 19.2%\n",
      "\t450.0 samples train: 30.1% test: 21.0%\n",
      "\t500.0 samples train: 37.6% test: 20.2%\n",
      "\t550.0 samples train: 21.4% test: 20.6%\n",
      "\t600.0 samples train: 21.2% test: 18.6%\n",
      "\t650.0 samples train: 32.8% test: 20.2%\n",
      "\t700.0 samples train: 34.7% test: 20.1%\n",
      "\n",
      "\n",
      "Run 27\n",
      "\t50.0 samples train: 16.0% test: 14.6%\n",
      "\t100.0 samples train: 26.1% test: 19.4%\n",
      "\t150.0 samples train: 10.5% test: 21.8%\n",
      "\t200.0 samples train: 28.5% test: 24.7%\n",
      "\t250.0 samples train: 24.3% test: 21.1%\n",
      "\t300.0 samples train: 21.2% test: 20.7%\n",
      "\t350.0 samples train: 20.7% test: 21.6%\n",
      "\t400.0 samples train: 24.4% test: 18.9%\n",
      "\t450.0 samples train: 21.2% test: 19.1%\n",
      "\t500.0 samples train: 30.0% test: 21.3%\n",
      "\t550.0 samples train: 37.8% test: 19.5%\n",
      "\t600.0 samples train: 28.8% test: 20.9%\n",
      "\t650.0 samples train: 35.8% test: 20.2%\n",
      "\t700.0 samples train: 28.5% test: 20.0%\n",
      "\n",
      "\n",
      "Run 28\n",
      "\t50.0 samples train: 29.4% test: 31.8%\n",
      "\t100.0 samples train: 30.4% test: 19.8%\n",
      "\t150.0 samples train: 27.8% test: 17.0%\n",
      "\t200.0 samples train: 40.8% test: 19.3%\n",
      "\t250.0 samples train: 18.4% test: 25.1%\n",
      "\t300.0 samples train: 24.2% test: 17.4%\n",
      "\t350.0 samples train: 32.2% test: 18.9%\n",
      "\t400.0 samples train: 22.7% test: 19.2%\n",
      "\t450.0 samples train: 27.9% test: 18.3%\n",
      "\t500.0 samples train: 27.0% test: 19.0%\n",
      "\t550.0 samples train: 24.7% test: 20.1%\n",
      "\t600.0 samples train: 26.3% test: 19.3%\n",
      "\t650.0 samples train: 44.6% test: 20.3%\n",
      "\t700.0 samples train: 30.3% test: 20.8%\n",
      "\n",
      "\n",
      "Run 29\n",
      "\t50.0 samples train: 29.4% test: 27.0%\n",
      "\t100.0 samples train: 27.5% test: 13.0%\n",
      "\t150.0 samples train: 19.4% test: 16.5%\n",
      "\t200.0 samples train: 27.9% test: 19.7%\n",
      "\t250.0 samples train: 25.9% test: 29.0%\n",
      "\t300.0 samples train: 38.3% test: 18.3%\n",
      "\t350.0 samples train: 29.7% test: 19.2%\n",
      "\t400.0 samples train: 35.5% test: 22.1%\n",
      "\t450.0 samples train: 24.5% test: 21.3%\n",
      "\t500.0 samples train: 18.6% test: 22.7%\n",
      "\t550.0 samples train: 40.3% test: 20.3%\n",
      "\t600.0 samples train: 27.2% test: 19.0%\n",
      "\t650.0 samples train: 27.2% test: 21.6%\n",
      "\t700.0 samples train: 35.8% test: 19.8%\n",
      "\n",
      "\n",
      "Run 30\n",
      "\t50.0 samples train: 13.4% test: 15.4%\n",
      "\t100.0 samples train: 16.3% test: 18.3%\n",
      "\t150.0 samples train: 19.6% test: 20.5%\n",
      "\t200.0 samples train: 26.5% test: 21.1%\n",
      "\t250.0 samples train: 28.9% test: 21.9%\n",
      "\t300.0 samples train: 22.4% test: 22.9%\n",
      "\t350.0 samples train: 25.7% test: 20.9%\n",
      "\t400.0 samples train: 31.5% test: 21.5%\n",
      "\t450.0 samples train: 27.6% test: 19.1%\n",
      "\t500.0 samples train: 23.2% test: 20.5%\n",
      "\t550.0 samples train: 30.2% test: 19.4%\n",
      "\t600.0 samples train: 29.1% test: 21.6%\n",
      "\t650.0 samples train: 45.4% test: 20.1%\n",
      "\t700.0 samples train: 26.0% test: 20.3%\n",
      "\n",
      "\n",
      "Run 31\n",
      "\t50.0 samples train: 25.7% test: 25.8%\n",
      "\t100.0 samples train: 34.9% test: 24.5%\n",
      "\t150.0 samples train: 24.0% test: 27.1%\n",
      "\t200.0 samples train: 22.9% test: 16.1%\n",
      "\t250.0 samples train: 22.3% test: 21.0%\n",
      "\t300.0 samples train: 26.7% test: 18.4%\n",
      "\t350.0 samples train: 22.1% test: 24.3%\n",
      "\t400.0 samples train: 29.7% test: 26.1%\n",
      "\t450.0 samples train: 34.4% test: 18.4%\n",
      "\t500.0 samples train: 27.1% test: 20.2%\n",
      "\t550.0 samples train: 39.7% test: 21.0%\n",
      "\t600.0 samples train: 19.5% test: 19.5%\n",
      "\t650.0 samples train: 31.4% test: 20.9%\n",
      "\t700.0 samples train: 33.4% test: 21.0%\n",
      "\n",
      "\n",
      "Run 32\n",
      "\t50.0 samples train: 16.0% test: 17.8%\n",
      "\t100.0 samples train: 23.2% test: 19.1%\n",
      "\t150.0 samples train: 19.0% test: 21.6%\n",
      "\t200.0 samples train: 27.5% test: 23.0%\n",
      "\t250.0 samples train: 21.6% test: 17.3%\n",
      "\t300.0 samples train: 27.5% test: 25.5%\n",
      "\t350.0 samples train: 24.9% test: 20.2%\n",
      "\t400.0 samples train: 16.1% test: 21.0%\n",
      "\t450.0 samples train: 13.5% test: 19.4%\n",
      "\t500.0 samples train: 21.5% test: 21.0%\n",
      "\t550.0 samples train: 32.5% test: 20.9%\n",
      "\t600.0 samples train: 40.4% test: 20.8%\n",
      "\t650.0 samples train: 33.2% test: 21.3%\n",
      "\t700.0 samples train: 36.8% test: 19.9%\n",
      "\n",
      "\n",
      "Run 33\n",
      "\t50.0 samples train: 15.5% test: 13.6%\n",
      "\t100.0 samples train: 24.5% test: 25.0%\n",
      "\t150.0 samples train: 23.5% test: 28.9%\n",
      "\t200.0 samples train: 27.5% test: 19.2%\n",
      "\t250.0 samples train: 29.6% test: 20.6%\n",
      "\t300.0 samples train: 29.5% test: 18.4%\n",
      "\t350.0 samples train: 20.8% test: 20.1%\n",
      "\t400.0 samples train: 16.6% test: 19.0%\n",
      "\t450.0 samples train: 23.2% test: 22.7%\n",
      "\t500.0 samples train: 33.2% test: 20.9%\n",
      "\t550.0 samples train: 22.5% test: 20.0%\n",
      "\t600.0 samples train: 27.1% test: 20.0%\n",
      "\t650.0 samples train: 36.7% test: 19.8%\n",
      "\t700.0 samples train: 18.8% test: 19.8%\n",
      "\n",
      "\n",
      "Run 34\n",
      "\t50.0 samples train: 16.0% test: 19.8%\n",
      "\t100.0 samples train: 18.9% test: 20.0%\n",
      "\t150.0 samples train: 23.5% test: 20.7%\n",
      "\t200.0 samples train: 21.1% test: 22.4%\n",
      "\t250.0 samples train: 18.9% test: 22.5%\n",
      "\t300.0 samples train: 20.1% test: 27.0%\n",
      "\t350.0 samples train: 31.3% test: 19.5%\n",
      "\t400.0 samples train: 36.9% test: 16.7%\n",
      "\t450.0 samples train: 25.4% test: 22.7%\n",
      "\t500.0 samples train: 30.7% test: 18.9%\n",
      "\t550.0 samples train: 20.8% test: 19.7%\n",
      "\t600.0 samples train: 28.6% test: 19.7%\n",
      "\t650.0 samples train: 31.7% test: 20.2%\n",
      "\t700.0 samples train: 21.1% test: 20.2%\n",
      "\n",
      "\n",
      "Run 35\n",
      "\t50.0 samples train: 19.8% test: 17.9%\n",
      "\t100.0 samples train: 14.7% test: 16.3%\n",
      "\t150.0 samples train: 19.9% test: 19.1%\n",
      "\t200.0 samples train: 17.2% test: 18.9%\n",
      "\t250.0 samples train: 19.1% test: 25.1%\n",
      "\t300.0 samples train: 20.6% test: 22.9%\n",
      "\t350.0 samples train: 38.9% test: 22.6%\n",
      "\t400.0 samples train: 23.2% test: 18.1%\n",
      "\t450.0 samples train: 32.4% test: 23.7%\n",
      "\t500.0 samples train: 20.7% test: 20.9%\n",
      "\t550.0 samples train: 21.9% test: 19.7%\n",
      "\t600.0 samples train: 43.4% test: 19.4%\n",
      "\t650.0 samples train: 33.8% test: 19.9%\n",
      "\t700.0 samples train: 27.5% test: 20.8%\n",
      "\n",
      "\n",
      "Run 36\n",
      "\t50.0 samples train: 17.1% test: 15.1%\n",
      "\t100.0 samples train: 25.3% test: 12.7%\n",
      "\t150.0 samples train: 23.8% test: 14.1%\n",
      "\t200.0 samples train: 24.5% test: 28.7%\n",
      "\t250.0 samples train: 26.4% test: 20.0%\n",
      "\t300.0 samples train: 27.6% test: 22.9%\n",
      "\t350.0 samples train: 21.0% test: 22.5%\n",
      "\t400.0 samples train: 18.3% test: 19.8%\n",
      "\t450.0 samples train: 20.0% test: 19.0%\n",
      "\t500.0 samples train: 20.5% test: 19.2%\n",
      "\t550.0 samples train: 20.8% test: 19.9%\n",
      "\t600.0 samples train: 29.9% test: 19.4%\n",
      "\t650.0 samples train: 40.3% test: 20.8%\n",
      "\t700.0 samples train: 20.4% test: 20.7%\n",
      "\n",
      "\n",
      "Run 37\n",
      "\t50.0 samples train: 14.4% test: 14.7%\n",
      "\t100.0 samples train: 20.5% test: 24.7%\n",
      "\t150.0 samples train: 20.3% test: 31.3%\n",
      "\t200.0 samples train: 25.9% test: 34.1%\n",
      "\t250.0 samples train: 21.8% test: 20.2%\n",
      "\t300.0 samples train: 29.2% test: 20.6%\n",
      "\t350.0 samples train: 26.6% test: 21.4%\n",
      "\t400.0 samples train: 30.6% test: 20.1%\n",
      "\t450.0 samples train: 26.6% test: 19.1%\n",
      "\t500.0 samples train: 30.1% test: 19.4%\n",
      "\t550.0 samples train: 19.1% test: 20.3%\n",
      "\t600.0 samples train: 30.5% test: 20.0%\n",
      "\t650.0 samples train: 34.1% test: 19.4%\n",
      "\t700.0 samples train: 33.8% test: 20.1%\n",
      "\n",
      "\n",
      "Run 38\n",
      "\t50.0 samples train: 21.4% test: 23.2%\n",
      "\t100.0 samples train: 20.0% test: 21.4%\n",
      "\t150.0 samples train: 18.3% test: 17.3%\n",
      "\t200.0 samples train: 19.6% test: 20.7%\n",
      "\t250.0 samples train: 18.8% test: 21.5%\n",
      "\t300.0 samples train: 19.8% test: 18.1%\n",
      "\t350.0 samples train: 33.8% test: 21.0%\n",
      "\t400.0 samples train: 15.9% test: 21.3%\n",
      "\t450.0 samples train: 34.5% test: 20.5%\n",
      "\t500.0 samples train: 18.6% test: 20.7%\n",
      "\t550.0 samples train: 28.8% test: 19.3%\n",
      "\t600.0 samples train: 30.2% test: 21.5%\n",
      "\t650.0 samples train: 32.1% test: 20.8%\n",
      "\t700.0 samples train: 23.6% test: 20.1%\n",
      "\n",
      "\n",
      "Run 39\n",
      "\t50.0 samples train: 13.9% test: 14.3%\n",
      "\t100.0 samples train: 25.6% test: 22.7%\n",
      "\t150.0 samples train: 26.7% test: 20.7%\n",
      "\t200.0 samples train: 22.7% test: 23.3%\n",
      "\t250.0 samples train: 35.1% test: 20.1%\n",
      "\t300.0 samples train: 20.0% test: 17.3%\n",
      "\t350.0 samples train: 17.7% test: 18.3%\n",
      "\t400.0 samples train: 21.5% test: 19.2%\n",
      "\t450.0 samples train: 26.7% test: 22.1%\n",
      "\t500.0 samples train: 31.0% test: 20.5%\n",
      "\t550.0 samples train: 16.8% test: 19.4%\n",
      "\t600.0 samples train: 23.5% test: 19.3%\n",
      "\t650.0 samples train: 35.5% test: 20.0%\n",
      "\t700.0 samples train: 24.9% test: 19.7%\n",
      "\n",
      "\n",
      "Run 40\n",
      "\t50.0 samples train: 24.6% test: 27.2%\n",
      "\t100.0 samples train: 20.8% test: 26.1%\n",
      "\t150.0 samples train: 26.2% test: 23.1%\n",
      "\t200.0 samples train: 17.6% test: 21.8%\n",
      "\t250.0 samples train: 21.7% test: 20.9%\n",
      "\t300.0 samples train: 31.3% test: 19.4%\n",
      "\t350.0 samples train: 23.9% test: 19.7%\n",
      "\t400.0 samples train: 23.3% test: 20.9%\n",
      "\t450.0 samples train: 35.0% test: 19.4%\n",
      "\t500.0 samples train: 27.4% test: 21.0%\n",
      "\t550.0 samples train: 26.2% test: 19.8%\n",
      "\t600.0 samples train: 28.0% test: 19.7%\n",
      "\t650.0 samples train: 50.1% test: 19.3%\n",
      "\t700.0 samples train: 28.8% test: 19.8%\n",
      "\n",
      "\n",
      "Run 41\n",
      "\t50.0 samples train: 16.0% test: 15.7%\n",
      "\t100.0 samples train: 12.5% test: 18.5%\n",
      "\t150.0 samples train: 23.3% test: 21.4%\n",
      "\t200.0 samples train: 20.7% test: 18.6%\n",
      "\t250.0 samples train: 20.1% test: 17.7%\n",
      "\t300.0 samples train: 23.7% test: 23.0%\n",
      "\t350.0 samples train: 27.1% test: 17.6%\n",
      "\t400.0 samples train: 19.7% test: 20.0%\n",
      "\t450.0 samples train: 19.1% test: 23.3%\n",
      "\t500.0 samples train: 24.3% test: 19.8%\n",
      "\t550.0 samples train: 27.1% test: 18.6%\n",
      "\t600.0 samples train: 31.7% test: 19.9%\n",
      "\t650.0 samples train: 30.8% test: 20.7%\n",
      "\t700.0 samples train: 26.2% test: 20.8%\n",
      "\n",
      "\n",
      "Run 42\n",
      "\t50.0 samples train: 18.7% test: 19.3%\n",
      "\t100.0 samples train: 18.9% test: 24.7%\n",
      "\t150.0 samples train: 30.6% test: 20.0%\n",
      "\t200.0 samples train: 22.1% test: 19.9%\n",
      "\t250.0 samples train: 22.5% test: 23.1%\n",
      "\t300.0 samples train: 31.2% test: 18.6%\n",
      "\t350.0 samples train: 15.2% test: 19.9%\n",
      "\t400.0 samples train: 26.2% test: 22.3%\n",
      "\t450.0 samples train: 22.6% test: 20.7%\n",
      "\t500.0 samples train: 23.2% test: 22.1%\n",
      "\t550.0 samples train: 20.7% test: 19.3%\n",
      "\t600.0 samples train: 29.3% test: 21.6%\n",
      "\t650.0 samples train: 26.5% test: 19.5%\n",
      "\t700.0 samples train: 25.6% test: 20.3%\n",
      "\n",
      "\n",
      "Run 43\n",
      "\t50.0 samples train: 19.3% test: 18.5%\n",
      "\t100.0 samples train: 18.1% test: 18.5%\n",
      "\t150.0 samples train: 22.1% test: 23.1%\n",
      "\t200.0 samples train: 17.2% test: 18.6%\n",
      "\t250.0 samples train: 20.2% test: 18.3%\n",
      "\t300.0 samples train: 15.6% test: 22.2%\n",
      "\t350.0 samples train: 38.5% test: 23.0%\n",
      "\t400.0 samples train: 31.3% test: 19.5%\n",
      "\t450.0 samples train: 32.4% test: 20.0%\n",
      "\t500.0 samples train: 19.0% test: 18.5%\n",
      "\t550.0 samples train: 27.1% test: 19.8%\n",
      "\t600.0 samples train: 36.7% test: 19.9%\n",
      "\t650.0 samples train: 25.9% test: 20.3%\n",
      "\t700.0 samples train: 29.1% test: 20.2%\n",
      "\n",
      "\n",
      "Run 44\n",
      "\t50.0 samples train: 15.5% test: 19.3%\n",
      "\t100.0 samples train: 21.9% test: 16.8%\n",
      "\t150.0 samples train: 21.9% test: 19.3%\n",
      "\t200.0 samples train: 17.7% test: 18.9%\n",
      "\t250.0 samples train: 17.8% test: 18.4%\n",
      "\t300.0 samples train: 21.3% test: 18.7%\n",
      "\t350.0 samples train: 36.6% test: 19.1%\n",
      "\t400.0 samples train: 24.1% test: 21.6%\n",
      "\t450.0 samples train: 28.6% test: 19.9%\n",
      "\t500.0 samples train: 38.7% test: 20.5%\n",
      "\t550.0 samples train: 28.9% test: 19.0%\n",
      "\t600.0 samples train: 28.1% test: 19.8%\n",
      "\t650.0 samples train: 23.6% test: 20.9%\n",
      "\t700.0 samples train: 30.9% test: 19.9%\n",
      "\n",
      "\n",
      "Run 45\n",
      "\t50.0 samples train: 22.5% test: 20.5%\n",
      "\t100.0 samples train: 16.8% test: 14.6%\n",
      "\t150.0 samples train: 25.6% test: 19.2%\n",
      "\t200.0 samples train: 17.7% test: 19.7%\n",
      "\t250.0 samples train: 20.0% test: 19.0%\n",
      "\t300.0 samples train: 30.4% test: 19.2%\n",
      "\t350.0 samples train: 23.1% test: 19.8%\n",
      "\t400.0 samples train: 27.7% test: 20.2%\n",
      "\t450.0 samples train: 31.9% test: 20.7%\n",
      "\t500.0 samples train: 26.0% test: 21.4%\n",
      "\t550.0 samples train: 32.8% test: 21.1%\n",
      "\t600.0 samples train: 23.5% test: 18.7%\n",
      "\t650.0 samples train: 37.9% test: 20.5%\n",
      "\t700.0 samples train: 30.9% test: 21.6%\n",
      "\n",
      "\n",
      "Run 46\n",
      "\t50.0 samples train: 20.3% test: 29.3%\n",
      "\t100.0 samples train: 26.4% test: 16.0%\n",
      "\t150.0 samples train: 20.6% test: 20.6%\n",
      "\t200.0 samples train: 20.4% test: 21.8%\n",
      "\t250.0 samples train: 30.9% test: 15.1%\n",
      "\t300.0 samples train: 31.1% test: 19.4%\n",
      "\t350.0 samples train: 21.1% test: 23.7%\n",
      "\t400.0 samples train: 29.0% test: 18.5%\n",
      "\t450.0 samples train: 14.9% test: 20.7%\n",
      "\t500.0 samples train: 24.1% test: 20.5%\n",
      "\t550.0 samples train: 33.2% test: 20.6%\n",
      "\t600.0 samples train: 22.4% test: 20.1%\n",
      "\t650.0 samples train: 36.8% test: 20.7%\n",
      "\t700.0 samples train: 39.4% test: 21.0%\n",
      "\n",
      "\n",
      "Run 47\n",
      "\t50.0 samples train: 29.9% test: 34.2%\n",
      "\t100.0 samples train: 22.1% test: 14.2%\n",
      "\t150.0 samples train: 20.1% test: 28.0%\n",
      "\t200.0 samples train: 16.9% test: 30.6%\n",
      "\t250.0 samples train: 12.2% test: 17.6%\n",
      "\t300.0 samples train: 21.2% test: 18.3%\n",
      "\t350.0 samples train: 21.4% test: 19.9%\n",
      "\t400.0 samples train: 26.5% test: 22.5%\n",
      "\t450.0 samples train: 23.5% test: 21.8%\n",
      "\t500.0 samples train: 28.7% test: 20.0%\n",
      "\t550.0 samples train: 22.5% test: 23.0%\n",
      "\t600.0 samples train: 20.0% test: 18.4%\n",
      "\t650.0 samples train: 20.5% test: 21.5%\n",
      "\t700.0 samples train: 36.4% test: 20.8%\n",
      "\n",
      "\n",
      "Run 48\n",
      "\t50.0 samples train: 21.4% test: 22.9%\n",
      "\t100.0 samples train: 17.3% test: 28.8%\n",
      "\t150.0 samples train: 26.2% test: 20.9%\n",
      "\t200.0 samples train: 15.2% test: 23.2%\n",
      "\t250.0 samples train: 32.2% test: 18.3%\n",
      "\t300.0 samples train: 19.5% test: 20.1%\n",
      "\t350.0 samples train: 20.6% test: 22.1%\n",
      "\t400.0 samples train: 18.5% test: 20.1%\n",
      "\t450.0 samples train: 26.9% test: 21.3%\n",
      "\t500.0 samples train: 32.8% test: 18.5%\n",
      "\t550.0 samples train: 25.2% test: 20.5%\n",
      "\t600.0 samples train: 27.2% test: 19.8%\n",
      "\t650.0 samples train: 40.0% test: 19.3%\n",
      "\t700.0 samples train: 34.2% test: 20.0%\n",
      "\n",
      "\n",
      "Run 49\n",
      "\t50.0 samples train: 26.7% test: 21.7%\n",
      "\t100.0 samples train: 21.1% test: 19.7%\n",
      "\t150.0 samples train: 28.3% test: 22.6%\n",
      "\t200.0 samples train: 30.5% test: 23.0%\n",
      "\t250.0 samples train: 22.3% test: 23.0%\n",
      "\t300.0 samples train: 29.6% test: 25.7%\n",
      "\t350.0 samples train: 29.8% test: 22.6%\n",
      "\t400.0 samples train: 22.1% test: 22.3%\n",
      "\t450.0 samples train: 36.5% test: 18.9%\n",
      "\t500.0 samples train: 22.9% test: 22.3%\n",
      "\t550.0 samples train: 22.8% test: 20.2%\n",
      "\t600.0 samples train: 29.8% test: 21.0%\n",
      "\t650.0 samples train: 30.7% test: 21.4%\n",
      "\t700.0 samples train: 25.8% test: 20.2%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_x_samples = [\n",
    "    (data_50_samples, target_50_samples), \n",
    "    (data_100_samples, target_100_samples),\n",
    "    (data_150_samples, target_150_samples), \n",
    "    (data_200_samples, target_200_samples), \n",
    "    (data_250_samples, target_250_samples), \n",
    "    (data_300_samples, target_300_samples), \n",
    "    (data_350_samples, target_350_samples), \n",
    "    (data_400_samples, target_400_samples), \n",
    "    (data_450_samples, target_450_samples),\n",
    "    (data_500_samples, target_500_samples), \n",
    "    (data_550_samples, target_550_samples), \n",
    "    (data_600_samples, target_600_samples), \n",
    "    (data_650_samples, target_650_samples), \n",
    "    (data_700_samples, target_700_samples)\n",
    "]\n",
    "sample_numbers = (list(range(50, 701, 50)))\n",
    "results = []\n",
    "\n",
    "def samples_test(verbose=True):\n",
    "\n",
    "    dummy, static_X_test, dummy, static_y_test = train_test_split(data_700_samples, target_700_samples, stratify=target_700_samples)\n",
    "    \n",
    "    results.append([])\n",
    "\n",
    "    for sample_number, i in zip(sample_numbers, range(14)):\n",
    "        data_x_samples = info_x_samples[i][0]\n",
    "        target_x_samples = info_x_samples[i][1]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data_x_samples = data_x_samples.reshape(data_x_samples.shape[0], -1)\n",
    "        data_x_samples = (scaler.fit_transform(data_x_samples)).reshape((data_x_samples.shape[0], 10, 10, 1))\n",
    "        \n",
    "        target_x_samples = to_categorical(target_x_samples)\n",
    "\n",
    "        split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data_x_samples, target_x_samples, stratify=target_x_samples)\n",
    "\n",
    "        model = Model()\n",
    "    \n",
    "        model.build(input_shape=(1, 10, 10, 1))\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(split_X_train, split_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "    \n",
    "        train_accuracy = model.evaluate(split_X_train, split_y_train, verbose=False)[1]\n",
    "\n",
    "        static_X_test = static_X_test.reshape(static_X_test.shape[0], -1)\n",
    "        static_X_test = (scaler.transform(static_X_test)).reshape((static_X_test.shape[0], 10, 10, 1))\n",
    "\n",
    "        test_accuracy = model.evaluate(static_X_test, to_categorical(static_y_test), verbose=False)[1]\n",
    "        \n",
    "        print(f'\\t{(data_x_samples.shape[0])/5} samples train: {train_accuracy*100:.1f}% test: {test_accuracy*100:.1f}%')\n",
    "\n",
    "        results[-1].append(test_accuracy)\n",
    "\n",
    "for i in range(49):\n",
    "    print(f\"Run {i+1}\")\n",
    "    samples_test(verbose=False)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare CSV for R Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "df = pd.DataFrame(results, columns=[f'{num} samples' for num in range(50, 701, 50)])\n",
    "df.to_csv('R Data Analysis/data/samples_test_175_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total dataset test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data.shape: (1259300, 10, 10)\n",
      "original target.shape: (1259300,)\n",
      "\n",
      "electron.shape: (3150, 10, 10), (3150,)\n",
      "muon.shape: (700, 10, 10), (700,)\n",
      "pion.shape: (981050, 10, 10), (981050,)\n",
      "kaon.shape: (160300, 10, 10), (160300,)\n",
      "proton.shape: (114100, 10, 10), (114100,)\n",
      "\n",
      "X_train.shape: (944475, 10, 10, 1)\n",
      "y_train.shape: (944475, 5)\n",
      "X_test.shape: (314825, 10, 10, 1)\n",
      "y_test.shape: (314825, 5)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we evaluate the models accuracies on the dataset without limit of 700 per class.\n",
    "# However, first we must setup the data, as shown in the top of the notebook.\n",
    "\n",
    "data_total = []\n",
    "target_total = []\n",
    "\n",
    "for file in files:\n",
    "    file = open(f'data/{files[0]}', 'rb')\n",
    "    file = pickle.load(file)\n",
    "\n",
    "    for sample, sample_target in zip(file[0], file[1]):\n",
    "        data_total.append(sample)\n",
    "        target_total.append(sample_target)\n",
    "\n",
    "data_total = np.array(data_total)\n",
    "target_total = np.array(target_total)\n",
    "\n",
    "sleep(7)\n",
    "clear_output()\n",
    "\n",
    "print(f'original data.shape: {data_total.shape}')\n",
    "print(f'original target.shape: {target_total.shape}\\n')\n",
    "\n",
    "# Edit target values to 0, 1, 2...\n",
    "new_target = []\n",
    "\n",
    "for tar in target_total:\n",
    "    if tar == 11:\n",
    "        new_target.append(0)\n",
    "    elif tar == 13:\n",
    "        new_target.append(1)\n",
    "    elif tar == 211:\n",
    "        new_target.append(2)\n",
    "    elif tar == 321:\n",
    "        new_target.append(3)\n",
    "    else:\n",
    "        new_target.append(4)\n",
    "    \n",
    "target_total = np.array(new_target)\n",
    "\n",
    "for i in range(5):\n",
    "    particle_indexes = np.where(target_total == i)[0]\n",
    "\n",
    "    data_modified = data_total[particle_indexes]\n",
    "    target_modified = target_total[particle_indexes]\n",
    "    \n",
    "    print(f'{target_names[str(i)]}.shape: {data_modified.shape}, {target_modified.shape}')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_total, target_total, stratify=target_total)\n",
    "\n",
    "# Change the train and test datasets.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape + change data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Scale and reshape data back to og form.\n",
    "X_train = (scaler.fit_transform(X_train)).reshape((X_train.shape[0], 10, 10, 1))\n",
    "X_test = (scaler.transform(X_test)).reshape((X_test.shape[0], 10, 10, 1))\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f'\\nX_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "\n",
    "# NOTE: We are using the unbalanced dataset in order to see if there is correlation to high accuracy with particles that have high # of samples.\n",
    "#       Based on the dataset partitions below, we would expect pion, kaon, and proton to have a higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.0%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohan\\Documents\\AI\\Projects\\AI Predicts Particle Collisions\\main.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mappend(particle_accuracy)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     individual_particle_test_modified(tf_model)\n",
      "\u001b[1;32mc:\\Users\\rohan\\Documents\\AI\\Projects\\AI Predicts Particle Collisions\\main.ipynb Cell 30\u001b[0m in \u001b[0;36mindividual_particle_test_modified\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model_recreate\u001b[39m.\u001b[39mbuild(input_shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_recreate\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m history \u001b[39m=\u001b[39m model_recreate\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39mhistory    \u001b[39m# We want to recreate the model every run so that we get different results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     int_y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39margmax(y, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m y_test])    \u001b[39m# convert back to integer for comparison.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "def individual_particle_test_modified(model):    # The only difference with this one is we record the data\n",
    "\n",
    "    results.append([])\n",
    "    model_recreate = Model()\n",
    "\n",
    "    model_recreate.build(input_shape=(1, 10, 10, 1))\n",
    "    model_recreate.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model_recreate.fit(X_train, y_train, epochs=3, batch_size=64, verbose=False).history    # We want to recreate the model every run so that we get different results\n",
    "\n",
    "    for i in range(5):\n",
    "        int_y_test = np.array([np.argmax(y, axis=None, out=None) for y in y_test])    # convert back to integer for comparison.\n",
    "        particle_indexes = np.where(int_y_test == i)    # gives indexes for all electron, muon, etc testcases...\n",
    "\n",
    "        X_test_modified = X_test[particle_indexes]\n",
    "        y_test_modified = y_test[particle_indexes]\n",
    "\n",
    "        particle_accuracy = model_recreate.evaluate(X_test_modified, y_test_modified, verbose=False)[1]\n",
    "\n",
    "        print(f'{target_names[str(i)]} accuracy: {particle_accuracy*100:.1f}%')\n",
    "\n",
    "        results[-1].append(particle_accuracy)\n",
    "\n",
    "for i in range(50):\n",
    "    individual_particle_test_modified(tf_model)\n",
    "\n",
    "# Basically, in this test, train on ENTIRE dataset;\n",
    "# test on specific particle (recorded as result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare results for R data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "df = pd.DataFrame(results, columns=['electron accuracy', 'muon accuracy', 'pion accuracy', 'kaon accuracy', 'proton accuracy'])\n",
    "df.to_csv('R Data Analysis/data/total_dataset_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 700, Test ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 2. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 3.]]\n",
      "\n",
      " [[2. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 2. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 2. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 2.]]\n",
      "\n",
      " [[2. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 2. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 3.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 3. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 3. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[2. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[4. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 3. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 2.]]]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data_700_samples' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohan\\Documents\\AI\\Projects\\AI Predicts Particle Collisions\\main.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mappend(particle_accuracy)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     individual_particle_test_modified(tf_model)\n",
      "\u001b[1;32mc:\\Users\\rohan\\Documents\\AI\\Projects\\AI Predicts Particle Collisions\\main.ipynb Cell 34\u001b[0m in \u001b[0;36mindividual_particle_test_modified\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindividual_particle_test_modified\u001b[39m(model):    \u001b[39m# The only difference with this one is we record the data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Reshape data first\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_700_samples \u001b[39m=\u001b[39m data_700_samples\u001b[39m.\u001b[39mreshape(data_700_samples\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     data_700_samples \u001b[39m=\u001b[39m (scaler\u001b[39m.\u001b[39mfit_transform(data_700_samples))\u001b[39m.\u001b[39mreshape(data_700_samples[\u001b[39m0\u001b[39m], \u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     target_700_samples \u001b[39m=\u001b[39m to_categorical(target_700_samples)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'data_700_samples' referenced before assignment"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "print(data_700_samples)\n",
    "\n",
    "def individual_particle_test_modified(model):    # The only difference with this one is we record the data\n",
    "\n",
    "    # Reshape data first\n",
    "    data_700_samples = data_700_samples.reshape(data_700_samples.shape[0], -1)\n",
    "    data_700_samples = (scaler.fit_transform(data_700_samples)).reshape(data_700_samples[0], 10, 10, 1)\n",
    "\n",
    "    target_700_samples = to_categorical(target_700_samples)\n",
    "\n",
    "    results.append([])\n",
    "    model_recreate = Model()\n",
    "\n",
    "    model_recreate.build(input_shape=(1, 10, 10, 1))\n",
    "    model_recreate.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model_recreate.fit(data_700_samples, target_700_samples, epochs=3, batch_size=64, verbose=False).history    # We want to recreate the model every run so that we get different results\n",
    "\n",
    "    for i in range(5):\n",
    "        int_y_test = np.array([np.argmax(y, axis=None, out=None) for y in y_test])    # convert back to integer for comparison.\n",
    "        particle_indexes = np.where(int_y_test == i)    # gives indexes for all electron, muon, etc testcases...\n",
    "\n",
    "        X_test_modified = X_test[particle_indexes]\n",
    "        y_test_modified = y_test[particle_indexes]\n",
    "\n",
    "        particle_accuracy = model_recreate.evaluate(X_test_modified, y_test_modified, verbose=False)[1]\n",
    "\n",
    "        print(f'{target_names[str(i)]} accuracy: {particle_accuracy*100:.1f}%')\n",
    "\n",
    "        results[-1].append(particle_accuracy)\n",
    "\n",
    "for i in range(50):\n",
    "    individual_particle_test_modified(tf_model)\n",
    "\n",
    "# Basically, in this test, train on ENTIRE dataset;\n",
    "# test on specific particle (recorded as result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muon vs All Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the muon is 1 and all else is changed to 0.\n",
    "\n",
    "muon_data, muon_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "muon_target = list(muon_target)\n",
    "\n",
    "# muon before is label 1 (already), everything else needs to be changed to a 0\n",
    "for i in range(len(muon_target)):\n",
    "    if muon_target[i] != 1:\n",
    "        muon_target[i] = 0\n",
    "\n",
    "muon_target = np.array(muon_target)        \n",
    "\n",
    "# change dataset to 700 muon and 700 other\n",
    "muon_indexes = np.where(muon_target == 1)\n",
    "other_indexes = np.where(muon_target == 0)\n",
    "\n",
    "muon_target = np.append(muon_target[muon_indexes], muon_target[other_indexes][:700])\n",
    "muon_data = np.append(muon_data[muon_indexes], muon_data[other_indexes][:700], axis=0)\n",
    "\n",
    "print(muon_data.shape)\n",
    "print(muon_target.shape)\n",
    "\n",
    "muon_data = muon_data.reshape(muon_data.shape[0], -1)\n",
    "muon_data = (scaler.fit_transform(muon_data)).reshape(muon_data.shape[0], 10, 10, 1)\n",
    "\n",
    "moun_target = to_categorical(muon_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "muon_X_train, muon_y_train = (np.append(muon_data[:350], muon_data[700:1050], axis=0), np.append(muon_target[:350], muon_target[700:1050]))\n",
    "muon_X_test, muon_y_test = (np.append(muon_data[350:700], muon_data[1050:1400], axis=0), np.append(muon_target[350:700], muon_target[1050:1400]))\n",
    "\n",
    "class Muon_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Muon_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    muon_model = Muon_Model()\n",
    "\n",
    "    muon_model.build(input_shape=(1, 10, 10, 1))\n",
    "    muon_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = muon_model.fit(muon_X_train, muon_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_muon = muon_model.evaluate(muon_X_train, muon_y_train, verbose=False)[1]\n",
    "    test_accuracy_muon = muon_model.evaluate(muon_X_test, muon_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_muon}')\n",
    "    print(f'Test accuracy: {test_accuracy_muon}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muon Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 350]\n",
      " [  0 350]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "predictions = muon_model.predict(muon_X_test)\n",
    "answers = muon_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 0 is everything else, 1 is muon\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting samples labeled 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muon Test: Confusion Matrix (`logreg` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muon_X_train_logreg.shape (700, 100)\n",
      "muon_y_train_logreg.shape (700,)\n",
      "muon_X_test_logreg.shape (700, 100)\n",
      "muon_y_test_logreg.shape (700,)\n",
      "Train Accuracy: 0.5\n",
      "Test Accuracy: 0.5\n",
      "[[350   0]\n",
      " [350   0]]\n"
     ]
    }
   ],
   "source": [
    "muon_X_train_logreg = muon_X_train.reshape((700, -1))\n",
    "muon_y_train_logreg = muon_y_train\n",
    "\n",
    "muon_X_test_logreg = muon_X_test.reshape((700, -1))\n",
    "muon_y_test_logreg = muon_y_test\n",
    "\n",
    "print(f'muon_X_train_logreg.shape {muon_X_train_logreg.shape}')\n",
    "print(f'muon_y_train_logreg.shape {muon_y_train_logreg.shape}')\n",
    "print(f'muon_X_test_logreg.shape {muon_X_test_logreg.shape}')\n",
    "print(f'muon_y_test_logreg.shape {muon_y_test_logreg.shape}')\n",
    "\n",
    "muon_model_logreg = LogisticRegression()\n",
    "\n",
    "muon_model_logreg.fit(muon_X_train_logreg, muon_y_train_logreg)\n",
    "\n",
    "print(f'Train Accuracy: {muon_model_logreg.score(muon_X_train_logreg, muon_y_train_logreg)}')\n",
    "print(f'Test Accuracy: {muon_model_logreg.score(muon_X_test_logreg, muon_y_test_logreg)}')\n",
    "\n",
    "predictions = muon_model_logreg.predict(muon_X_test_logreg)\n",
    "answers = muon_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "print('FP Rate: 50%')\n",
    "print('TP Rate: 0%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 10, 10, 1)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "print(muon_X_train.shape)\n",
    "print(muon_y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Particles Test (700 samples each i.e. original test): Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohan\\Documents\\AI\\Projects\\AI Predicts Particle Collisions\\main.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m prdictions \u001b[39m=\u001b[39m tf_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predictions_num \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Documents/AI/Projects/AI%20Predicts%20Particle%20Collisions/main.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m prediction \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(predictions):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "prdictions = tf_model.predict(X_test)\n",
    "\n",
    "predictions_num = []\n",
    "\n",
    "for prediction in list(predictions):\n",
    "    predictions_num.append(np.argmax(prediction))\n",
    "\n",
    "predictions_num = np.array(preditions_num)\n",
    "answers = y_test\n",
    "\n",
    "print(multilabel_confusion_matrix(answers, predictions_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15273\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electron vs Non-Electron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the electron is 0 and all else is changed to 1.\n",
    "\n",
    "electron_data, electron_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "electron_target = list(electron_target)\n",
    "\n",
    "# electron is label 0 (keep 0 to simplify process), everything else needs to be changed to a 1\n",
    "for i in range(len(electron_target)):\n",
    "    if electron_target[i] != 0:\n",
    "        electron_target[i] = 1\n",
    "\n",
    "electron_target = np.array(electron_target)        \n",
    "\n",
    "# change dataset to 700 electron and 700 other\n",
    "electron_indexes = np.where(electron_target == 0)\n",
    "other_indexes = np.where(electron_target == 1)\n",
    "\n",
    "electron_target = np.append(electron_target[electron_indexes], electron_target[other_indexes][:700])\n",
    "electron_data = np.append(electron_data[electron_indexes], electron_data[other_indexes][:700], axis=0)\n",
    "\n",
    "print(electron_data.shape)\n",
    "print(electron_target.shape)\n",
    "\n",
    "electron_data = electron_data.reshape(electron_data.shape[0], -1)\n",
    "electron_data = (scaler.fit_transform(electron_data)).reshape(electron_data.shape[0], 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "electron_X_train, electron_y_train = (np.append(electron_data[:350], electron_data[700:1050], axis=0), np.append(electron_target[:350], electron_target[700:1050]))\n",
    "electron_X_test, electron_y_test = (np.append(electron_data[350:700], electron_data[1050:1400], axis=0), np.append(electron_target[350:700], electron_target[1050:1400]))\n",
    "\n",
    "class Electron_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Electron_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    electron_model = Electron_Model()\n",
    "\n",
    "    electron_model.build(input_shape=(1, 10, 10, 1))\n",
    "    electron_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = electron_model.fit(electron_X_train, electron_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_electron = electron_model.evaluate(electron_X_train, electron_y_train, verbose=False)[1]\n",
    "    test_accuracy_electron = electron_model.evaluate(electron_X_test, electron_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_electron}')\n",
    "    print(f'Test accuracy: {test_accuracy_electron}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 350]\n",
      " [  0 350]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "predictions = electron_model.predict(electron_X_test)\n",
    "answers = electron_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 0 is electron, 1 is everything else\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting samples labeled 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron Test: Confusion Matrix (`logreg` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron_X_train_logreg.shape (700, 100)\n",
      "electron_y_train_logreg.shape (700,)\n",
      "electron_X_test_logreg.shape (700, 100)\n",
      "electron_y_test_logreg.shape (700,)\n",
      "Train Accuracy: 0.5\n",
      "Test Accuracy: 0.5\n",
      "[[350   0]\n",
      " [350   0]]\n",
      "FP Rate: 50%\n",
      "TP Rate: 0%\n"
     ]
    }
   ],
   "source": [
    "electron_X_train_logreg = electron_X_train.reshape((700, -1))\n",
    "electron_y_train_logreg = electron_y_train\n",
    "\n",
    "electron_X_test_logreg = electron_X_test.reshape((700, -1))\n",
    "electron_y_test_logreg = electron_y_test\n",
    "\n",
    "print(f'electron_X_train_logreg.shape {electron_X_train_logreg.shape}')\n",
    "print(f'electron_y_train_logreg.shape {electron_y_train_logreg.shape}')\n",
    "print(f'electron_X_test_logreg.shape {electron_X_test_logreg.shape}')\n",
    "print(f'electron_y_test_logreg.shape {electron_y_test_logreg.shape}')\n",
    "\n",
    "electron_model_logreg = LogisticRegression()\n",
    "\n",
    "electron_model_logreg.fit(electron_X_train_logreg, electron_y_train_logreg)\n",
    "\n",
    "print(f'Train Accuracy: {electron_model_logreg.score(electron_X_train_logreg, electron_y_train_logreg)}')\n",
    "print(f'Test Accuracy: {electron_model_logreg.score(electron_X_test_logreg, electron_y_test_logreg)}')\n",
    "\n",
    "predictions = electron_model_logreg.predict(electron_X_test_logreg)\n",
    "answers = electron_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 0 is electron, 1 is everything else\n",
    "\n",
    "print('FP Rate: 50%')    # 50% on predicting samples labeled 0\n",
    "print('TP Rate: 0%')    # 0% on predicting samples labeled 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pion vs Non-Pion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the pion is 1 and all else is changed to 0\n",
    "\n",
    "pion_data, pion_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "pion_target = list(pion_target)\n",
    "\n",
    "# pion is label 1, everything else needs to be changed to a 0.\n",
    "for i in range(len(pion_target)):\n",
    "    if pion_target[i] != 2:\n",
    "        pion_target[i] = 0\n",
    "    else:\n",
    "        pion_target[i] = 1    # This means that the target is 2 (pion)... change it to 1.\n",
    "\n",
    "pion_target = np.array(pion_target)\n",
    "\n",
    "# change dataset to 700 pion and 700 other.\n",
    "pion_indexes = np.where(pion_target == 1)\n",
    "other_indexes = np.where(pion_target == 0)\n",
    "\n",
    "pion_data = np.append(pion_data[pion_indexes], pion_data[other_indexes][:700], axis=0)\n",
    "pion_target = np.append(pion_target[pion_indexes], pion_target[other_indexes][:700])\n",
    "\n",
    "print(pion_data.shape)\n",
    "print(pion_target.shape)\n",
    "\n",
    "pion_data = pion_data.reshape(pion_data.shape[0], -1)\n",
    "pion_data = (scaler.fit_transform(pion_data)).reshape(pion_data.shape[0], 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pion_X_train, pion_y_train = (np.append(pion_data[:350], pion_data[700:1050], axis=0), np.append(pion_target[:350], pion_target[700:1050]))\n",
    "pion_X_test, pion_y_test = (np.append(pion_data[350:700], pion_data[1050:1400], axis=0), np.append(pion_target[350:700], pion_target[1050:1400]))\n",
    "\n",
    "class Pion_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Pion_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    pion_model = Pion_Model()\n",
    "\n",
    "    pion_model.build(input_shape=(1, 10, 10, 1))\n",
    "    pion_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = pion_model.fit(pion_X_train, pion_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_pion = pion_model.evaluate(pion_X_train, pion_y_train, verbose=False)[1]\n",
    "    test_accuracy_pion = pion_model.evaluate(pion_X_test, pion_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_pion}')\n",
    "    print(f'Test Accuracy {test_accuracy_pion}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pion Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 350]\n",
      " [  0 350]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "predictions = pion_model.predict(pion_X_test)\n",
    "answers = pion_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 1 is pion, 0 is everything else.\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting smaples labeled 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "7b8ec01fe1ca8fb45588a4ccd1c70e5bbb495e4fae5c72e85a541e07ce265118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
