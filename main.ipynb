{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules & prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data.shape: (1259300, 10, 10)\n",
      "original target.shape: (1259300,)\n",
      "\n",
      "electron.shape: (3150, 10, 10), (3150,)\n",
      "muon.shape: (700, 10, 10), (700,)\n",
      "pion.shape: (981050, 10, 10), (981050,)\n",
      "kaon.shape: (160300, 10, 10), (160300,)\n",
      "proton.shape: (114100, 10, 10), (114100,)\n"
     ]
    }
   ],
   "source": [
    "# Import sklearn/tensorflow modules.\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import other modules.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from os import walk\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "# Data source: https://www.kaggle.com/stephenmugisha/particle-collisions\n",
    "\n",
    "_, _, files = next(walk('data'))\n",
    "\n",
    "target_names = {\n",
    "    '0': 'electron',    # Negatively charged particle that is a lepton  (doesn't take part in strong force).\n",
    "    '1': 'muon',    # Electron with 200 times more mass and makes up lots of cosmic radiation.\n",
    "    '2': 'pion',    # Meson (connects with strong force) that can be positive, negative, or neutral\n",
    "    '3': 'kaon',    # Pion with more mass.\n",
    "    '4': 'proton'    # Positively charged particle with 2 up quarks and 1 down quark.\n",
    "}\n",
    "\n",
    "# Check how the data is formatted/stored.\n",
    "file_test = open(f'data/{files[0]}', 'rb')\n",
    "file = pickle.load(file_test)\n",
    "\n",
    "print(file[0].shape)    # Group of 3000 images.\n",
    "print(file[0][0].shape)    # Check first image.\n",
    "print(file[1].shape)    # Group of 3000 targets.\n",
    "print(file[1][0])    # Classified as 'pion.'\n",
    "\n",
    "# Collect all the data.\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for file in files:\n",
    "    file = open(f'data/{files[0]}', 'rb')\n",
    "    file =  pickle.load(file)\n",
    "\n",
    "    for sample, sample_target in zip(file[0], file[1]):\n",
    "        data.append(sample)\n",
    "        target.append(sample_target)\n",
    "\n",
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "\n",
    "sleep(7)\n",
    "clear_output()\n",
    "\n",
    "print(f'original data.shape: {data.shape}')\n",
    "print(f'original target.shape: {target.shape}\\n')\n",
    "\n",
    "# Edit target values to 0, 1, 2...\n",
    "new_target = []\n",
    "\n",
    "for tar in target:\n",
    "    if tar == 11:\n",
    "        new_target.append(0)\n",
    "    elif tar == 13:\n",
    "        new_target.append(1)\n",
    "    elif tar == 211:\n",
    "        new_target.append(2)\n",
    "    elif tar == 321:\n",
    "        new_target.append(3)\n",
    "    else:\n",
    "        new_target.append(4)\n",
    "    \n",
    "target = np.array(new_target)\n",
    "\n",
    "for i in range(5):\n",
    "    particle_indexes = np.where(target == i)[0]\n",
    "\n",
    "    data_modified = data[particle_indexes]\n",
    "    target_modified = target[particle_indexes]\n",
    "    \n",
    "    print(f'{target_names[str(i)]}.shape: {data_modified.shape}, {target_modified.shape}')\n",
    "\n",
    "# NOTE: through the above code, we find there are inconsistencies in the data (less samples for one particle but lots of samples in another)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping data (to make even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even data.shape: (3500, 10, 10)\n",
      "even target.shape: (3500,)\n",
      "even data.shape (sklearn version): (3500, 100)\n"
     ]
    }
   ],
   "source": [
    "muon_indexes = np.where(target == 1)[0]    # since this has least # of samples... use this as limiter\n",
    "\n",
    "def set_data_samples(number_of_samples):    # limit to <= 700 samples for each particle. (to keep data even)\n",
    "    \n",
    "    data_new, target_new = ((data[muon_indexes])[:number_of_samples], (target[muon_indexes])[:number_of_samples])\n",
    "    \n",
    "    for i in [0, 2, 3, 4]:\n",
    "        particle_indexes = np.where(target == i)[0]\n",
    "        data_modified = (data[particle_indexes])[:number_of_samples]    \n",
    "        target_modified = (target[particle_indexes])[:number_of_samples]\n",
    "    \n",
    "        data_new = np.append(data_new, data_modified, axis=0)\n",
    "        target_new = np.append(target_new, target_modified)\n",
    "\n",
    "    return (np.array(data_new), np.array(target_new))\n",
    "\n",
    "\n",
    "data_50_samples, target_50_samples = set_data_samples(50)\n",
    "data_100_samples, target_100_samples = set_data_samples(100)\n",
    "data_150_samples, target_150_samples = set_data_samples(150)\n",
    "data_200_samples, target_200_samples = set_data_samples(200)\n",
    "data_250_samples, target_250_samples = set_data_samples(250)\n",
    "data_300_samples, target_300_samples = set_data_samples(300)\n",
    "data_350_samples, target_350_samples = set_data_samples(350)\n",
    "data_400_samples, target_400_samples = set_data_samples(400)\n",
    "data_450_samples, target_450_samples = set_data_samples(450)\n",
    "data_500_samples, target_500_samples = set_data_samples(500)\n",
    "data_550_samples, target_550_samples = set_data_samples(550)\n",
    "data_600_samples, target_600_samples = set_data_samples(600)\n",
    "data_650_samples, target_650_samples = set_data_samples(650)\n",
    "data_700_samples, target_700_samples = set_data_samples(700)\n",
    "\n",
    "\n",
    "# data_140_samples, target_140_samples = set_data_samples(140)    # NOTE: These will be used for later tests.\n",
    "# data_280_samples, target_280_samples = set_data_samples(280)\n",
    "# data_420_samples, target_420_samples = set_data_samples(420)\n",
    "# data_560_samples, target_560_samples = set_data_samples(560)\n",
    "# data_700_samples, target_700_samples = set_data_samples(700)\n",
    "\n",
    "data = data_700_samples    # Regular number of samples that should be used.\n",
    "target = target_700_samples\n",
    "\n",
    "data_sklearn = data.reshape((3500, -1))\n",
    "\n",
    "print(f'even data.shape: {data.shape}')\n",
    "print(f'even target.shape: {target.shape}')\n",
    "\n",
    "print(f'even data.shape (sklearn version): {data_sklearn.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2625, 10, 10, 1)\n",
      "y_train.shape: (2625, 5)\n",
      "X_test.shape: (875, 10, 10, 1)\n",
      "y_test.shape: (875, 5)\n",
      "\n",
      "sklearn versions\n",
      "X_train.shape: (2625, 100)\n",
      "y_train.shape: (2625,)\n",
      "X_test.shape: (875, 100)\n",
      "y_test.shape: (875,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for NaN values.\n",
    "print(np.isnan(np.sum(data)))    # -> False\n",
    "\n",
    "# Check range of values.\n",
    "print(np.max(data), np.min(data))    # -> 8, 0\n",
    "\n",
    "sleep(4)\n",
    "clear_output()\n",
    "\n",
    "# Get indexes for each different target possibility.\n",
    "indexes = [\n",
    "    np.where(target == 0)[0][0],\n",
    "    np.where(target == 1)[0][0],\n",
    "    np.where(target == 2)[0][0],\n",
    "    np.where(target == 3)[0][0],\n",
    "    np.where(target == 4)[0][0],\n",
    "]\n",
    "\n",
    "samples = [data[index] for index in indexes]\n",
    "samples_target = [target_names[str(target[index])] for index in indexes]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9, 6), subplot_kw={\n",
    "    'yticks': (),\n",
    "    'xticks': ()\n",
    "})\n",
    "\n",
    "axs = [ax for ax in axs.flatten()]\n",
    "\n",
    "for sample, sample_target, ax in zip(samples, samples_target, axs):\n",
    "    ax.imshow(sample, cmap='binary')\n",
    "    ax.set_title(str(sample_target))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, stratify=target)\n",
    "\n",
    "# Change the train and test datasets.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape + change data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Scale and reshape data back to og form.\n",
    "X_train = (scaler.fit_transform(X_train)).reshape((X_train.shape[0], 10, 10, 1))\n",
    "X_test = (scaler.transform(X_test)).reshape((X_test.shape[0], 10, 10, 1))\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train_sklearn, X_test_sklearn, y_train_sklearn, y_test_sklearn = train_test_split(data_sklearn, target, stratify=target)\n",
    "\n",
    "y_train_sklearn, y_test_sklearn = ([], [])\n",
    "\n",
    "for label in list(y_train):\n",
    "    y_train_sklearn.append(list(label).index(1))    # changing sample from [0, 1, 0, 0, 0] to [2, .....]\n",
    "\n",
    "for label in list(y_test):\n",
    "    y_test_sklearn.append(list(label).index(1))\n",
    "\n",
    "y_train_sklearn = np.array(y_train_sklearn)\n",
    "y_test_sklearn = np.array(y_test_sklearn)\n",
    "\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "\n",
    "print('\\nsklearn versions')\n",
    "print(f'X_train.shape: {X_train_sklearn.shape}')\n",
    "print(f'y_train.shape: {y_train_sklearn.shape}')\n",
    "print(f'X_test.shape: {X_test_sklearn.shape}')\n",
    "print(f'y_test.shape: {y_test_sklearn.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "42/42 [==============================] - 1s 2ms/step - loss: 2.0855 - accuracy: 0.2526\n",
      "Epoch 2/3\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9875 - accuracy: 0.2549\n",
      "Epoch 3/3\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 1.9359 - accuracy: 0.2701\n",
      "Train accuracy: 27.7%\n",
      "Test accuracy: 23.2%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(5, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "tf_model = Model()\n",
    "\n",
    "tf_model.build(input_shape=(1, 10, 10, 1))\n",
    "tf_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = tf_model.fit(X_train, y_train, epochs=3, batch_size=64).history\n",
    "\n",
    "sleep(4)\n",
    "# clear_output()\n",
    "\n",
    "print(f'Train accuracy: {tf_model.evaluate(X_train, y_train, verbose=False)[1]*100:.1f}%')\n",
    "print(f'Test accuracy: {tf_model.evaluate(X_test, y_test, verbose=False)[1]*100:.1f}%')\n",
    "\n",
    "fig, (ax_1, ax_2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax_1.plot(range(3), history['loss'])\n",
    "ax_2.plot(range(3), history['accuracy'])\n",
    "\n",
    "ax_1.set_title('Loss')\n",
    "ax_2.set_title('Accuracy');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `sklearn` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 26.86%\n",
      "Test Accuracy: 18.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_sklearn, y_train_sklearn)\n",
    "\n",
    "print(f'Train Accuracy: {logreg.score(X_train_sklearn, y_train_sklearn)*100:.2f}%')\n",
    "print(f'Test Accuracy: {logreg.score(X_test_sklearn, y_test_sklearn)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron accuracy: 0.0%\n",
      "muon accuracy: 41.7%\n",
      "pion accuracy: 21.7%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 51.4%\n"
     ]
    }
   ],
   "source": [
    "def individual_particle_test(model):\n",
    "    for i in range(5):\n",
    "        int_y_test = np.array([np.argmax(y, axis=None, out=None) for y in y_test])    # convert back to integer for comparison.\n",
    "        particle_indexes = np.where(int_y_test == i)    # gives indexes for all electron, muon, etc testcases...\n",
    "\n",
    "        X_test_modified = X_test[particle_indexes]\n",
    "        y_test_modified = y_test[particle_indexes]\n",
    "\n",
    "        print(f'{target_names[str(i)]} accuracy: {model.evaluate(X_test_modified, y_test_modified, verbose=False)[1]*100:.1f}%')\n",
    "\n",
    "individual_particle_test(tf_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Results\n",
    "<img src='images/test_1_(19).png'>\n",
    "<img src='images/test 2 (19).png'></br>\n",
    "difference between one test and another (inconsistencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "* The algorithm shows some promise for some particles, but little for others.\n",
    "    * muon could have 100% accuracy because of its mass... has less quantum effect compared to others.\n",
    "    * electron could be low because of quantum effects\n",
    "    * proton is actually pretty consistent.\n",
    "    * out of mesons, kaon and proton lowest while pion higher (because of higher mass than other mesons)\n",
    "    * next steps, find reason for fluctuations in percentages and relationships between particles considering their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph relationship between sample size and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy: 13.3% (50 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 18.2% (100 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 20.4% (150 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 27.0% (200 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 22.2% (250 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 31.6% (300 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 27.7% (350 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 26.9% (400 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 30.1% (450 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 34.2% (500 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 25.1% (550 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 39.8% (600 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 29.0% (650 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n",
      "\n",
      "Train accuracy: 48.5% (700 samples)\n",
      "\t50.0 samples test: 30.4%\n",
      "\t100.0 samples test: 30.4%\n",
      "\t150.0 samples test: 29.7%\n",
      "\t200.0 samples test: 28.9%\n",
      "\t250.0 samples test: 26.2%\n",
      "\t300.0 samples test: 26.6%\n",
      "\t350.0 samples test: 26.7%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 26.7%\n",
      "\t500.0 samples test: 26.4%\n",
      "\t550.0 samples test: 26.3%\n",
      "\t600.0 samples test: 26.3%\n",
      "\t650.0 samples test: 26.4%\n",
      "\t700.0 samples test: 26.6%\n"
     ]
    }
   ],
   "source": [
    "info_x_samples = [\n",
    "    (data_50_samples, target_50_samples), \n",
    "    (data_100_samples, target_100_samples),\n",
    "    (data_150_samples, target_150_samples), \n",
    "    (data_200_samples, target_200_samples), \n",
    "    (data_250_samples, target_250_samples), \n",
    "    (data_300_samples, target_300_samples), \n",
    "    (data_350_samples, target_350_samples), \n",
    "    (data_400_samples, target_400_samples), \n",
    "    (data_450_samples, target_450_samples),\n",
    "    (data_500_samples, target_500_samples), \n",
    "    (data_550_samples, target_550_samples), \n",
    "    (data_600_samples, target_600_samples), \n",
    "    (data_650_samples, target_650_samples), \n",
    "    (data_700_samples, target_700_samples)\n",
    "]\n",
    "sample_numbers = (list(range(50, 701, 50)))\n",
    "results = []\n",
    "\n",
    "def samples_test(verbose=True):\n",
    "    \n",
    "    results.append([])\n",
    "\n",
    "    for sample_number, i in zip(sample_numbers, range(14)):\n",
    "        data_x_samples = info_x_samples[i][0]\n",
    "        target_x_samples = info_x_samples[i][1]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data_x_samples = data_x_samples.reshape(data_x_samples.shape[0], -1)\n",
    "        data_x_samples = (scaler.fit_transform(data_x_samples)).reshape((data_x_samples.shape[0], 10, 10, 1))\n",
    "        \n",
    "        target_x_samples = to_categorical(target_x_samples)\n",
    "    \n",
    "        temp_tf_model = Model()\n",
    "    \n",
    "        temp_tf_model.build(input_shape=(1, 10, 10, 1))\n",
    "        temp_tf_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        temp_tf_model.fit(data_x_samples, target_x_samples, epochs=3, batch_size=64, verbose=False)\n",
    "    \n",
    "        initial_accuracy = temp_tf_model.evaluate(X_train, y_train, verbose=False)[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nTrain accuracy: {initial_accuracy*100:.1f}% ({sample_number} samples)')\n",
    "        \n",
    "        if verbose:\n",
    "            for re_iter in info_x_samples:\n",
    "                data_new = re_iter[0]\n",
    "                target_new = re_iter[1]\n",
    "        \n",
    "                scaler = StandardScaler()\n",
    "        \n",
    "                data_new = data_new.reshape(data_new.shape[0], -1)\n",
    "                data_new = (scaler.fit_transform(data_new)).reshape((data_new.shape[0], 10, 10, 1))\n",
    "        \n",
    "                target_new = to_categorical(target_new)\n",
    "        \n",
    "                print(f'\\t{(data_new.shape[0])/5} samples test: {tf_model.evaluate(data_new, target_new, verbose=False)[1]*100:.1f}%')\n",
    "        \n",
    "        results[-1].append(initial_accuracy)\n",
    "    \n",
    "\n",
    "samples_test()\n",
    "for i in range(49):\n",
    "    samples_test(verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare results from tests for R data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "df = pd.DataFrame(results, columns=[f'{num} samples' for num in range(50, 701, 50)])\n",
    "df.to_csv('R Data Analysis/data/samples_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Test Runs (when trained on 700 samples):\n",
    "<img src='images/accuracy_sample_test1.png'>\n",
    "<img src='images/accuracy_sample_test2.png'>\n",
    "<img src='images/accuracy_sample_test3.png'>\n",
    "<img src='images/accuracy_sample_test4.png'>\n",
    "<img src='images/accuracy_sample_test5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy: 25.3% (50 samples)\n",
      "\t50.0 samples test: 25.6%\n",
      "\t100.0 samples test: 25.6%\n",
      "\t150.0 samples test: 25.9%\n",
      "\t200.0 samples test: 25.6%\n",
      "\t250.0 samples test: 25.1%\n",
      "\t300.0 samples test: 25.3%\n",
      "\t350.0 samples test: 25.1%\n",
      "\t400.0 samples test: 25.5%\n",
      "\t450.0 samples test: 25.5%\n",
      "\t500.0 samples test: 25.3%\n",
      "\t550.0 samples test: 25.3%\n",
      "\t600.0 samples test: 23.2%\n",
      "\t650.0 samples test: 23.1%\n",
      "\t700.0 samples test: 23.0%\n",
      "\n",
      "Train accuracy: 18.9% (100 samples)\n",
      "\t50.0 samples test: 19.2%\n",
      "\t100.0 samples test: 19.4%\n",
      "\t150.0 samples test: 19.6%\n",
      "\t200.0 samples test: 19.2%\n",
      "\t250.0 samples test: 19.0%\n",
      "\t300.0 samples test: 18.8%\n",
      "\t350.0 samples test: 18.9%\n",
      "\t400.0 samples test: 19.0%\n",
      "\t450.0 samples test: 18.8%\n",
      "\t500.0 samples test: 18.5%\n",
      "\t550.0 samples test: 18.8%\n",
      "\t600.0 samples test: 18.8%\n",
      "\t650.0 samples test: 18.7%\n",
      "\t700.0 samples test: 18.8%\n",
      "\n",
      "Train accuracy: 20.8% (150 samples)\n",
      "\t50.0 samples test: 24.8%\n",
      "\t100.0 samples test: 34.2%\n",
      "\t150.0 samples test: 23.2%\n",
      "\t200.0 samples test: 22.8%\n",
      "\t250.0 samples test: 22.0%\n",
      "\t300.0 samples test: 21.9%\n",
      "\t350.0 samples test: 21.5%\n",
      "\t400.0 samples test: 21.5%\n",
      "\t450.0 samples test: 21.2%\n",
      "\t500.0 samples test: 21.2%\n",
      "\t550.0 samples test: 21.3%\n",
      "\t600.0 samples test: 21.1%\n",
      "\t650.0 samples test: 20.9%\n",
      "\t700.0 samples test: 21.0%\n",
      "\n",
      "Train accuracy: 25.0% (200 samples)\n",
      "\t50.0 samples test: 21.2%\n",
      "\t100.0 samples test: 23.4%\n",
      "\t150.0 samples test: 24.9%\n",
      "\t200.0 samples test: 25.0%\n",
      "\t250.0 samples test: 24.9%\n",
      "\t300.0 samples test: 24.2%\n",
      "\t350.0 samples test: 24.5%\n",
      "\t400.0 samples test: 24.3%\n",
      "\t450.0 samples test: 24.9%\n",
      "\t500.0 samples test: 24.9%\n",
      "\t550.0 samples test: 24.8%\n",
      "\t600.0 samples test: 24.7%\n",
      "\t650.0 samples test: 24.7%\n",
      "\t700.0 samples test: 24.9%\n",
      "\n",
      "Train accuracy: 41.2% (250 samples)\n",
      "\t50.0 samples test: 37.6%\n",
      "\t100.0 samples test: 38.8%\n",
      "\t150.0 samples test: 40.5%\n",
      "\t200.0 samples test: 40.6%\n",
      "\t250.0 samples test: 40.7%\n",
      "\t300.0 samples test: 40.4%\n",
      "\t350.0 samples test: 40.4%\n",
      "\t400.0 samples test: 40.5%\n",
      "\t450.0 samples test: 40.2%\n",
      "\t500.0 samples test: 40.7%\n",
      "\t550.0 samples test: 40.5%\n",
      "\t600.0 samples test: 40.6%\n",
      "\t650.0 samples test: 40.4%\n",
      "\t700.0 samples test: 40.6%\n",
      "\n",
      "Train accuracy: 30.5% (300 samples)\n",
      "\t50.0 samples test: 30.8%\n",
      "\t100.0 samples test: 31.6%\n",
      "\t150.0 samples test: 31.5%\n",
      "\t200.0 samples test: 31.4%\n",
      "\t250.0 samples test: 30.8%\n",
      "\t300.0 samples test: 30.7%\n",
      "\t350.0 samples test: 30.4%\n",
      "\t400.0 samples test: 30.2%\n",
      "\t450.0 samples test: 30.6%\n",
      "\t500.0 samples test: 30.5%\n",
      "\t550.0 samples test: 30.5%\n",
      "\t600.0 samples test: 30.7%\n",
      "\t650.0 samples test: 30.7%\n",
      "\t700.0 samples test: 30.5%\n",
      "\n",
      "Train accuracy: 18.9% (350 samples)\n",
      "\t50.0 samples test: 28.0%\n",
      "\t100.0 samples test: 30.0%\n",
      "\t150.0 samples test: 19.9%\n",
      "\t200.0 samples test: 19.4%\n",
      "\t250.0 samples test: 29.4%\n",
      "\t300.0 samples test: 29.5%\n",
      "\t350.0 samples test: 29.4%\n",
      "\t400.0 samples test: 18.9%\n",
      "\t450.0 samples test: 19.1%\n",
      "\t500.0 samples test: 18.9%\n",
      "\t550.0 samples test: 18.8%\n",
      "\t600.0 samples test: 18.9%\n",
      "\t650.0 samples test: 18.7%\n",
      "\t700.0 samples test: 18.8%\n",
      "\n",
      "Train accuracy: 28.9% (400 samples)\n",
      "\t50.0 samples test: 20.4%\n",
      "\t100.0 samples test: 22.8%\n",
      "\t150.0 samples test: 25.7%\n",
      "\t200.0 samples test: 26.9%\n",
      "\t250.0 samples test: 27.7%\n",
      "\t300.0 samples test: 28.1%\n",
      "\t350.0 samples test: 27.6%\n",
      "\t400.0 samples test: 28.1%\n",
      "\t450.0 samples test: 28.3%\n",
      "\t500.0 samples test: 28.4%\n",
      "\t550.0 samples test: 28.4%\n",
      "\t600.0 samples test: 28.6%\n",
      "\t650.0 samples test: 28.5%\n",
      "\t700.0 samples test: 28.3%\n",
      "\n",
      "Train accuracy: 41.0% (450 samples)\n",
      "\t50.0 samples test: 26.8%\n",
      "\t100.0 samples test: 30.2%\n",
      "\t150.0 samples test: 41.6%\n",
      "\t200.0 samples test: 41.8%\n",
      "\t250.0 samples test: 41.8%\n",
      "\t300.0 samples test: 42.0%\n",
      "\t350.0 samples test: 41.5%\n",
      "\t400.0 samples test: 40.9%\n",
      "\t450.0 samples test: 40.9%\n",
      "\t500.0 samples test: 40.8%\n",
      "\t550.0 samples test: 41.2%\n",
      "\t600.0 samples test: 41.2%\n",
      "\t650.0 samples test: 41.3%\n",
      "\t700.0 samples test: 41.3%\n",
      "\n",
      "Train accuracy: 37.5% (500 samples)\n",
      "\t50.0 samples test: 35.6%\n",
      "\t100.0 samples test: 34.6%\n",
      "\t150.0 samples test: 37.3%\n",
      "\t200.0 samples test: 37.4%\n",
      "\t250.0 samples test: 38.3%\n",
      "\t300.0 samples test: 38.6%\n",
      "\t350.0 samples test: 38.8%\n",
      "\t400.0 samples test: 38.2%\n",
      "\t450.0 samples test: 38.5%\n",
      "\t500.0 samples test: 38.2%\n",
      "\t550.0 samples test: 38.0%\n",
      "\t600.0 samples test: 38.1%\n",
      "\t650.0 samples test: 38.2%\n",
      "\t700.0 samples test: 38.3%\n",
      "\n",
      "Train accuracy: 22.5% (550 samples)\n",
      "\t50.0 samples test: 23.2%\n",
      "\t100.0 samples test: 23.0%\n",
      "\t150.0 samples test: 23.3%\n",
      "\t200.0 samples test: 23.4%\n",
      "\t250.0 samples test: 22.6%\n",
      "\t300.0 samples test: 22.9%\n",
      "\t350.0 samples test: 22.3%\n",
      "\t400.0 samples test: 22.0%\n",
      "\t450.0 samples test: 22.1%\n",
      "\t500.0 samples test: 22.3%\n",
      "\t550.0 samples test: 22.2%\n",
      "\t600.0 samples test: 22.8%\n",
      "\t650.0 samples test: 22.6%\n",
      "\t700.0 samples test: 22.6%\n",
      "\n",
      "Train accuracy: 32.8% (600 samples)\n",
      "\t50.0 samples test: 34.0%\n",
      "\t100.0 samples test: 33.8%\n",
      "\t150.0 samples test: 33.1%\n",
      "\t200.0 samples test: 32.8%\n",
      "\t250.0 samples test: 32.2%\n",
      "\t300.0 samples test: 32.6%\n",
      "\t350.0 samples test: 32.6%\n",
      "\t400.0 samples test: 33.3%\n",
      "\t450.0 samples test: 33.3%\n",
      "\t500.0 samples test: 33.0%\n",
      "\t550.0 samples test: 33.2%\n",
      "\t600.0 samples test: 33.2%\n",
      "\t650.0 samples test: 33.0%\n",
      "\t700.0 samples test: 32.7%\n",
      "\n",
      "Train accuracy: 35.2% (650 samples)\n",
      "\t50.0 samples test: 34.8%\n",
      "\t100.0 samples test: 34.8%\n",
      "\t150.0 samples test: 34.1%\n",
      "\t200.0 samples test: 32.7%\n",
      "\t250.0 samples test: 35.7%\n",
      "\t300.0 samples test: 35.1%\n",
      "\t350.0 samples test: 34.9%\n",
      "\t400.0 samples test: 35.1%\n",
      "\t450.0 samples test: 35.2%\n",
      "\t500.0 samples test: 35.1%\n",
      "\t550.0 samples test: 35.1%\n",
      "\t600.0 samples test: 34.9%\n",
      "\t650.0 samples test: 34.8%\n",
      "\t700.0 samples test: 34.9%\n",
      "\n",
      "Train accuracy: 26.9% (700 samples)\n",
      "\t50.0 samples test: 25.6%\n",
      "\t100.0 samples test: 26.0%\n",
      "\t150.0 samples test: 26.1%\n",
      "\t200.0 samples test: 26.5%\n",
      "\t250.0 samples test: 26.8%\n",
      "\t300.0 samples test: 27.2%\n",
      "\t350.0 samples test: 26.9%\n",
      "\t400.0 samples test: 26.8%\n",
      "\t450.0 samples test: 27.0%\n",
      "\t500.0 samples test: 26.6%\n",
      "\t550.0 samples test: 26.6%\n",
      "\t600.0 samples test: 26.5%\n",
      "\t650.0 samples test: 26.7%\n",
      "\t700.0 samples test: 26.9%\n"
     ]
    }
   ],
   "source": [
    "info_x_samples = [\n",
    "    (data_50_samples, target_50_samples), \n",
    "    (data_100_samples, target_100_samples),\n",
    "    (data_150_samples, target_150_samples), \n",
    "    (data_200_samples, target_200_samples), \n",
    "    (data_250_samples, target_250_samples), \n",
    "    (data_300_samples, target_300_samples), \n",
    "    (data_350_samples, target_350_samples), \n",
    "    (data_400_samples, target_400_samples), \n",
    "    (data_450_samples, target_450_samples),\n",
    "    (data_500_samples, target_500_samples), \n",
    "    (data_550_samples, target_550_samples), \n",
    "    (data_600_samples, target_600_samples), \n",
    "    (data_650_samples, target_650_samples), \n",
    "    (data_700_samples, target_700_samples)\n",
    "]\n",
    "sample_numbers = (list(range(50, 701, 50)))\n",
    "results = []\n",
    "\n",
    "def samples_test(verbose=True):\n",
    "    \n",
    "    results.append([])\n",
    "\n",
    "    for sample_number, i in zip(sample_numbers, range(14)):\n",
    "        data_x_samples = info_x_samples[i][0]\n",
    "        target_x_samples = info_x_samples[i][1]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data_x_samples = data_x_samples.reshape(data_x_samples.shape[0], -1)\n",
    "        data_x_samples = (scaler.fit_transform(data_x_samples)).reshape((data_x_samples.shape[0], 10, 10, 1))\n",
    "        \n",
    "        target_x_samples = to_categorical(target_x_samples)\n",
    "    \n",
    "        model = Model()\n",
    "    \n",
    "        model.build(input_shape=(1, 10, 10, 1))\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(data_x_samples, target_x_samples, epochs=3, batch_size=64, verbose=False)\n",
    "    \n",
    "        initial_accuracy = model.evaluate(X_train, y_train, verbose=False)[1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nTrain accuracy: {initial_accuracy*100:.1f}% ({sample_number} samples)')\n",
    "        \n",
    "        if verbose:\n",
    "            for re_iter in info_x_samples:\n",
    "                data_new = re_iter[0]\n",
    "                target_new = re_iter[1]\n",
    "        \n",
    "                scaler = StandardScaler()\n",
    "        \n",
    "                data_new = data_new.reshape(data_new.shape[0], -1)\n",
    "                data_new = (scaler.fit_transform(data_new)).reshape((data_new.shape[0], 10, 10, 1))\n",
    "        \n",
    "                target_new = to_categorical(target_new)\n",
    "        \n",
    "                print(f'\\t{(data_new.shape[0])/5} samples test: {model.evaluate(data_new, target_new, verbose=False)[1]*100:.1f}%')\n",
    "        \n",
    "        results[-1].append(initial_accuracy)\n",
    "\n",
    "\n",
    "samples_test()\n",
    "for i in range(49):\n",
    "    samples_test(verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Test with Constant Test Samples (175 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "\t50.0 samples train: 16.0% test: 16.6%\n",
      "\t100.0 samples train: 19.2% test: 17.3%\n",
      "\t150.0 samples train: 22.2% test: 16.9%\n",
      "\t200.0 samples train: 20.5% test: 18.5%\n",
      "\t250.0 samples train: 22.9% test: 29.7%\n",
      "\t300.0 samples train: 19.4% test: 22.9%\n",
      "\t350.0 samples train: 31.5% test: 22.3%\n",
      "\t400.0 samples train: 9.4% test: 16.5%\n",
      "\t450.0 samples train: 21.9% test: 19.9%\n",
      "\t500.0 samples train: 24.4% test: 21.5%\n",
      "\t550.0 samples train: 29.6% test: 21.3%\n",
      "\t600.0 samples train: 28.4% test: 20.6%\n",
      "\t650.0 samples train: 28.8% test: 20.0%\n",
      "\t700.0 samples train: 22.8% test: 20.6%\n",
      "\n",
      "\n",
      "Run 2\n",
      "\t50.0 samples train: 22.5% test: 19.9%\n",
      "\t100.0 samples train: 21.6% test: 38.1%\n",
      "\t150.0 samples train: 21.0% test: 9.1%\n",
      "\t200.0 samples train: 20.4% test: 20.2%\n",
      "\t250.0 samples train: 20.1% test: 22.1%\n",
      "\t300.0 samples train: 18.0% test: 19.7%\n",
      "\t350.0 samples train: 29.0% test: 21.8%\n",
      "\t400.0 samples train: 31.3% test: 20.8%\n",
      "\t450.0 samples train: 28.5% test: 20.3%\n",
      "\t500.0 samples train: 17.3% test: 20.3%\n",
      "\t550.0 samples train: 23.2% test: 20.3%\n",
      "\t600.0 samples train: 20.0% test: 18.7%\n",
      "\t650.0 samples train: 37.6% test: 20.0%\n",
      "\t700.0 samples train: 25.4% test: 19.0%\n",
      "\n",
      "\n",
      "Run 3\n",
      "\t50.0 samples train: 17.6% test: 20.2%\n",
      "\t100.0 samples train: 35.5% test: 25.5%\n",
      "\t150.0 samples train: 20.3% test: 23.5%\n",
      "\t200.0 samples train: 28.9% test: 31.4%\n",
      "\t250.0 samples train: 34.7% test: 23.2%\n",
      "\t300.0 samples train: 19.6% test: 19.7%\n",
      "\t350.0 samples train: 31.9% test: 17.7%\n",
      "\t400.0 samples train: 27.4% test: 22.4%\n",
      "\t450.0 samples train: 23.1% test: 20.3%\n",
      "\t500.0 samples train: 26.7% test: 18.4%\n",
      "\t550.0 samples train: 32.5% test: 19.9%\n",
      "\t600.0 samples train: 23.6% test: 20.6%\n",
      "\t650.0 samples train: 17.7% test: 20.6%\n",
      "\t700.0 samples train: 31.4% test: 20.9%\n",
      "\n",
      "\n",
      "Run 4\n",
      "\t50.0 samples train: 21.9% test: 20.2%\n",
      "\t100.0 samples train: 15.5% test: 28.2%\n",
      "\t150.0 samples train: 27.9% test: 14.1%\n",
      "\t200.0 samples train: 18.8% test: 19.5%\n",
      "\t250.0 samples train: 25.4% test: 18.9%\n",
      "\t300.0 samples train: 25.3% test: 20.3%\n",
      "\t350.0 samples train: 19.7% test: 20.1%\n",
      "\t400.0 samples train: 30.1% test: 19.7%\n",
      "\t450.0 samples train: 24.7% test: 19.5%\n",
      "\t500.0 samples train: 23.8% test: 22.9%\n",
      "\t550.0 samples train: 35.2% test: 22.4%\n",
      "\t600.0 samples train: 18.1% test: 19.3%\n",
      "\t650.0 samples train: 24.7% test: 19.1%\n",
      "\t700.0 samples train: 33.0% test: 21.7%\n",
      "\n",
      "\n",
      "Run 5\n",
      "\t50.0 samples train: 20.3% test: 21.3%\n",
      "\t100.0 samples train: 22.7% test: 25.6%\n",
      "\t150.0 samples train: 24.9% test: 20.0%\n",
      "\t200.0 samples train: 31.9% test: 31.7%\n",
      "\t250.0 samples train: 24.0% test: 24.9%\n",
      "\t300.0 samples train: 18.7% test: 20.7%\n",
      "\t350.0 samples train: 22.9% test: 19.2%\n",
      "\t400.0 samples train: 22.8% test: 20.0%\n",
      "\t450.0 samples train: 30.8% test: 19.8%\n",
      "\t500.0 samples train: 26.8% test: 20.7%\n",
      "\t550.0 samples train: 20.8% test: 19.4%\n",
      "\t600.0 samples train: 18.6% test: 21.4%\n",
      "\t650.0 samples train: 35.7% test: 19.5%\n",
      "\t700.0 samples train: 30.3% test: 19.4%\n",
      "\n",
      "\n",
      "Run 6\n",
      "\t50.0 samples train: 17.1% test: 20.1%\n",
      "\t100.0 samples train: 32.3% test: 12.6%\n",
      "\t150.0 samples train: 15.8% test: 20.3%\n",
      "\t200.0 samples train: 33.5% test: 17.6%\n",
      "\t250.0 samples train: 28.5% test: 17.7%\n",
      "\t300.0 samples train: 24.0% test: 20.3%\n",
      "\t350.0 samples train: 31.7% test: 18.9%\n",
      "\t400.0 samples train: 33.5% test: 20.0%\n",
      "\t450.0 samples train: 32.4% test: 19.9%\n",
      "\t500.0 samples train: 24.9% test: 20.3%\n",
      "\t550.0 samples train: 22.6% test: 19.8%\n",
      "\t600.0 samples train: 25.1% test: 20.3%\n",
      "\t650.0 samples train: 17.0% test: 19.9%\n",
      "\t700.0 samples train: 19.6% test: 19.7%\n",
      "\n",
      "\n",
      "Run 7\n",
      "\t50.0 samples train: 15.0% test: 14.7%\n",
      "\t100.0 samples train: 28.8% test: 30.7%\n",
      "\t150.0 samples train: 21.4% test: 18.4%\n",
      "\t200.0 samples train: 20.1% test: 15.8%\n",
      "\t250.0 samples train: 16.1% test: 17.7%\n",
      "\t300.0 samples train: 16.0% test: 19.4%\n",
      "\t350.0 samples train: 24.6% test: 20.9%\n",
      "\t400.0 samples train: 22.1% test: 19.3%\n",
      "\t450.0 samples train: 25.4% test: 21.0%\n",
      "\t500.0 samples train: 29.0% test: 18.7%\n",
      "\t550.0 samples train: 31.0% test: 20.2%\n",
      "\t600.0 samples train: 39.7% test: 19.5%\n",
      "\t650.0 samples train: 33.8% test: 19.5%\n",
      "\t700.0 samples train: 38.5% test: 19.4%\n",
      "\n",
      "\n",
      "Run 8\n",
      "\t50.0 samples train: 17.6% test: 17.6%\n",
      "\t100.0 samples train: 17.1% test: 17.6%\n",
      "\t150.0 samples train: 25.1% test: 24.1%\n",
      "\t200.0 samples train: 21.6% test: 23.4%\n",
      "\t250.0 samples train: 18.7% test: 20.9%\n",
      "\t300.0 samples train: 26.3% test: 21.7%\n",
      "\t350.0 samples train: 20.3% test: 22.6%\n",
      "\t400.0 samples train: 19.3% test: 20.8%\n",
      "\t450.0 samples train: 20.7% test: 20.2%\n",
      "\t500.0 samples train: 19.4% test: 21.7%\n",
      "\t550.0 samples train: 38.1% test: 21.4%\n",
      "\t600.0 samples train: 26.8% test: 21.4%\n",
      "\t650.0 samples train: 25.2% test: 20.0%\n",
      "\t700.0 samples train: 37.2% test: 21.4%\n",
      "\n",
      "\n",
      "Run 9\n",
      "\t50.0 samples train: 26.7% test: 22.6%\n",
      "\t100.0 samples train: 22.4% test: 22.2%\n",
      "\t150.0 samples train: 24.6% test: 16.0%\n",
      "\t200.0 samples train: 22.0% test: 15.3%\n",
      "\t250.0 samples train: 26.9% test: 19.4%\n",
      "\t300.0 samples train: 28.0% test: 22.5%\n",
      "\t350.0 samples train: 25.1% test: 20.8%\n",
      "\t400.0 samples train: 23.9% test: 18.2%\n",
      "\t450.0 samples train: 36.2% test: 19.4%\n",
      "\t500.0 samples train: 27.0% test: 19.9%\n",
      "\t550.0 samples train: 25.0% test: 20.0%\n",
      "\t600.0 samples train: 24.3% test: 21.3%\n",
      "\t650.0 samples train: 41.3% test: 19.3%\n",
      "\t700.0 samples train: 22.1% test: 19.5%\n",
      "\n",
      "\n",
      "Run 10\n",
      "\t50.0 samples train: 22.5% test: 22.5%\n",
      "\t100.0 samples train: 27.7% test: 19.3%\n",
      "\t150.0 samples train: 17.3% test: 20.1%\n",
      "\t200.0 samples train: 23.6% test: 21.3%\n",
      "\t250.0 samples train: 21.7% test: 23.8%\n",
      "\t300.0 samples train: 16.6% test: 21.1%\n",
      "\t350.0 samples train: 16.5% test: 19.5%\n",
      "\t400.0 samples train: 22.9% test: 20.5%\n",
      "\t450.0 samples train: 19.0% test: 19.5%\n",
      "\t500.0 samples train: 24.6% test: 22.1%\n",
      "\t550.0 samples train: 25.2% test: 20.1%\n",
      "\t600.0 samples train: 25.8% test: 19.2%\n",
      "\t650.0 samples train: 27.8% test: 20.1%\n",
      "\t700.0 samples train: 21.5% test: 18.6%\n",
      "\n",
      "\n",
      "Run 11\n",
      "\t50.0 samples train: 18.7% test: 21.0%\n",
      "\t100.0 samples train: 17.3% test: 18.5%\n",
      "\t150.0 samples train: 21.2% test: 22.3%\n",
      "\t200.0 samples train: 28.5% test: 29.7%\n",
      "\t250.0 samples train: 18.6% test: 20.2%\n",
      "\t300.0 samples train: 33.1% test: 14.2%\n",
      "\t350.0 samples train: 29.5% test: 19.9%\n",
      "\t400.0 samples train: 30.5% test: 20.9%\n",
      "\t450.0 samples train: 21.7% test: 23.9%\n",
      "\t500.0 samples train: 29.8% test: 20.6%\n",
      "\t550.0 samples train: 28.4% test: 21.7%\n",
      "\t600.0 samples train: 39.3% test: 19.9%\n",
      "\t650.0 samples train: 32.4% test: 19.5%\n",
      "\t700.0 samples train: 29.9% test: 19.5%\n",
      "\n",
      "\n",
      "Run 12\n",
      "\t50.0 samples train: 25.1% test: 27.7%\n",
      "\t100.0 samples train: 26.9% test: 25.8%\n",
      "\t150.0 samples train: 21.4% test: 20.6%\n",
      "\t200.0 samples train: 32.3% test: 25.5%\n",
      "\t250.0 samples train: 25.9% test: 16.3%\n",
      "\t300.0 samples train: 25.0% test: 20.7%\n",
      "\t350.0 samples train: 23.9% test: 18.5%\n",
      "\t400.0 samples train: 19.9% test: 22.3%\n",
      "\t450.0 samples train: 27.1% test: 19.3%\n",
      "\t500.0 samples train: 29.2% test: 21.3%\n",
      "\t550.0 samples train: 21.9% test: 19.8%\n",
      "\t600.0 samples train: 38.6% test: 19.4%\n",
      "\t650.0 samples train: 44.4% test: 20.2%\n",
      "\t700.0 samples train: 46.6% test: 20.8%\n",
      "\n",
      "\n",
      "Run 13\n",
      "\t50.0 samples train: 19.8% test: 21.0%\n",
      "\t100.0 samples train: 30.9% test: 25.8%\n",
      "\t150.0 samples train: 21.2% test: 20.7%\n",
      "\t200.0 samples train: 26.8% test: 20.6%\n",
      "\t250.0 samples train: 25.7% test: 24.7%\n",
      "\t300.0 samples train: 34.3% test: 23.3%\n",
      "\t350.0 samples train: 15.7% test: 22.2%\n",
      "\t400.0 samples train: 36.0% test: 21.1%\n",
      "\t450.0 samples train: 32.1% test: 22.7%\n",
      "\t500.0 samples train: 21.2% test: 19.8%\n",
      "\t550.0 samples train: 28.0% test: 19.4%\n",
      "\t600.0 samples train: 31.5% test: 20.0%\n",
      "\t650.0 samples train: 28.1% test: 20.7%\n",
      "\t700.0 samples train: 20.0% test: 20.1%\n",
      "\n",
      "\n",
      "Run 14\n",
      "\t50.0 samples train: 24.6% test: 21.7%\n",
      "\t100.0 samples train: 22.7% test: 17.9%\n",
      "\t150.0 samples train: 21.4% test: 39.8%\n",
      "\t200.0 samples train: 22.3% test: 24.7%\n",
      "\t250.0 samples train: 16.1% test: 23.1%\n",
      "\t300.0 samples train: 37.7% test: 22.5%\n",
      "\t350.0 samples train: 18.1% test: 18.4%\n",
      "\t400.0 samples train: 23.6% test: 20.6%\n",
      "\t450.0 samples train: 24.5% test: 18.7%\n",
      "\t500.0 samples train: 28.9% test: 21.1%\n",
      "\t550.0 samples train: 38.7% test: 19.0%\n",
      "\t600.0 samples train: 30.4% test: 19.1%\n",
      "\t650.0 samples train: 32.6% test: 20.2%\n",
      "\t700.0 samples train: 32.1% test: 19.5%\n",
      "\n",
      "\n",
      "Run 15\n",
      "\t50.0 samples train: 18.2% test: 20.1%\n",
      "\t100.0 samples train: 18.4% test: 16.1%\n",
      "\t150.0 samples train: 18.7% test: 27.5%\n",
      "\t200.0 samples train: 27.2% test: 12.3%\n",
      "\t250.0 samples train: 22.6% test: 20.2%\n",
      "\t300.0 samples train: 37.2% test: 19.3%\n",
      "\t350.0 samples train: 26.8% test: 18.5%\n",
      "\t400.0 samples train: 20.4% test: 19.3%\n",
      "\t450.0 samples train: 31.3% test: 21.7%\n",
      "\t500.0 samples train: 19.4% test: 21.7%\n",
      "\t550.0 samples train: 38.1% test: 20.1%\n",
      "\t600.0 samples train: 20.9% test: 20.0%\n",
      "\t650.0 samples train: 35.8% test: 21.4%\n",
      "\t700.0 samples train: 22.7% test: 20.1%\n",
      "\n",
      "\n",
      "Run 16\n",
      "\t50.0 samples train: 17.6% test: 21.0%\n",
      "\t100.0 samples train: 19.5% test: 32.8%\n",
      "\t150.0 samples train: 18.3% test: 19.5%\n",
      "\t200.0 samples train: 22.1% test: 21.4%\n",
      "\t250.0 samples train: 35.1% test: 23.8%\n",
      "\t300.0 samples train: 20.7% test: 19.0%\n",
      "\t350.0 samples train: 23.1% test: 17.7%\n",
      "\t400.0 samples train: 31.5% test: 19.4%\n",
      "\t450.0 samples train: 30.3% test: 19.0%\n",
      "\t500.0 samples train: 30.4% test: 19.1%\n",
      "\t550.0 samples train: 19.5% test: 19.9%\n",
      "\t600.0 samples train: 40.7% test: 20.7%\n",
      "\t650.0 samples train: 25.3% test: 20.8%\n",
      "\t700.0 samples train: 23.8% test: 19.7%\n",
      "\n",
      "\n",
      "Run 17\n",
      "\t50.0 samples train: 21.9% test: 19.8%\n",
      "\t100.0 samples train: 17.6% test: 19.0%\n",
      "\t150.0 samples train: 28.8% test: 20.3%\n",
      "\t200.0 samples train: 18.3% test: 18.9%\n",
      "\t250.0 samples train: 22.6% test: 21.5%\n",
      "\t300.0 samples train: 24.4% test: 17.9%\n",
      "\t350.0 samples train: 27.4% test: 20.9%\n",
      "\t400.0 samples train: 30.4% test: 20.2%\n",
      "\t450.0 samples train: 26.7% test: 19.8%\n",
      "\t500.0 samples train: 31.6% test: 20.9%\n",
      "\t550.0 samples train: 24.3% test: 19.0%\n",
      "\t600.0 samples train: 24.4% test: 20.0%\n",
      "\t650.0 samples train: 32.2% test: 19.7%\n",
      "\t700.0 samples train: 30.3% test: 19.1%\n",
      "\n",
      "\n",
      "Run 18\n",
      "\t50.0 samples train: 15.0% test: 16.7%\n",
      "\t100.0 samples train: 13.9% test: 12.7%\n",
      "\t150.0 samples train: 25.1% test: 25.0%\n",
      "\t200.0 samples train: 20.8% test: 22.3%\n",
      "\t250.0 samples train: 29.8% test: 26.6%\n",
      "\t300.0 samples train: 31.1% test: 21.9%\n",
      "\t350.0 samples train: 35.1% test: 19.2%\n",
      "\t400.0 samples train: 23.1% test: 23.1%\n",
      "\t450.0 samples train: 30.7% test: 19.2%\n",
      "\t500.0 samples train: 31.1% test: 18.9%\n",
      "\t550.0 samples train: 32.3% test: 19.7%\n",
      "\t600.0 samples train: 28.2% test: 20.0%\n",
      "\t650.0 samples train: 36.1% test: 20.9%\n",
      "\t700.0 samples train: 19.2% test: 19.0%\n",
      "\n",
      "\n",
      "Run 19\n",
      "\t50.0 samples train: 26.7% test: 25.3%\n",
      "\t100.0 samples train: 22.7% test: 18.6%\n",
      "\t150.0 samples train: 25.6% test: 17.7%\n",
      "\t200.0 samples train: 18.8% test: 18.9%\n",
      "\t250.0 samples train: 21.2% test: 18.5%\n",
      "\t300.0 samples train: 26.2% test: 24.9%\n",
      "\t350.0 samples train: 26.1% test: 20.0%\n",
      "\t400.0 samples train: 26.2% test: 19.9%\n",
      "\t450.0 samples train: 34.8% test: 19.7%\n",
      "\t500.0 samples train: 25.7% test: 19.9%\n",
      "\t550.0 samples train: 29.5% test: 19.3%\n",
      "\t600.0 samples train: 19.2% test: 20.0%\n",
      "\t650.0 samples train: 30.3% test: 19.8%\n",
      "\t700.0 samples train: 23.1% test: 21.6%\n",
      "\n",
      "\n",
      "Run 20\n",
      "\t50.0 samples train: 19.8% test: 17.5%\n",
      "\t100.0 samples train: 27.2% test: 21.7%\n",
      "\t150.0 samples train: 21.7% test: 20.1%\n",
      "\t200.0 samples train: 16.0% test: 17.4%\n",
      "\t250.0 samples train: 23.3% test: 21.6%\n",
      "\t300.0 samples train: 16.4% test: 21.9%\n",
      "\t350.0 samples train: 20.0% test: 19.2%\n",
      "\t400.0 samples train: 25.3% test: 21.4%\n",
      "\t450.0 samples train: 24.7% test: 19.3%\n",
      "\t500.0 samples train: 27.4% test: 19.9%\n",
      "\t550.0 samples train: 34.0% test: 19.0%\n",
      "\t600.0 samples train: 22.5% test: 21.1%\n",
      "\t650.0 samples train: 36.8% test: 20.5%\n",
      "\t700.0 samples train: 32.3% test: 20.7%\n",
      "\n",
      "\n",
      "Run 21\n",
      "\t50.0 samples train: 17.6% test: 17.8%\n",
      "\t100.0 samples train: 18.4% test: 19.9%\n",
      "\t150.0 samples train: 18.0% test: 15.9%\n",
      "\t200.0 samples train: 25.5% test: 22.2%\n",
      "\t250.0 samples train: 34.3% test: 24.9%\n",
      "\t300.0 samples train: 21.2% test: 20.9%\n",
      "\t350.0 samples train: 18.9% test: 18.9%\n",
      "\t400.0 samples train: 38.6% test: 21.4%\n",
      "\t450.0 samples train: 20.6% test: 21.8%\n",
      "\t500.0 samples train: 30.2% test: 21.4%\n",
      "\t550.0 samples train: 29.0% test: 19.9%\n",
      "\t600.0 samples train: 38.3% test: 20.7%\n",
      "\t650.0 samples train: 34.0% test: 19.1%\n",
      "\t700.0 samples train: 35.1% test: 20.6%\n",
      "\n",
      "\n",
      "Run 22\n",
      "\t50.0 samples train: 18.7% test: 21.4%\n",
      "\t100.0 samples train: 21.6% test: 19.8%\n",
      "\t150.0 samples train: 15.3% test: 12.0%\n",
      "\t200.0 samples train: 19.6% test: 19.7%\n",
      "\t250.0 samples train: 19.6% test: 20.5%\n",
      "\t300.0 samples train: 22.2% test: 19.1%\n",
      "\t350.0 samples train: 21.2% test: 19.3%\n",
      "\t400.0 samples train: 27.7% test: 17.6%\n",
      "\t450.0 samples train: 39.1% test: 21.7%\n",
      "\t500.0 samples train: 20.6% test: 18.9%\n",
      "\t550.0 samples train: 35.1% test: 19.3%\n",
      "\t600.0 samples train: 36.8% test: 19.1%\n",
      "\t650.0 samples train: 30.9% test: 20.7%\n",
      "\t700.0 samples train: 32.4% test: 19.1%\n",
      "\n",
      "\n",
      "Run 23\n",
      "\t50.0 samples train: 25.7% test: 23.8%\n",
      "\t100.0 samples train: 32.3% test: 19.2%\n",
      "\t150.0 samples train: 21.4% test: 13.7%\n",
      "\t200.0 samples train: 28.8% test: 19.2%\n",
      "\t250.0 samples train: 17.5% test: 26.1%\n",
      "\t300.0 samples train: 31.8% test: 20.7%\n",
      "\t350.0 samples train: 33.3% test: 18.2%\n",
      "\t400.0 samples train: 27.3% test: 19.1%\n",
      "\t450.0 samples train: 19.7% test: 20.7%\n",
      "\t500.0 samples train: 35.0% test: 19.8%\n",
      "\t550.0 samples train: 22.5% test: 19.7%\n",
      "\t600.0 samples train: 36.8% test: 19.9%\n",
      "\t650.0 samples train: 39.5% test: 20.8%\n",
      "\t700.0 samples train: 23.5% test: 20.2%\n",
      "\n",
      "\n",
      "Run 24\n",
      "\t50.0 samples train: 19.8% test: 20.2%\n",
      "\t100.0 samples train: 17.3% test: 21.6%\n",
      "\t150.0 samples train: 17.4% test: 16.3%\n",
      "\t200.0 samples train: 14.5% test: 21.0%\n",
      "\t250.0 samples train: 30.1% test: 20.7%\n",
      "\t300.0 samples train: 27.2% test: 20.5%\n",
      "\t350.0 samples train: 32.7% test: 23.8%\n",
      "\t400.0 samples train: 30.7% test: 20.0%\n",
      "\t450.0 samples train: 30.6% test: 22.3%\n",
      "\t500.0 samples train: 22.7% test: 21.9%\n",
      "\t550.0 samples train: 33.9% test: 21.0%\n",
      "\t600.0 samples train: 21.4% test: 19.4%\n",
      "\t650.0 samples train: 34.7% test: 21.0%\n",
      "\t700.0 samples train: 31.4% test: 21.6%\n",
      "\n",
      "\n",
      "Run 25\n",
      "\t50.0 samples train: 26.7% test: 25.7%\n",
      "\t100.0 samples train: 19.7% test: 25.1%\n",
      "\t150.0 samples train: 24.0% test: 23.5%\n",
      "\t200.0 samples train: 17.7% test: 17.0%\n",
      "\t250.0 samples train: 20.3% test: 22.4%\n",
      "\t300.0 samples train: 29.5% test: 19.4%\n",
      "\t350.0 samples train: 27.4% test: 19.0%\n",
      "\t400.0 samples train: 34.6% test: 17.4%\n",
      "\t450.0 samples train: 33.0% test: 23.1%\n",
      "\t500.0 samples train: 24.8% test: 18.9%\n",
      "\t550.0 samples train: 16.3% test: 21.7%\n",
      "\t600.0 samples train: 32.4% test: 21.0%\n",
      "\t650.0 samples train: 22.1% test: 18.6%\n",
      "\t700.0 samples train: 26.3% test: 20.6%\n",
      "\n",
      "\n",
      "Run 26\n",
      "\t50.0 samples train: 26.2% test: 22.2%\n",
      "\t100.0 samples train: 20.8% test: 24.0%\n",
      "\t150.0 samples train: 23.5% test: 17.4%\n",
      "\t200.0 samples train: 33.7% test: 24.3%\n",
      "\t250.0 samples train: 33.9% test: 21.8%\n",
      "\t300.0 samples train: 18.0% test: 19.2%\n",
      "\t350.0 samples train: 16.5% test: 23.8%\n",
      "\t400.0 samples train: 31.5% test: 19.2%\n",
      "\t450.0 samples train: 30.1% test: 21.0%\n",
      "\t500.0 samples train: 37.6% test: 20.2%\n",
      "\t550.0 samples train: 21.4% test: 20.6%\n",
      "\t600.0 samples train: 21.2% test: 18.6%\n",
      "\t650.0 samples train: 32.8% test: 20.2%\n",
      "\t700.0 samples train: 34.7% test: 20.1%\n",
      "\n",
      "\n",
      "Run 27\n",
      "\t50.0 samples train: 16.0% test: 14.6%\n",
      "\t100.0 samples train: 26.1% test: 19.4%\n",
      "\t150.0 samples train: 10.5% test: 21.8%\n",
      "\t200.0 samples train: 28.5% test: 24.7%\n",
      "\t250.0 samples train: 24.3% test: 21.1%\n",
      "\t300.0 samples train: 21.2% test: 20.7%\n",
      "\t350.0 samples train: 20.7% test: 21.6%\n",
      "\t400.0 samples train: 24.4% test: 18.9%\n",
      "\t450.0 samples train: 21.2% test: 19.1%\n",
      "\t500.0 samples train: 30.0% test: 21.3%\n",
      "\t550.0 samples train: 37.8% test: 19.5%\n",
      "\t600.0 samples train: 28.8% test: 20.9%\n",
      "\t650.0 samples train: 35.8% test: 20.2%\n",
      "\t700.0 samples train: 28.5% test: 20.0%\n",
      "\n",
      "\n",
      "Run 28\n",
      "\t50.0 samples train: 29.4% test: 31.8%\n",
      "\t100.0 samples train: 30.4% test: 19.8%\n",
      "\t150.0 samples train: 27.8% test: 17.0%\n",
      "\t200.0 samples train: 40.8% test: 19.3%\n",
      "\t250.0 samples train: 18.4% test: 25.1%\n",
      "\t300.0 samples train: 24.2% test: 17.4%\n",
      "\t350.0 samples train: 32.2% test: 18.9%\n",
      "\t400.0 samples train: 22.7% test: 19.2%\n",
      "\t450.0 samples train: 27.9% test: 18.3%\n",
      "\t500.0 samples train: 27.0% test: 19.0%\n",
      "\t550.0 samples train: 24.7% test: 20.1%\n",
      "\t600.0 samples train: 26.3% test: 19.3%\n",
      "\t650.0 samples train: 44.6% test: 20.3%\n",
      "\t700.0 samples train: 30.3% test: 20.8%\n",
      "\n",
      "\n",
      "Run 29\n",
      "\t50.0 samples train: 29.4% test: 27.0%\n",
      "\t100.0 samples train: 27.5% test: 13.0%\n",
      "\t150.0 samples train: 19.4% test: 16.5%\n",
      "\t200.0 samples train: 27.9% test: 19.7%\n",
      "\t250.0 samples train: 25.9% test: 29.0%\n",
      "\t300.0 samples train: 38.3% test: 18.3%\n",
      "\t350.0 samples train: 29.7% test: 19.2%\n",
      "\t400.0 samples train: 35.5% test: 22.1%\n",
      "\t450.0 samples train: 24.5% test: 21.3%\n",
      "\t500.0 samples train: 18.6% test: 22.7%\n",
      "\t550.0 samples train: 40.3% test: 20.3%\n",
      "\t600.0 samples train: 27.2% test: 19.0%\n",
      "\t650.0 samples train: 27.2% test: 21.6%\n",
      "\t700.0 samples train: 35.8% test: 19.8%\n",
      "\n",
      "\n",
      "Run 30\n",
      "\t50.0 samples train: 13.4% test: 15.4%\n",
      "\t100.0 samples train: 16.3% test: 18.3%\n",
      "\t150.0 samples train: 19.6% test: 20.5%\n",
      "\t200.0 samples train: 26.5% test: 21.1%\n",
      "\t250.0 samples train: 28.9% test: 21.9%\n",
      "\t300.0 samples train: 22.4% test: 22.9%\n",
      "\t350.0 samples train: 25.7% test: 20.9%\n",
      "\t400.0 samples train: 31.5% test: 21.5%\n",
      "\t450.0 samples train: 27.6% test: 19.1%\n",
      "\t500.0 samples train: 23.2% test: 20.5%\n",
      "\t550.0 samples train: 30.2% test: 19.4%\n",
      "\t600.0 samples train: 29.1% test: 21.6%\n",
      "\t650.0 samples train: 45.4% test: 20.1%\n",
      "\t700.0 samples train: 26.0% test: 20.3%\n",
      "\n",
      "\n",
      "Run 31\n",
      "\t50.0 samples train: 25.7% test: 25.8%\n",
      "\t100.0 samples train: 34.9% test: 24.5%\n",
      "\t150.0 samples train: 24.0% test: 27.1%\n",
      "\t200.0 samples train: 22.9% test: 16.1%\n",
      "\t250.0 samples train: 22.3% test: 21.0%\n",
      "\t300.0 samples train: 26.7% test: 18.4%\n",
      "\t350.0 samples train: 22.1% test: 24.3%\n",
      "\t400.0 samples train: 29.7% test: 26.1%\n",
      "\t450.0 samples train: 34.4% test: 18.4%\n",
      "\t500.0 samples train: 27.1% test: 20.2%\n",
      "\t550.0 samples train: 39.7% test: 21.0%\n",
      "\t600.0 samples train: 19.5% test: 19.5%\n",
      "\t650.0 samples train: 31.4% test: 20.9%\n",
      "\t700.0 samples train: 33.4% test: 21.0%\n",
      "\n",
      "\n",
      "Run 32\n",
      "\t50.0 samples train: 16.0% test: 17.8%\n",
      "\t100.0 samples train: 23.2% test: 19.1%\n",
      "\t150.0 samples train: 19.0% test: 21.6%\n",
      "\t200.0 samples train: 27.5% test: 23.0%\n",
      "\t250.0 samples train: 21.6% test: 17.3%\n",
      "\t300.0 samples train: 27.5% test: 25.5%\n",
      "\t350.0 samples train: 24.9% test: 20.2%\n",
      "\t400.0 samples train: 16.1% test: 21.0%\n",
      "\t450.0 samples train: 13.5% test: 19.4%\n",
      "\t500.0 samples train: 21.5% test: 21.0%\n",
      "\t550.0 samples train: 32.5% test: 20.9%\n",
      "\t600.0 samples train: 40.4% test: 20.8%\n",
      "\t650.0 samples train: 33.2% test: 21.3%\n",
      "\t700.0 samples train: 36.8% test: 19.9%\n",
      "\n",
      "\n",
      "Run 33\n",
      "\t50.0 samples train: 15.5% test: 13.6%\n",
      "\t100.0 samples train: 24.5% test: 25.0%\n",
      "\t150.0 samples train: 23.5% test: 28.9%\n",
      "\t200.0 samples train: 27.5% test: 19.2%\n",
      "\t250.0 samples train: 29.6% test: 20.6%\n",
      "\t300.0 samples train: 29.5% test: 18.4%\n",
      "\t350.0 samples train: 20.8% test: 20.1%\n",
      "\t400.0 samples train: 16.6% test: 19.0%\n",
      "\t450.0 samples train: 23.2% test: 22.7%\n",
      "\t500.0 samples train: 33.2% test: 20.9%\n",
      "\t550.0 samples train: 22.5% test: 20.0%\n",
      "\t600.0 samples train: 27.1% test: 20.0%\n",
      "\t650.0 samples train: 36.7% test: 19.8%\n",
      "\t700.0 samples train: 18.8% test: 19.8%\n",
      "\n",
      "\n",
      "Run 34\n",
      "\t50.0 samples train: 16.0% test: 19.8%\n",
      "\t100.0 samples train: 18.9% test: 20.0%\n",
      "\t150.0 samples train: 23.5% test: 20.7%\n",
      "\t200.0 samples train: 21.1% test: 22.4%\n",
      "\t250.0 samples train: 18.9% test: 22.5%\n",
      "\t300.0 samples train: 20.1% test: 27.0%\n",
      "\t350.0 samples train: 31.3% test: 19.5%\n",
      "\t400.0 samples train: 36.9% test: 16.7%\n",
      "\t450.0 samples train: 25.4% test: 22.7%\n",
      "\t500.0 samples train: 30.7% test: 18.9%\n",
      "\t550.0 samples train: 20.8% test: 19.7%\n",
      "\t600.0 samples train: 28.6% test: 19.7%\n",
      "\t650.0 samples train: 31.7% test: 20.2%\n",
      "\t700.0 samples train: 21.1% test: 20.2%\n",
      "\n",
      "\n",
      "Run 35\n",
      "\t50.0 samples train: 19.8% test: 17.9%\n",
      "\t100.0 samples train: 14.7% test: 16.3%\n",
      "\t150.0 samples train: 19.9% test: 19.1%\n",
      "\t200.0 samples train: 17.2% test: 18.9%\n",
      "\t250.0 samples train: 19.1% test: 25.1%\n",
      "\t300.0 samples train: 20.6% test: 22.9%\n",
      "\t350.0 samples train: 38.9% test: 22.6%\n",
      "\t400.0 samples train: 23.2% test: 18.1%\n",
      "\t450.0 samples train: 32.4% test: 23.7%\n",
      "\t500.0 samples train: 20.7% test: 20.9%\n",
      "\t550.0 samples train: 21.9% test: 19.7%\n",
      "\t600.0 samples train: 43.4% test: 19.4%\n",
      "\t650.0 samples train: 33.8% test: 19.9%\n",
      "\t700.0 samples train: 27.5% test: 20.8%\n",
      "\n",
      "\n",
      "Run 36\n",
      "\t50.0 samples train: 17.1% test: 15.1%\n",
      "\t100.0 samples train: 25.3% test: 12.7%\n",
      "\t150.0 samples train: 23.8% test: 14.1%\n",
      "\t200.0 samples train: 24.5% test: 28.7%\n",
      "\t250.0 samples train: 26.4% test: 20.0%\n",
      "\t300.0 samples train: 27.6% test: 22.9%\n",
      "\t350.0 samples train: 21.0% test: 22.5%\n",
      "\t400.0 samples train: 18.3% test: 19.8%\n",
      "\t450.0 samples train: 20.0% test: 19.0%\n",
      "\t500.0 samples train: 20.5% test: 19.2%\n",
      "\t550.0 samples train: 20.8% test: 19.9%\n",
      "\t600.0 samples train: 29.9% test: 19.4%\n",
      "\t650.0 samples train: 40.3% test: 20.8%\n",
      "\t700.0 samples train: 20.4% test: 20.7%\n",
      "\n",
      "\n",
      "Run 37\n",
      "\t50.0 samples train: 14.4% test: 14.7%\n",
      "\t100.0 samples train: 20.5% test: 24.7%\n",
      "\t150.0 samples train: 20.3% test: 31.3%\n",
      "\t200.0 samples train: 25.9% test: 34.1%\n",
      "\t250.0 samples train: 21.8% test: 20.2%\n",
      "\t300.0 samples train: 29.2% test: 20.6%\n",
      "\t350.0 samples train: 26.6% test: 21.4%\n",
      "\t400.0 samples train: 30.6% test: 20.1%\n",
      "\t450.0 samples train: 26.6% test: 19.1%\n",
      "\t500.0 samples train: 30.1% test: 19.4%\n",
      "\t550.0 samples train: 19.1% test: 20.3%\n",
      "\t600.0 samples train: 30.5% test: 20.0%\n",
      "\t650.0 samples train: 34.1% test: 19.4%\n",
      "\t700.0 samples train: 33.8% test: 20.1%\n",
      "\n",
      "\n",
      "Run 38\n",
      "\t50.0 samples train: 21.4% test: 23.2%\n",
      "\t100.0 samples train: 20.0% test: 21.4%\n",
      "\t150.0 samples train: 18.3% test: 17.3%\n",
      "\t200.0 samples train: 19.6% test: 20.7%\n",
      "\t250.0 samples train: 18.8% test: 21.5%\n",
      "\t300.0 samples train: 19.8% test: 18.1%\n",
      "\t350.0 samples train: 33.8% test: 21.0%\n",
      "\t400.0 samples train: 15.9% test: 21.3%\n",
      "\t450.0 samples train: 34.5% test: 20.5%\n",
      "\t500.0 samples train: 18.6% test: 20.7%\n",
      "\t550.0 samples train: 28.8% test: 19.3%\n",
      "\t600.0 samples train: 30.2% test: 21.5%\n",
      "\t650.0 samples train: 32.1% test: 20.8%\n",
      "\t700.0 samples train: 23.6% test: 20.1%\n",
      "\n",
      "\n",
      "Run 39\n",
      "\t50.0 samples train: 13.9% test: 14.3%\n",
      "\t100.0 samples train: 25.6% test: 22.7%\n",
      "\t150.0 samples train: 26.7% test: 20.7%\n",
      "\t200.0 samples train: 22.7% test: 23.3%\n",
      "\t250.0 samples train: 35.1% test: 20.1%\n",
      "\t300.0 samples train: 20.0% test: 17.3%\n",
      "\t350.0 samples train: 17.7% test: 18.3%\n",
      "\t400.0 samples train: 21.5% test: 19.2%\n",
      "\t450.0 samples train: 26.7% test: 22.1%\n",
      "\t500.0 samples train: 31.0% test: 20.5%\n",
      "\t550.0 samples train: 16.8% test: 19.4%\n",
      "\t600.0 samples train: 23.5% test: 19.3%\n",
      "\t650.0 samples train: 35.5% test: 20.0%\n",
      "\t700.0 samples train: 24.9% test: 19.7%\n",
      "\n",
      "\n",
      "Run 40\n",
      "\t50.0 samples train: 24.6% test: 27.2%\n",
      "\t100.0 samples train: 20.8% test: 26.1%\n",
      "\t150.0 samples train: 26.2% test: 23.1%\n",
      "\t200.0 samples train: 17.6% test: 21.8%\n",
      "\t250.0 samples train: 21.7% test: 20.9%\n",
      "\t300.0 samples train: 31.3% test: 19.4%\n",
      "\t350.0 samples train: 23.9% test: 19.7%\n",
      "\t400.0 samples train: 23.3% test: 20.9%\n",
      "\t450.0 samples train: 35.0% test: 19.4%\n",
      "\t500.0 samples train: 27.4% test: 21.0%\n",
      "\t550.0 samples train: 26.2% test: 19.8%\n",
      "\t600.0 samples train: 28.0% test: 19.7%\n",
      "\t650.0 samples train: 50.1% test: 19.3%\n",
      "\t700.0 samples train: 28.8% test: 19.8%\n",
      "\n",
      "\n",
      "Run 41\n",
      "\t50.0 samples train: 16.0% test: 15.7%\n",
      "\t100.0 samples train: 12.5% test: 18.5%\n",
      "\t150.0 samples train: 23.3% test: 21.4%\n",
      "\t200.0 samples train: 20.7% test: 18.6%\n",
      "\t250.0 samples train: 20.1% test: 17.7%\n",
      "\t300.0 samples train: 23.7% test: 23.0%\n",
      "\t350.0 samples train: 27.1% test: 17.6%\n",
      "\t400.0 samples train: 19.7% test: 20.0%\n",
      "\t450.0 samples train: 19.1% test: 23.3%\n",
      "\t500.0 samples train: 24.3% test: 19.8%\n",
      "\t550.0 samples train: 27.1% test: 18.6%\n",
      "\t600.0 samples train: 31.7% test: 19.9%\n",
      "\t650.0 samples train: 30.8% test: 20.7%\n",
      "\t700.0 samples train: 26.2% test: 20.8%\n",
      "\n",
      "\n",
      "Run 42\n",
      "\t50.0 samples train: 18.7% test: 19.3%\n",
      "\t100.0 samples train: 18.9% test: 24.7%\n",
      "\t150.0 samples train: 30.6% test: 20.0%\n",
      "\t200.0 samples train: 22.1% test: 19.9%\n",
      "\t250.0 samples train: 22.5% test: 23.1%\n",
      "\t300.0 samples train: 31.2% test: 18.6%\n",
      "\t350.0 samples train: 15.2% test: 19.9%\n",
      "\t400.0 samples train: 26.2% test: 22.3%\n",
      "\t450.0 samples train: 22.6% test: 20.7%\n",
      "\t500.0 samples train: 23.2% test: 22.1%\n",
      "\t550.0 samples train: 20.7% test: 19.3%\n",
      "\t600.0 samples train: 29.3% test: 21.6%\n",
      "\t650.0 samples train: 26.5% test: 19.5%\n",
      "\t700.0 samples train: 25.6% test: 20.3%\n",
      "\n",
      "\n",
      "Run 43\n",
      "\t50.0 samples train: 19.3% test: 18.5%\n",
      "\t100.0 samples train: 18.1% test: 18.5%\n",
      "\t150.0 samples train: 22.1% test: 23.1%\n",
      "\t200.0 samples train: 17.2% test: 18.6%\n",
      "\t250.0 samples train: 20.2% test: 18.3%\n",
      "\t300.0 samples train: 15.6% test: 22.2%\n",
      "\t350.0 samples train: 38.5% test: 23.0%\n",
      "\t400.0 samples train: 31.3% test: 19.5%\n",
      "\t450.0 samples train: 32.4% test: 20.0%\n",
      "\t500.0 samples train: 19.0% test: 18.5%\n",
      "\t550.0 samples train: 27.1% test: 19.8%\n",
      "\t600.0 samples train: 36.7% test: 19.9%\n",
      "\t650.0 samples train: 25.9% test: 20.3%\n",
      "\t700.0 samples train: 29.1% test: 20.2%\n",
      "\n",
      "\n",
      "Run 44\n",
      "\t50.0 samples train: 15.5% test: 19.3%\n",
      "\t100.0 samples train: 21.9% test: 16.8%\n",
      "\t150.0 samples train: 21.9% test: 19.3%\n",
      "\t200.0 samples train: 17.7% test: 18.9%\n",
      "\t250.0 samples train: 17.8% test: 18.4%\n",
      "\t300.0 samples train: 21.3% test: 18.7%\n",
      "\t350.0 samples train: 36.6% test: 19.1%\n",
      "\t400.0 samples train: 24.1% test: 21.6%\n",
      "\t450.0 samples train: 28.6% test: 19.9%\n",
      "\t500.0 samples train: 38.7% test: 20.5%\n",
      "\t550.0 samples train: 28.9% test: 19.0%\n",
      "\t600.0 samples train: 28.1% test: 19.8%\n",
      "\t650.0 samples train: 23.6% test: 20.9%\n",
      "\t700.0 samples train: 30.9% test: 19.9%\n",
      "\n",
      "\n",
      "Run 45\n",
      "\t50.0 samples train: 22.5% test: 20.5%\n",
      "\t100.0 samples train: 16.8% test: 14.6%\n",
      "\t150.0 samples train: 25.6% test: 19.2%\n",
      "\t200.0 samples train: 17.7% test: 19.7%\n",
      "\t250.0 samples train: 20.0% test: 19.0%\n",
      "\t300.0 samples train: 30.4% test: 19.2%\n",
      "\t350.0 samples train: 23.1% test: 19.8%\n",
      "\t400.0 samples train: 27.7% test: 20.2%\n",
      "\t450.0 samples train: 31.9% test: 20.7%\n",
      "\t500.0 samples train: 26.0% test: 21.4%\n",
      "\t550.0 samples train: 32.8% test: 21.1%\n",
      "\t600.0 samples train: 23.5% test: 18.7%\n",
      "\t650.0 samples train: 37.9% test: 20.5%\n",
      "\t700.0 samples train: 30.9% test: 21.6%\n",
      "\n",
      "\n",
      "Run 46\n",
      "\t50.0 samples train: 20.3% test: 29.3%\n",
      "\t100.0 samples train: 26.4% test: 16.0%\n",
      "\t150.0 samples train: 20.6% test: 20.6%\n",
      "\t200.0 samples train: 20.4% test: 21.8%\n",
      "\t250.0 samples train: 30.9% test: 15.1%\n",
      "\t300.0 samples train: 31.1% test: 19.4%\n",
      "\t350.0 samples train: 21.1% test: 23.7%\n",
      "\t400.0 samples train: 29.0% test: 18.5%\n",
      "\t450.0 samples train: 14.9% test: 20.7%\n",
      "\t500.0 samples train: 24.1% test: 20.5%\n",
      "\t550.0 samples train: 33.2% test: 20.6%\n",
      "\t600.0 samples train: 22.4% test: 20.1%\n",
      "\t650.0 samples train: 36.8% test: 20.7%\n",
      "\t700.0 samples train: 39.4% test: 21.0%\n",
      "\n",
      "\n",
      "Run 47\n",
      "\t50.0 samples train: 29.9% test: 34.2%\n",
      "\t100.0 samples train: 22.1% test: 14.2%\n",
      "\t150.0 samples train: 20.1% test: 28.0%\n",
      "\t200.0 samples train: 16.9% test: 30.6%\n",
      "\t250.0 samples train: 12.2% test: 17.6%\n",
      "\t300.0 samples train: 21.2% test: 18.3%\n",
      "\t350.0 samples train: 21.4% test: 19.9%\n",
      "\t400.0 samples train: 26.5% test: 22.5%\n",
      "\t450.0 samples train: 23.5% test: 21.8%\n",
      "\t500.0 samples train: 28.7% test: 20.0%\n",
      "\t550.0 samples train: 22.5% test: 23.0%\n",
      "\t600.0 samples train: 20.0% test: 18.4%\n",
      "\t650.0 samples train: 20.5% test: 21.5%\n",
      "\t700.0 samples train: 36.4% test: 20.8%\n",
      "\n",
      "\n",
      "Run 48\n",
      "\t50.0 samples train: 21.4% test: 22.9%\n",
      "\t100.0 samples train: 17.3% test: 28.8%\n",
      "\t150.0 samples train: 26.2% test: 20.9%\n",
      "\t200.0 samples train: 15.2% test: 23.2%\n",
      "\t250.0 samples train: 32.2% test: 18.3%\n",
      "\t300.0 samples train: 19.5% test: 20.1%\n",
      "\t350.0 samples train: 20.6% test: 22.1%\n",
      "\t400.0 samples train: 18.5% test: 20.1%\n",
      "\t450.0 samples train: 26.9% test: 21.3%\n",
      "\t500.0 samples train: 32.8% test: 18.5%\n",
      "\t550.0 samples train: 25.2% test: 20.5%\n",
      "\t600.0 samples train: 27.2% test: 19.8%\n",
      "\t650.0 samples train: 40.0% test: 19.3%\n",
      "\t700.0 samples train: 34.2% test: 20.0%\n",
      "\n",
      "\n",
      "Run 49\n",
      "\t50.0 samples train: 26.7% test: 21.7%\n",
      "\t100.0 samples train: 21.1% test: 19.7%\n",
      "\t150.0 samples train: 28.3% test: 22.6%\n",
      "\t200.0 samples train: 30.5% test: 23.0%\n",
      "\t250.0 samples train: 22.3% test: 23.0%\n",
      "\t300.0 samples train: 29.6% test: 25.7%\n",
      "\t350.0 samples train: 29.8% test: 22.6%\n",
      "\t400.0 samples train: 22.1% test: 22.3%\n",
      "\t450.0 samples train: 36.5% test: 18.9%\n",
      "\t500.0 samples train: 22.9% test: 22.3%\n",
      "\t550.0 samples train: 22.8% test: 20.2%\n",
      "\t600.0 samples train: 29.8% test: 21.0%\n",
      "\t650.0 samples train: 30.7% test: 21.4%\n",
      "\t700.0 samples train: 25.8% test: 20.2%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_x_samples = [\n",
    "    (data_50_samples, target_50_samples), \n",
    "    (data_100_samples, target_100_samples),\n",
    "    (data_150_samples, target_150_samples), \n",
    "    (data_200_samples, target_200_samples), \n",
    "    (data_250_samples, target_250_samples), \n",
    "    (data_300_samples, target_300_samples), \n",
    "    (data_350_samples, target_350_samples), \n",
    "    (data_400_samples, target_400_samples), \n",
    "    (data_450_samples, target_450_samples),\n",
    "    (data_500_samples, target_500_samples), \n",
    "    (data_550_samples, target_550_samples), \n",
    "    (data_600_samples, target_600_samples), \n",
    "    (data_650_samples, target_650_samples), \n",
    "    (data_700_samples, target_700_samples)\n",
    "]\n",
    "sample_numbers = (list(range(50, 701, 50)))\n",
    "results = []\n",
    "\n",
    "def samples_test(verbose=True):\n",
    "\n",
    "    dummy, static_X_test, dummy, static_y_test = train_test_split(data_700_samples, target_700_samples, stratify=target_700_samples)\n",
    "    \n",
    "    results.append([])\n",
    "\n",
    "    for sample_number, i in zip(sample_numbers, range(14)):\n",
    "        data_x_samples = info_x_samples[i][0]\n",
    "        target_x_samples = info_x_samples[i][1]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        data_x_samples = data_x_samples.reshape(data_x_samples.shape[0], -1)\n",
    "        data_x_samples = (scaler.fit_transform(data_x_samples)).reshape((data_x_samples.shape[0], 10, 10, 1))\n",
    "        \n",
    "        target_x_samples = to_categorical(target_x_samples)\n",
    "\n",
    "        split_X_train, split_X_test, split_y_train, split_y_test = train_test_split(data_x_samples, target_x_samples, stratify=target_x_samples)\n",
    "\n",
    "        model = Model()\n",
    "    \n",
    "        model.build(input_shape=(1, 10, 10, 1))\n",
    "        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(split_X_train, split_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "    \n",
    "        train_accuracy = model.evaluate(split_X_train, split_y_train, verbose=False)[1]\n",
    "\n",
    "        static_X_test = static_X_test.reshape(static_X_test.shape[0], -1)\n",
    "        static_X_test = (scaler.transform(static_X_test)).reshape((static_X_test.shape[0], 10, 10, 1))\n",
    "\n",
    "        test_accuracy = model.evaluate(static_X_test, to_categorical(static_y_test), verbose=False)[1]\n",
    "        \n",
    "        print(f'\\t{(data_x_samples.shape[0])/5} samples train: {train_accuracy*100:.1f}% test: {test_accuracy*100:.1f}%')\n",
    "\n",
    "        results[-1].append(test_accuracy)\n",
    "\n",
    "for i in range(49):\n",
    "    print(f\"Run {i+1}\")\n",
    "    samples_test(verbose=False)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare CSV for R Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "df = pd.DataFrame(results, columns=[f'{num} samples' for num in range(50, 701, 50)])\n",
    "df.to_csv('R Data Analysis/data/samples_test_175_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total dataset test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data.shape: (1259300, 10, 10)\n",
      "original target.shape: (1259300,)\n",
      "\n",
      "electron.shape: (3150, 10, 10), (3150,)\n",
      "muon.shape: (700, 10, 10), (700,)\n",
      "pion.shape: (981050, 10, 10), (981050,)\n",
      "kaon.shape: (160300, 10, 10), (160300,)\n",
      "proton.shape: (114100, 10, 10), (114100,)\n",
      "\n",
      "X_train.shape: (944475, 10, 10, 1)\n",
      "y_train.shape: (944475, 5)\n",
      "X_test.shape: (314825, 10, 10, 1)\n",
      "y_test.shape: (314825, 5)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we evaluate the models accuracies on the dataset without limit of 700 per class.\n",
    "# However, first we must setup the data, as shown in the top of the notebook.\n",
    "\n",
    "data_total = []\n",
    "target_total = []\n",
    "\n",
    "for file in files:\n",
    "    file = open(f'data/{files[0]}', 'rb')\n",
    "    file = pickle.load(file)\n",
    "\n",
    "    for sample, sample_target in zip(file[0], file[1]):\n",
    "        data_total.append(sample)\n",
    "        target_total.append(sample_target)\n",
    "\n",
    "data_total = np.array(data_total)\n",
    "target_total = np.array(target_total)\n",
    "\n",
    "sleep(7)\n",
    "clear_output()\n",
    "\n",
    "print(f'original data.shape: {data_total.shape}')\n",
    "print(f'original target.shape: {target_total.shape}\\n')\n",
    "\n",
    "# Edit target values to 0, 1, 2...\n",
    "new_target = []\n",
    "\n",
    "for tar in target_total:\n",
    "    if tar == 11:\n",
    "        new_target.append(0)\n",
    "    elif tar == 13:\n",
    "        new_target.append(1)\n",
    "    elif tar == 211:\n",
    "        new_target.append(2)\n",
    "    elif tar == 321:\n",
    "        new_target.append(3)\n",
    "    else:\n",
    "        new_target.append(4)\n",
    "    \n",
    "target_total = np.array(new_target)\n",
    "\n",
    "for i in range(5):\n",
    "    particle_indexes = np.where(target_total == i)[0]\n",
    "\n",
    "    data_modified = data_total[particle_indexes]\n",
    "    target_modified = target_total[particle_indexes]\n",
    "    \n",
    "    print(f'{target_names[str(i)]}.shape: {data_modified.shape}, {target_modified.shape}')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_total, target_total, stratify=target_total)\n",
    "\n",
    "# Change the train and test datasets.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape + change data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Scale and reshape data back to og form.\n",
    "X_train = (scaler.fit_transform(X_train)).reshape((X_train.shape[0], 10, 10, 1))\n",
    "X_test = (scaler.transform(X_test)).reshape((X_test.shape[0], 10, 10, 1))\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f'\\nX_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "\n",
    "# NOTE: We are using the unbalanced dataset in order to see if there is correlation to high accuracy with particles that have high # of samples.\n",
    "#       Based on the dataset partitions below, we would expect pion, kaon, and proton to have a higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 0.7%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.3%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 0.9%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 1.2%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 1.2%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 0.9%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 1.2%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 1.2%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.3%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 0.9%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 0.7%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.3%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 0.9%\n",
      "proton accuracy: 0.3%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 1.2%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 1.2%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.3%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.1%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.4%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.5%\n",
      "proton accuracy: 0.9%\n",
      "electron accuracy: 0.0%\n",
      "muon accuracy: 0.0%\n",
      "pion accuracy: 100.0%\n",
      "kaon accuracy: 1.3%\n",
      "proton accuracy: 0.6%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "def individual_particle_test_modified(model):    # The only difference with this one is we record the data\n",
    "\n",
    "    results.append([])\n",
    "    model_recreate = Model()\n",
    "\n",
    "    model_recreate.build(input_shape=(1, 10, 10, 1))\n",
    "    model_recreate.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model_recreate.fit(X_train, y_train, epochs=3, batch_size=64, verbose=False).history    # We want to recreate the model every run so that we get different results\n",
    "\n",
    "    for i in range(5):\n",
    "        int_y_test = np.array([np.argmax(y, axis=None, out=None) for y in y_test])    # convert back to integer for comparison.\n",
    "        particle_indexes = np.where(int_y_test == i)    # gives indexes for all electron, muon, etc testcases...\n",
    "\n",
    "        X_test_modified = X_test[particle_indexes]\n",
    "        y_test_modified = y_test[particle_indexes]\n",
    "\n",
    "        particle_accuracy = model_recreate.evaluate(X_test_modified, y_test_modified, verbose=False)[1]\n",
    "\n",
    "        print(f'{target_names[str(i)]} accuracy: {particle_accuracy*100:.1f}%')\n",
    "\n",
    "        results[-1].append(particle_accuracy)\n",
    "\n",
    "for i in range(50):\n",
    "    individual_particle_test_modified(tf_model)\n",
    "\n",
    "# Basically, in this test, train on ENTIRE dataset;\n",
    "# test on specific particle (recorded as result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare results for R data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "df = pd.DataFrame(results, columns=['electron accuracy', 'muon accuracy', 'pion accuracy', 'kaon accuracy', 'proton accuracy'])\n",
    "df.to_csv('R Data Analysis/data/total_dataset_test_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muon vs All Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the muon is 1 and all else is changed to 0.\n",
    "\n",
    "muon_data, muon_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "muon_target = list(muon_target)\n",
    "\n",
    "# muon before is label 1 (already), everything else needs to be changed to a 0\n",
    "for i in range(len(muon_target)):\n",
    "    if muon_target[i] != 1:\n",
    "        muon_target[i] = 0\n",
    "\n",
    "muon_target = np.array(muon_target)        \n",
    "\n",
    "# change dataset to 700 muon and 700 other\n",
    "muon_indexes = np.where(muon_target == 1)\n",
    "other_indexes = np.where(muon_target == 0)\n",
    "\n",
    "muon_target = np.append(muon_target[muon_indexes], muon_target[other_indexes][:700])\n",
    "muon_data = np.append(muon_data[muon_indexes], muon_data[other_indexes][:700], axis=0)\n",
    "\n",
    "print(muon_data.shape)\n",
    "print(muon_target.shape)\n",
    "\n",
    "muon_data = muon_data.reshape(muon_data.shape[0], -1)\n",
    "muon_data = (scaler.fit_transform(muon_data)).reshape(muon_data.shape[0], 10, 10, 1)\n",
    "\n",
    "moun_target = to_categorical(muon_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "muon_X_train, muon_y_train = (np.append(muon_data[:350], muon_data[700:1050], axis=0), np.append(muon_target[:350], muon_target[700:1050]))\n",
    "muon_X_test, muon_y_test = (np.append(muon_data[350:700], muon_data[1050:1400], axis=0), np.append(muon_target[350:700], muon_target[1050:1400]))\n",
    "\n",
    "class Muon_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Muon_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    muon_model = Muon_Model()\n",
    "\n",
    "    muon_model.build(input_shape=(1, 10, 10, 1))\n",
    "    muon_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = muon_model.fit(muon_X_train, muon_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_muon = muon_model.evaluate(muon_X_train, muon_y_train, verbose=False)[1]\n",
    "    test_accuracy_muon = muon_model.evaluate(muon_X_test, muon_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_muon}')\n",
    "    print(f'Test accuracy: {test_accuracy_muon}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muon Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 350]\n",
      " [  0 350]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "predictions = muon_model.predict(muon_X_test)\n",
    "answers = muon_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 0 is everything else, 1 is muon\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting samples labeled 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muon Test: Confusion Matrix (`logreg` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muon_X_train_logreg.shape (700, 100)\n",
      "muon_y_train_logreg.shape (700,)\n",
      "muon_X_test_logreg.shape (700, 100)\n",
      "muon_y_test_logreg.shape (700,)\n",
      "Train Accuracy: 0.5\n",
      "Test Accuracy: 0.5\n",
      "[[350   0]\n",
      " [350   0]]\n"
     ]
    }
   ],
   "source": [
    "muon_X_train_logreg = muon_X_train.reshape((700, -1))\n",
    "muon_y_train_logreg = muon_y_train\n",
    "\n",
    "muon_X_test_logreg = muon_X_test.reshape((700, -1))\n",
    "muon_y_test_logreg = muon_y_test\n",
    "\n",
    "print(f'muon_X_train_logreg.shape {muon_X_train_logreg.shape}')\n",
    "print(f'muon_y_train_logreg.shape {muon_y_train_logreg.shape}')\n",
    "print(f'muon_X_test_logreg.shape {muon_X_test_logreg.shape}')\n",
    "print(f'muon_y_test_logreg.shape {muon_y_test_logreg.shape}')\n",
    "\n",
    "muon_model_logreg = LogisticRegression()\n",
    "\n",
    "muon_model_logreg.fit(muon_X_train_logreg, muon_y_train_logreg)\n",
    "\n",
    "print(f'Train Accuracy: {muon_model_logreg.score(muon_X_train_logreg, muon_y_train_logreg)}')\n",
    "print(f'Test Accuracy: {muon_model_logreg.score(muon_X_test_logreg, muon_y_test_logreg)}')\n",
    "\n",
    "predictions = muon_model_logreg.predict(muon_X_test_logreg)\n",
    "answers = muon_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "print('FP Rate: 50%')\n",
    "print('TP Rate: 0%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 10, 10, 1)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "print(muon_X_train.shape)\n",
    "print(muon_y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electron vs Non-Electron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the electron is 0 and all else is changed to 1.\n",
    "\n",
    "electron_data, electron_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "electron_target = list(electron_target)\n",
    "\n",
    "# electron is label 0 (keep 0 to simplify process), everything else needs to be changed to a 1\n",
    "for i in range(len(electron_target)):\n",
    "    if electron_target[i] != 0:\n",
    "        electron_target[i] = 1\n",
    "\n",
    "electron_target = np.array(electron_target)        \n",
    "\n",
    "# change dataset to 700 electron and 700 other\n",
    "electron_indexes = np.where(electron_target == 0)\n",
    "other_indexes = np.where(electron_target == 1)\n",
    "\n",
    "electron_target = np.append(electron_target[electron_indexes], electron_target[other_indexes][:700])\n",
    "electron_data = np.append(electron_data[electron_indexes], electron_data[other_indexes][:700], axis=0)\n",
    "\n",
    "print(electron_data.shape)\n",
    "print(electron_target.shape)\n",
    "\n",
    "electron_data = electron_data.reshape(electron_data.shape[0], -1)\n",
    "electron_data = (scaler.fit_transform(electron_data)).reshape(electron_data.shape[0], 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "electron_X_train, electron_y_train = (np.append(electron_data[:350], electron_data[700:1050], axis=0), np.append(electron_target[:350], electron_target[700:1050]))\n",
    "electron_X_test, electron_y_test = (np.append(electron_data[350:700], electron_data[1050:1400], axis=0), np.append(electron_target[350:700], electron_target[1050:1400]))\n",
    "\n",
    "class Electron_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Electron_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    electron_model = Electron_Model()\n",
    "\n",
    "    electron_model.build(input_shape=(1, 10, 10, 1))\n",
    "    electron_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = electron_model.fit(electron_X_train, electron_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_electron = electron_model.evaluate(electron_X_train, electron_y_train, verbose=False)[1]\n",
    "    test_accuracy_electron = electron_model.evaluate(electron_X_test, electron_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_electron}')\n",
    "    print(f'Test accuracy: {test_accuracy_electron}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 350]\n",
      " [  0 350]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "predictions = electron_model.predict(electron_X_test)\n",
    "answers = electron_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 0 is electron, 1 is everything else\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting samples labeled 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron Test: Confusion Matrix (`logreg` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron_X_train_logreg.shape (700, 100)\n",
      "electron_y_train_logreg.shape (700,)\n",
      "electron_X_test_logreg.shape (700, 100)\n",
      "electron_y_test_logreg.shape (700,)\n",
      "Train Accuracy: 0.5\n",
      "Test Accuracy: 0.5\n",
      "[[350   0]\n",
      " [350   0]]\n",
      "FP Rate: 50%\n",
      "TP Rate: 0%\n"
     ]
    }
   ],
   "source": [
    "electron_X_train_logreg = electron_X_train.reshape((700, -1))\n",
    "electron_y_train_logreg = electron_y_train\n",
    "\n",
    "electron_X_test_logreg = electron_X_test.reshape((700, -1))\n",
    "electron_y_test_logreg = electron_y_test\n",
    "\n",
    "print(f'electron_X_train_logreg.shape {electron_X_train_logreg.shape}')\n",
    "print(f'electron_y_train_logreg.shape {electron_y_train_logreg.shape}')\n",
    "print(f'electron_X_test_logreg.shape {electron_X_test_logreg.shape}')\n",
    "print(f'electron_y_test_logreg.shape {electron_y_test_logreg.shape}')\n",
    "\n",
    "electron_model_logreg = LogisticRegression()\n",
    "\n",
    "electron_model_logreg.fit(electron_X_train_logreg, electron_y_train_logreg)\n",
    "\n",
    "print(f'Train Accuracy: {electron_model_logreg.score(electron_X_train_logreg, electron_y_train_logreg)}')\n",
    "print(f'Test Accuracy: {electron_model_logreg.score(electron_X_test_logreg, electron_y_test_logreg)}')\n",
    "\n",
    "predictions = electron_model_logreg.predict(electron_X_test_logreg)\n",
    "answers = electron_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 0 is electron, 1 is everything else\n",
    "\n",
    "print('FP Rate: 50%')    # 50% on predicting samples labeled 0\n",
    "print('TP Rate: 0%')    # 0% on predicting samples labeled 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pion vs Non-Pion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the pion is 1 and all else is changed to 0\n",
    "\n",
    "pion_data, pion_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "pion_target = list(pion_target)\n",
    "\n",
    "# pion is label 1, everything else needs to be changed to a 0.\n",
    "for i in range(len(pion_target)):\n",
    "    if pion_target[i] != 2:\n",
    "        pion_target[i] = 0\n",
    "    else:\n",
    "        pion_target[i] = 1    # This means that the target is 2 (pion)... change it to 1.\n",
    "\n",
    "pion_target = np.array(pion_target)\n",
    "\n",
    "# change dataset to 700 pion and 700 other.\n",
    "pion_indexes = np.where(pion_target == 1)\n",
    "other_indexes = np.where(pion_target == 0)\n",
    "\n",
    "pion_data = np.append(pion_data[pion_indexes], pion_data[other_indexes][:700], axis=0)\n",
    "pion_target = np.append(pion_target[pion_indexes], pion_target[other_indexes][:700])\n",
    "\n",
    "print(pion_data.shape)\n",
    "print(pion_target.shape)\n",
    "\n",
    "pion_data = pion_data.reshape(pion_data.shape[0], -1)\n",
    "pion_data = (scaler.fit_transform(pion_data)).reshape(pion_data.shape[0], 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test Accuracy 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pion_X_train, pion_y_train = (np.append(pion_data[:350], pion_data[700:1050], axis=0), np.append(pion_target[:350], pion_target[700:1050]))\n",
    "pion_X_test, pion_y_test = (np.append(pion_data[350:700], pion_data[1050:1400], axis=0), np.append(pion_target[350:700], pion_target[1050:1400]))\n",
    "\n",
    "class Pion_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Pion_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    pion_model = Pion_Model()\n",
    "\n",
    "    pion_model.build(input_shape=(1, 10, 10, 1))\n",
    "    pion_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = pion_model.fit(pion_X_train, pion_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_pion = pion_model.evaluate(pion_X_train, pion_y_train, verbose=False)[1]\n",
    "    test_accuracy_pion = pion_model.evaluate(pion_X_test, pion_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_pion}')\n",
    "    print(f'Test Accuracy {test_accuracy_pion}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pion Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 350]\n",
      " [  0 350]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "predictions = pion_model.predict(pion_X_test)\n",
    "answers = pion_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 1 is pion, 0 is everything else.\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting smaples labeled 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaon vs Non-Kaon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the kaon is 1 and all else is changed to 0.\n",
    "\n",
    "kaon_data, kaon_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "kaon_target = list(kaon_target)\n",
    "\n",
    "# kaon is label 3 (make 1), everything else needs to be changed to a 0.\n",
    "for i in range(len(kaon_target)):\n",
    "    if kaon_target[i] != 3:\n",
    "        kaon_target[i] = 0\n",
    "    else:\n",
    "        kaon_target[i] = 1\n",
    "\n",
    "kaon_target = np.array(kaon_target)        \n",
    "\n",
    "# change dataset to 700 kaon and 700 other\n",
    "kaon_indexes = np.where(kaon_target == 1)\n",
    "other_indexes = np.where(kaon_target == 0)\n",
    "\n",
    "kaon_target = np.append(kaon_target[kaon_indexes], kaon_target[other_indexes][:700])\n",
    "kaon_data = np.append(kaon_data[kaon_indexes], kaon_data[other_indexes][:700], axis=0)\n",
    "\n",
    "print(kaon_data.shape)\n",
    "print(kaon_target.shape)\n",
    "\n",
    "kaon_data = kaon_data.reshape(kaon_data.shape[0], -1)\n",
    "kaon_data = (scaler.fit_transform(kaon_data)).reshape(kaon_data.shape[0], 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kaon_X_train, kaon_y_train = (np.append(kaon_data[:500], kaon_data[700:1200], axis=0), np.append(kaon_target[:500], kaon_target[700:1200]))\n",
    "kaon_X_test, kaon_y_test = (np.append(kaon_data[500:700], kaon_data[1200:1400], axis=0), np.append(kaon_target[500:700], kaon_target[1200:1400]))\n",
    "\n",
    "class Kaon_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Kaon_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "for i in range(25):\n",
    "    \n",
    "    kaon_model = Kaon_Model()\n",
    "\n",
    "    kaon_model.build(input_shape=(1, 10, 10, 1))\n",
    "    kaon_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = kaon_model.fit(kaon_X_train, kaon_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_kaon = kaon_model.evaluate(kaon_X_train, kaon_y_train, verbose=False)[1]\n",
    "    test_accuracy_kaon = kaon_model.evaluate(kaon_X_test, kaon_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_kaon}')\n",
    "    print(f'Test accuracy: {test_accuracy_kaon}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaon Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 200]\n",
      " [  0 200]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = kaon_model.predict(kaon_X_test)\n",
    "answers = kaon_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 1 is kaon, 0 is everything else\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting samples labeled 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proton vs Non-Proton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 10, 10)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "# In this test, we change the target where the proton is 1 and all else is changed to 0.\n",
    "\n",
    "proton_data, proton_target = (data_700_samples, target_700_samples)\n",
    "\n",
    "proton_target = list(proton_target)\n",
    "\n",
    "# proton is label 4 (change to 1), everything else needs to be changed to a 0\n",
    "for i in range(len(proton_target)):\n",
    "    if proton_target[i] != 4:\n",
    "        proton_target[i] = 0\n",
    "    else:\n",
    "        proton_target[i] = 1\n",
    "\n",
    "proton_target = np.array(proton_target)        \n",
    "\n",
    "# change dataset to 700 proton and 700 other\n",
    "proton_indexes = np.where(proton_target == 1)\n",
    "other_indexes = np.where(proton_target == 0)\n",
    "\n",
    "proton_target = np.append(proton_target[proton_indexes], proton_target[other_indexes][:700])\n",
    "proton_data = np.append(proton_data[proton_indexes], proton_data[other_indexes][:700], axis=0)\n",
    "\n",
    "print(proton_data.shape)\n",
    "print(proton_target.shape)\n",
    "\n",
    "proton_data = proton_data.reshape(proton_data.shape[0], -1)\n",
    "proton_data = (scaler.fit_transform(proton_data)).reshape(proton_data.shape[0], 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Train accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proton_X_train, proton_y_train = (np.append(proton_data[:500], proton_data[700:1200], axis=0), np.append(proton_target[:500], proton_target[700:1200]))\n",
    "proton_X_test, proton_y_test = (np.append(proton_data[500:700], proton_data[1200:1400], axis=0), np.append(proton_target[500:700], proton_target[1200:1400]))\n",
    "\n",
    "class Proton_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Proton_Model, self).__init__()\n",
    "\n",
    "        self.input_layers = [\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten()\n",
    "        ]\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2'),\n",
    "            Dense(19, activation='relu', kernel_regularizer='l2')\n",
    "        ]\n",
    "\n",
    "        self.output_layer = Dense(1, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.input_layers[0](inputs)\n",
    "        h = self.input_layers[1](h)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            h = hidden_layer(h)\n",
    "        \n",
    "        return self.output_layer(h)\n",
    "\n",
    "for i in range(25):\n",
    "    \n",
    "    proton_model = Proton_Model()\n",
    "\n",
    "    proton_model.build(input_shape=(1, 10, 10, 1))\n",
    "    proton_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = proton_model.fit(proton_X_train, proton_y_train, epochs=3, batch_size=64, verbose=False)\n",
    "\n",
    "    train_accuracy_proton = proton_model.evaluate(proton_X_train, proton_y_train, verbose=False)[1]\n",
    "    test_accuracy_proton = proton_model.evaluate(proton_X_test, proton_y_test, verbose=False)[1]\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy_proton}')\n",
    "    print(f'Test accuracy: {test_accuracy_proton}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proton Test: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 200]\n",
      " [  0 200]]\n",
      "TP Rate 50%\n",
      "FP Rate 0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = proton_model.predict(proton_X_test)\n",
    "answers = proton_y_test\n",
    "\n",
    "print(confusion_matrix(answers, predictions))\n",
    "\n",
    "# Remember, 1 is proton, 0 is everything else\n",
    "\n",
    "print(f'TP Rate 50%')    # 50% on predicting samples labeled 1\n",
    "print(f'FP Rate 0%')    # 0% on predicting samples labeled 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "7b8ec01fe1ca8fb45588a4ccd1c70e5bbb495e4fae5c72e85a541e07ce265118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
